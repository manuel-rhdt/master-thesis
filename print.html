<!DOCTYPE HTML>
<html lang="en-us" class="sidebar-visible no-js Light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Mutual Information between Trajectories</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.min.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
        <script>document.addEventListener("DOMContentLoaded", function () {
            var mathElements = document.getElementsByClassName("math");
            var regex = /\\qquad\W*\(([0-9]+)\)/;
            for (var i = 0; i < mathElements.length; i++) {
                var texText = mathElements[i].firstChild;
                if (mathElements[i].tagName == "SPAN") {
                    var tex_str = texText.data.replace(regex, "\\tag{$1}");
                    katex.render(tex_str, mathElements[i], {
                    displayMode: mathElements[i].classList.contains('display'),
                    throwOnError: false,
                    fleqn: false
                });
            }}});
        </script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "" : "Light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('Light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="expanded"><a href="index.html" class=""><span class="header-section-number">1</span> Introduction
                    </a>
                    </li><li class="expanded"><a href="acknowledgments.html" class="">Acknowledgments
                    </a>
                    </li><li class="expanded"><a href="introduction.html" class=""><span class="header-section-number">2</span> Introduction
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="introduction.html#goal-of-the-thesis" class=""><span class="header-section-number">2.1</span> Goal of the Thesis
                    </a>
                    </li><li class="expanded"><a href="introduction.html#structure-of-the-thesis" class=""><span class="header-section-number">2.2</span> Structure of the Thesis
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html" class=""><span class="header-section-number">3</span> Modeling Cell Signaling Networks as Information Processing Devices
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#information-theory-in-the-context-of-cellular-signaling-networks" class=""><span class="header-section-number">3.1</span> Information Theory in the context of cellular signaling networks
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#mutual-information-as-an-efficiency-measure-in-cell-signaling" class=""><span class="header-section-number">3.1.1</span> Mutual Information as an Efficiency Measure in Cell signaling
                    </a>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#information-transmission-for-time-varying-signals" class=""><span class="header-section-number">3.1.2</span> Information Transmission for Time-Varying Signals
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#stochastic-modeling-of-biochemical-networks" class=""><span class="header-section-number">3.2</span> Stochastic Modeling of Biochemical Networks
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#markov-processes" class=""><span class="header-section-number">3.2.1</span> Markov Processes
                    </a>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#chemical-master-equation" class=""><span class="header-section-number">3.2.2</span> Chemical Master Equation
                    </a>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#jump-processes" class=""><span class="header-section-number">3.2.3</span> Jump Processes
                    </a>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#probability-densities-of-trajectories" class=""><span class="header-section-number">3.2.4</span> Probability Densities of Trajectories
                    </a>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#sec:ssa" class=""><span class="header-section-number">3.2.5</span> Generating Stochastic Trajectories for Jump Processes
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="modeling-cell-signaling-networks-as-information-processing-devices.html#sec:simple_model" class=""><span class="header-section-number">3.3</span> A Simple Model of Gene Expression
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html" class=""><span class="header-section-number">3</span> Monte Carlo Estimate of the Mutual Information
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#monte-carlo-estimate-for-the-marginal-entropy" class=""><span class="header-section-number">3.1</span> Monte-Carlo Estimate for the Marginal Entropy
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#estimating-the-conditional-entropy" class=""><span class="header-section-number">3.2</span> Estimating the Conditional Entropy
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#monte-carlo-simulations-for-trajectories" class=""><span class="header-section-number">3.3</span> Monte-Carlo Simulations for Trajectories
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#general-stochastic-dynamics-of-signals" class=""><span class="header-section-number">3.3.1</span> General Stochastic Dynamics of Signals
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#generating-responses-for-time-varying-signals" class=""><span class="header-section-number">3.3.2</span> Generating Responses for Time-Varying Signals
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#generation-of-response-trajectories-according-to-mathrm-pmathbf-xmathbf-s" class=""><span class="header-section-number">3.3.2.1</span> Generation of response trajectories according to <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span>
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#generation-of-response-trajectories-according-to-mathrm-pmathbf-x" class=""><span class="header-section-number">3.3.2.2</span> Generation of response trajectories according to <span class="math inline">\mathrm P(\mathbf x)</span>
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#compuation-of-mathrm-pmathbf-xmathbf-s" class=""><span class="header-section-number">3.3.2.3</span> Compuation of <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span>
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#sec:initial_condition" class=""><span class="header-section-number">3.3.3</span> Probability Distribution of the Initial State
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#returning-to-the-simple-model-of-gene-expression" class=""><span class="header-section-number">3.4</span> Returning to the Simple Model of Gene Expression
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#simulating-signals-and-responses" class=""><span class="header-section-number">3.4.1</span> Simulating Signals and Responses
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#consistent-bias-in-comparisons-with-analytic-approximations" class=""><span class="header-section-number">3.4.2</span> Consistent Bias in Comparisons with Analytic Approximations
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#gaussian-approximation" class=""><span class="header-section-number">3.5</span> Gaussian Approximation
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#time-discretization" class=""><span class="header-section-number">3.5.1</span> Time Discretization
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#direct-importance-sampling" class=""><span class="header-section-number">3.5.2</span> Direct Importance Sampling
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#sec:umbrella" class=""><span class="header-section-number">3.5.3</span> Umbrella Sampling
                    </a>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#estimating-the-conditional-entropy-1" class=""><span class="header-section-number">3.5.4</span> Estimating the Conditional Entropy
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="monte-carlo-estimate-of-the-mutual-information.html#discussion" class=""><span class="header-section-number">3.6</span> Discussion
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html" class=""><span class="header-section-number">4</span> Directed Sampling in Trajectory Space
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="directed-sampling-in-trajectory-space.html#previous-work-on-the-computation-of-the-marginal-likelihood" class=""><span class="header-section-number">4.1</span> Previous Work on the Computation of the Marginal Likelihood
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="directed-sampling-in-trajectory-space.html#importance-sampling" class=""><span class="header-section-number">4.1.1</span> Importance Sampling
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#estimating-the-marginal-density-from-posterior-samples" class=""><span class="header-section-number">4.1.2</span> Estimating the Marginal Density from Posterior Samples
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#bridge-sampling-and-beyond" class=""><span class="header-section-number">4.1.3</span> Bridge Sampling and Beyond
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#borrowing-terminology-from-statistical-physics" class=""><span class="header-section-number">4.2</span> Borrowing Terminology from Statistical Physics
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#thermodynamic-integration" class=""><span class="header-section-number">4.3</span> Thermodynamic Integration
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="directed-sampling-in-trajectory-space.html#summary-of-the-technique" class=""><span class="header-section-number">4.3.1</span> Summary of the Technique
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#markov-chain-monte-carlo" class=""><span class="header-section-number">4.3.2</span> Markov Chain Monte Carlo
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#estimating-the-density-of-states" class=""><span class="header-section-number">4.4</span> Estimating the Density of States
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="directed-sampling-in-trajectory-space.html#wang-and-landau-algorithm" class=""><span class="header-section-number">4.4.1</span> Wang and Landau Algorithm
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#applying-wang-landau-to-the-computation-of-the-marginal-density" class=""><span class="header-section-number">4.4.2</span> Applying Wang-Landau to the Computation of the Marginal Density
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="directed-sampling-in-trajectory-space.html#modified-dos" class=""><span class="header-section-number">4.4.2.1</span> Modified DOS
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#modified-wang-landau-algorithm" class=""><span class="header-section-number">4.4.2.2</span> Modified Wang-Landau algorithm
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#comparison-to-usual-wang-landau-algorithm" class=""><span class="header-section-number">4.4.2.3</span> Comparison to usual Wang-Landau algorithm
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#connection-to-standard-monte-carlo-sampling" class=""><span class="header-section-number">4.4.2.4</span> Connection to Standard Monte-Carlo Sampling
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#example-results-for-a-wang-landau-simulation" class=""><span class="header-section-number">4.4.3</span> Example Results for a Wang-Landau Simulation
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#generating-proposal-trajectories-from-general-stochastic-dynamics" class=""><span class="header-section-number">4.5</span> Generating Proposal Trajectories from General Stochastic Dynamics
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#marginalizing-out-individual-components-of-the-biochemical-network" class=""><span class="header-section-number">4.6</span> Marginalizing Out Individual Components of the Biochemical Network
                    </a>
                    </li><li class="expanded"><a href="directed-sampling-in-trajectory-space.html#discussion" class=""><span class="header-section-number">4.7</span> Discussion
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="conclusion.html" class=""><span class="header-section-number">5</span> Conclusion
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="conclusion.html#summary-of-main-results" class=""><span class="header-section-number">5.1</span> Summary of Main Results
                    </a>
                    </li><li class="expanded"><a href="conclusion.html#outlook" class=""><span class="header-section-number">5.2</span> Outlook
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="references.html" class="">References
                    </a>
                    </li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                    </div>

                    <h1 class="menu-title">Mutual Information between Trajectories</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        <a href="https://github.com/manuel-rhdt/master-thesis" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <section id="index" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p><strong>Note:</strong> <em>This is only a draft of my master’s thesis.</em></p>
<p>When we consider the point of view of a signal-processing device (e.g. a cell) we might be interested in cases where both the quantity <span class="math inline">\mathcal S</span> and the data <span class="math inline">\mathcal X</span> change over time. We then consider the values of the random variables <span class="math inline">\mathcal S, \mathcal X</span> to be trajectories or sequences of states over time. Trajectories are usually represented as high-dimensional vectors (e.g. as a sequence of states and transition times). Our motivation is to compute the mutual information between such trajectories. To do this we intend to generate trajectories using a fully stochastic model of a biochemical network based on its master equation to compute the likelihoods of individual trajectories. In these notes however we only consider a very simple multi-dimensional Gaussian system because it allows us to test and understand the pitfalls of information estimation for high-dimensional systems with relatively low amounts of computing power. Additionally for a multivariate Gaussian system there exists a simple analytical expressions for the mutual information that we use to verify our estimates.</p>
</section>
<section id="acknowledgments" class="level1 unnumbered" data-number="">
<h1 class="unnumbered" data-number="1">Acknowledgments</h1>
<p>This thesis would not be in your hands (or your screen) if it weren’t for the help and support of many people. I would like to mention a few of them.</p>
<p>Pieter Rein, thank you for being my supervisor. I have learnt so much from our conversations and discussions. And I always felt I could come to you with simple or hard questions and good—or bad—results. I also think you have a very funny and uplifting personality and it is always a joy to work with you. Of course, I also want to thank the other members of the group individually. Tom, for always having a good joke ready. And I enjoyed our technical discussions about operating systems and programming languages. Mareike, you are an inspiration for any aspiring researcher and I want to thank you for your selfless support in good and in bad times. You always motivate me to keep going. Yao, for letting me enjoy your wonderful singing voice. Alex, really for our distinctly non-shallow conversations about any topic. Harmen for being someone whose opinion I always value greatly and for being so kind to me and everyone else around you. Lotte, you are the ideal office-mate and we had so much fun together. My first year at AMOLF would not have been the same without you.</p>
<p>I also want to thank all of my other colleagues at AMOLF, especially from the other theory group, Bela, Ramon, Tom, Marco and Faan. We had wonderful coffee breaks together, of the real and also the virtual kind.</p>
<p>Thank you, Gašper Tkačik for giving valuable feedback and for sharing your idea of using Wang-Landau sampling. I also thank Chase Broedersz, my official master thesis supervisor for supporting my master’s project abroad and for your suggestion to ask Pieter Rein for an internship.</p>
<p>Thank you to my Mother, Manuela, for without you I would not have come so far. You have made the suggestion to go to the Netherlands for a year (even though it now turns out it will be more). And thank you to my girlfriend, Victoria. Your love, support, understanding, compassion, cheerfulness and kindness are almost infinite. Thank you so much.</p>
</section>
<section id="introduction" class="level1" data-number="1">
<h1 data-number="2"><span class="header-section-number">2</span> Introduction</h1>
<p><em>Noise</em> is inherent across diverse biological systems and remains relevant at all biological scales. From <em>stochastic gene expression</em> and random <em>action potential spikes</em> in neuronal networks at the cellular scale to the <em>development of multi-cellular organisms</em> all the way to the <em>variations in population level</em> of competing species in whole ecosystems, we find examples of processes which can only be described precisely by taking into account noise as an intrinsic feature <span class="citation" data-cites="2002.Elowitz 2008.Faisal 1990.Parsons 2011.Hallatschek 2014.Tsimring">[<a href="#ref-2002.Elowitz" role="doc-biblioref">1</a>–<a href="#ref-2014.Tsimring" role="doc-biblioref">5</a>]</span>. In this thesis we focus on the smaller end of this scale, namely on the stochastic description of <em>biochemical networks</em>. These comprise among others <em>gene expression</em>, <em>gene regulatory networks</em>, and <em>cell signaling</em> networks, all of which exhibit noise due to small copy numbers of their components. Additionally, since biological processes often happen out of equilibrium even macroscopic quantities can exhibit large fluctuations. The main source of noise at the cellular level may be fluctuations in <em>gene expression</em> which propagate to higher levels of biological organization <span class="citation" data-cites="2014.Tsimring">[<a href="#ref-2014.Tsimring" role="doc-biblioref">5</a>]</span>. The abundance of noise in all these systems leads to the question of how cells can reliably make correct decisions, even in complex and changing environments and how cells are able to <em>encode</em> the information about their environment using biochemical networks.</p>
<p>To successfully function, cells must generally correctly react to environmental changes. This requires processing the environmental cues they receive through their receptors and thereby filtering out the useful information from the noisy signal. The processing of information through biochemical networks can be quite elaborate with individual network components being able to perform analogous functions like silicon computational devices such as transistors <span class="citation" data-cites="2020.Leifer">[<a href="#ref-2020.Leifer" role="doc-biblioref">6</a>]</span>. It is thus tempting to think that optimization of information processing drives the evolution of cellular signaling networks. To understand information processing from the cell’s point of view we employ the very general framework of <em>information theory</em> which was originally developed to address questions of the reliability of telecommunications <span class="citation" data-cites="1948.Shannon">[<a href="#ref-1948.Shannon" role="doc-biblioref">7</a>]</span>.</p>
<p>In this thesis we study novel methods to understand information processing capabilities of biochemical networks from computational simulations. To this end we need to model the cell signaling network and the cellular environment using <em>stochastic differential equations</em> and simulate the biochemical network response to different stimuli. Using information theory we can analyze the results of these simulations and estimate abstract quantities like the amount of information that the biochemical networks processes on average.</p>

<section id="goal-of-the-thesis" class="level2" data-number="1.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Goal of the Thesis</h2>
<p>This thesis presents an overview over the work performed throughout a master’s project. Its aim was to design an algorithm for the computational estimation of information processing efficiency of biochemical signaling networks. Therefore, the first goal of the thesis is to introduce the reader to the stochastic description of biochemical networks with special a focus on information processing. We continue by presenting a Monte Carlo algorithm to compute the amount of information that a chemical network retains of a time-varying signal. As was discovered throughout the project, this algorithm in its simplest form cannot give accurate estimates of the amount of processed information. Consequently, this thesis intends to highlight the reasons for the algorithm’s problems, and we discuss ways to overcome them. Hence, while the solutions we formulate to fix the estimate certainly are very promising it has to be noted that this thesis represents work that is still in progress. Thus, a final goal of the present thesis is to give a perspective about future developments that will have to be done to complete the work presented here.</p>
</section>
<section id="structure-of-the-thesis" class="level2" data-number="1.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Structure of the Thesis</h2>
<p>We begin the second chapter by giving a general introduction into stochastic description of biochemical systems and the core concepts of information theory that we will make use of. From basic identities of probability theory we heuristically derive the chemical master equation and other important mathematical identities that will be used throughout the later chapters. Crucially, the last section of chapter 2 contains a detailed analysis of a simple biochemical network that will be the main object of study throughout the rest of the thesis. Therefore, the goal of the second chapter is to provide a useful overview of existing knowledge and setting the stage for the remaining chapters rather than providing novel results itself.</p>
<p>In the third chapter we then apply the main results from chapter 2 to develop a computational estimate of the information transmission performance for a large class of biochemical systems. We compare estimates done using this novel method with analytical results and find large discrepancies. After performing a detailed analysis we argue that the main issue is the computation of a high-dimensional integral in trajectory space.</p>
<p>Therefore, the fourth chapter completely focuses on efficient methods of computing such a high-dimensional integral. We will review different approaches found in the literature to numerically perform integrals. The most convincing methods originate from statistical physics. To be able to make use of these, we demonstrate that our integral can be re-cast in terms of the canonical ensemble such that we can make use of algorithms originally designed for statistical ensembles. While this work is not done yet, we will give some useful ideas that need to be explored to complete this work.</p>
<p>The thesis ends with a summary of the main results and a conclusion focusing on future work.</p>
</section>
</section>
<section id="modeling-cell-signaling-networks-as-information-processing-devices" class="level1" data-number="2">
<h1 data-number="3"><span class="header-section-number">3</span> Modeling Cell Signaling Networks as Information Processing Devices</h1>
<p>Information theory has been successfully used in biology to study cellular communication, embryonic development and other biological systems <span class="citation" data-cites="2009.Tkačik 2020.Uda">[<a href="#ref-2009.Tkačik" role="doc-biblioref">8</a>,<a href="#ref-2020.Uda" role="doc-biblioref">9</a>]</span>. Notably, there are many parallels between biological signal processing and <em>noisy channels</em> which are used for example to describe information transmission across a telephone line. Hence, a crucial feature of information theory is that its results are broadly applicable, irrespective of the nature of the communication channel or the medium used to transmit a signal. The communication channel merely describes any kind of abstract device that processes an <em>input</em> in a probabilistic way to yield a corresponding <em>output</em>. It turns out that the study of information transmission through such a channel is closely related to the study of noise since the amount of noise introduced by a communication channel sets an upper bound to the amount of data that can be transmitted through it, known as the <em>channel capacity</em> <span class="citation" data-cites="2006.Cover">[<a href="#ref-2006.Cover" role="doc-biblioref">10</a>]</span>. Consequently, the output can be described as a deterministic, lossless transformation of the input <em>plus</em> some random noise from the channel which leads to a loss of information. Note that in biological systems the signal itself is typically a fluctuating quantity such that the noise in the output is a combination of the channel noise and the intrinsic fluctuations of the signal. Since in cell signaling both, input and output are time-varying quantities we require a description of our system that allows for deterministic <em>and</em> stochastic time evolution.</p>
<p><em>Differential equations</em> are generally extremely useful to describe any kind of system that evolves deterministically. Therefore, it is natural to try to extend the framework of <em>ordinary differential equations</em> (ODEs) to also include the ability to describe the effects of noise. Historically, this approach to modeling stochastic dynamics has first been formulated heuristically by Langevin to describe <em>Brownian motion</em> <span class="citation" data-cites="1908.Langevin">[<a href="#ref-1908.Langevin" role="doc-biblioref">11</a>]</span>. Later the theory of <em>stochastic differential equations</em> (SDEs) was put on solid mathematical footing by Itô and Stratonovich through the development of <em>stochastic calculus</em> which has been successfully used for applications in physics, biology, economics and others <span class="citation" data-cites="2010.Kunita 1997.Bunkin">[<a href="#ref-2010.Kunita" role="doc-biblioref">12</a>,<a href="#ref-1997.Bunkin" role="doc-biblioref">13</a>]</span> [citation needed]. The solutions to SDEs are not ordinary functions like for ODEs but <em>stochastic processes</em> that describe the probabilities for the system to be in any state for every instant in time. Consequently, a stochastic process contains the probabilities for any possible individual sequence of states in time, i.e. the probabilities for individual <em>trajectories</em>. Since SDEs contain a complete account of noise in the system, information theoretic concepts like the <em>entropy</em> and the <em>mutual information</em>—which we are going to use to understand information transmission in cell signaling—can be applied to stochastic processes. While SDEs can be formulated to describe the evolution of biochemical networks in a discrete state space it is generally more useful to use a less general but simpler <em>chemical master equation</em> for these kinds of problems <span class="citation" data-cites="2009.Gardiner">[<a href="#ref-2009.Gardiner" role="doc-biblioref">14</a>]</span>.</p>
<p>The chemical master equation is a description of a subset of stochastic processes by deriving the <em>time-evolution</em> of the probability distribution over the discrete state space. I.e. instead of describing the stochastic change to an individual state at a given time it focuses on the <em>deterministic</em> evolution of the whole probability distribution over all states. Conveniently, for a given set of chemical reactions that form a reaction network, we can easily find the corresponding chemical master equation that describes the stochastic dynamics of this network given some assumptions of homogeneity. The stochastic process that emerges of this formulation describes the probabilities for the individual counts of all species and how these probabilities change with time. The ease with which the chemical master equation allows the construction of a stochastic process for any kind of biochemical network makes the idea very attractive to try to use <em>master equations</em> as the basis for information theoretic computations. If we can <em>solve</em> the master equation we in principle have access to all stochastic (and therefore information theoretic) properties of the corresponding biochemical network. E.g. in <span class="citation" data-cites="2010.Tostevin">[<a href="#ref-2010.Tostevin" role="doc-biblioref">15</a>]</span> it is shown how by analytically solving some very simple biochemical networks (using some approximations) it is possible to compute many quantities related to information transmission for time-varying signals and corresponding responses of these networks.</p>
<p>In most cases however, chemical master equations cannot be solved analytically and instead require computing averages for ensembles of <em>stochastic trajectories</em>. For instance, in Shannon’s information theory the amount of communicated information is not a function of individual signal-response pairs but an averaged quantity that depends on the probability of seeing <em>any</em> random signal-response-pair. Hence, computationally efficient generation of stochastic realizations for a given master equation is a central requirement for the exact computation of information processing in chemical networks. A very well known algorithm for the <em>exact</em> generation of trajectories from a given initial condition is the <em>stochastic simulation algorithm</em> (SSA) also known by the name of its inventor as the <em>Gillespie algorithm</em> <span class="citation" data-cites="1976.Gillespie">[<a href="#ref-1976.Gillespie" role="doc-biblioref">16</a>]</span>. The most widely used variant is the <em>direct Gillespie method</em> which works by alternatingly a) computing the time during which no reactions happen and b) choosing which of the available reactions to perform next. As a result we generate a list of times when some reaction happens and a corresponding list of reactions that specifies the exact trajectory that was generated. This algorithm works quite well in practice and is also used for the work presented in this thesis. It is still worth mentioning that for systems that evolve at different time scales simultaneously, the direct Gillespie method can be computationally inefficient since by its design it always operates at the smallest time scale. Therefore, there have been developed further trajectory-generation algorithms that can generate <em>approximately</em> correct trajectories by accumulating various reactions into a single time step such as the <span class="math inline">\tau</span>-leap method <span class="citation" data-cites="2001.Gillespie">[<a href="#ref-2001.Gillespie" role="doc-biblioref">17</a>]</span>.</p>
<p>In summary, there has been considerable effort to understand how cells receive, process and make use of information that their environments provide. A key aspect in this endeavor is the stochastic modeling of biological processes that take into account the natural fluctuations in these systems. In the following sections of this chapter we explain in more detail how we specifically model biochemical signaling networks in cells and how to understand information transmission in that context.</p>
<section id="information-theory-in-the-context-of-cellular-signaling-networks" class="level2" data-number="2.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Information Theory in the context of cellular signaling networks</h2>
<p>We begin by introducing information theoretic quantities like the <em>mutual information</em> and the <em>information rate</em> as relevant properties to understand optimality criteria for biochemical signaling networks.</p>
<section id="mutual-information-as-an-efficiency-measure-in-cell-signaling" class="level3" data-number="2.1.1">
<h3 data-number="3.1.1"><span class="header-section-number">3.1.1</span> Mutual Information as an Efficiency Measure in Cell signaling</h3>
<figure>
<img src="figures/information_cartoon.svg" id="fig:information_cartoon" alt="" /></img><figcaption>Figure 1: Abstracting cell signaling as an information channel. The channel’s input is an environmental signal that the cell needs to respond to. The signal processing happens through a biochemical network which “computes” a response which is the output of the information channel. The mutual information between signals and responses quantifies the cell’s ability to discern between different signals and choose appropriate responses.</figcaption>
</figure>
<p>In a general sense, cells sense chemical <em>signals</em> from their environment e.g. through receptors on their membrane. These signals provide the cell with important information e.g. about current environmental conditions, their position inside a structure or the location of food. To translate the signal into a useful response (such as expressing a certain gene or changing movement direction) cells have evolved biochemical signaling networks that recognize and process the signals. We use a general description of the cell that is depicted in fig. <a href="#fig:information_cartoon">1</a> where the signal acts as the input of the information channel. The processing of the signal that yields a response is assumed to be a known biochemical network and the response is one species of the biochemical network that acts as the “result” of the computation and represents the reaction of the cell to the signal.</p>
<p>For any given signal there are many stochastically possible responses. Conversely, for any given response there is a range of signals that could have produced it. Both of these statements of uncertainty can be quantified using a single concept: the <em>mutual information</em>. In information theoretic terms we quantify the <em>uncertainty</em> of a random variable <span class="math inline">\mathcal S</span> by the <em>entropy</em> <span id="eq:signal_entropy"><span class="math display">
\mathrm H(\mathcal S)=-\int\limits_{\sigma(\mathcal S)} 
\mathrm d\mathbf s\ \mathrm P(\mathbf s)\,\ln\mathrm P(\mathbf s)
\qquad(1)</span></span> where <span class="math inline">\sigma(\mathcal S)</span> is the set of possible realizations of <span class="math inline">\mathcal S</span> and we use <span class="math inline">\mathrm P(\mathbf s)</span> to denote the probability (density) of <span class="math inline">\mathbf s</span> with respect to the distribution of <span class="math inline">\mathcal S</span>. If <span class="math inline">\mathcal S</span> describes the signal then a large entropy signifies that there is a large range of possible signals that could be expected by the cell. Now given the response <span class="math inline">\mathbf x</span> to a signal <span class="math inline">\mathbf s</span>, we expect <span class="math inline">\mathbf x</span> to contain information about <span class="math inline">\mathbf s</span> such that the uncertainty about the signal is reduced. The conditional entropy <span class="math inline">\mathrm H(\mathcal S|\mathcal X)</span> denotes the <em>average</em> remaining uncertainty of a signal after observing the response, hence it reads <span id="eq:conditional_entropy"><span class="math display">
\mathrm H(\mathcal S|\mathcal X)=-
\int\limits_{\sigma(\mathcal X)} 
\mathrm d\mathbf x\ \mathrm P(\mathbf x)
\int\limits_{\sigma(\mathcal S)} 
\mathrm d\mathbf s\ \mathrm P(\mathbf s|\mathbf x)\ln\mathrm P(\mathbf s|\mathbf x) \,.
\qquad(2)</span></span> <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span> is the conditional distribution of the signals for a given response <span class="math inline">\mathbf x</span> which encodes the transmission characteristics of the communication channel. So we have eq. <a href="#eq:signal_entropy">1</a> which describes the distribution of signals and eq. <a href="#eq:conditional_entropy">2</a> which describes how information is processed. Combining eqns. <a href="#eq:signal_entropy">1</a>, <a href="#eq:conditional_entropy">2</a> we can express the <em>average</em> amount of information gained on the signal by observing the response <span id="eq:mi_form1"><span class="math display">
\mathrm I(\mathcal S,\mathcal X) = \mathrm H(\mathcal S) - \mathrm H(\mathcal S|\mathcal X) = 
\int\limits_{\sigma(\mathcal X)} 
\mathrm d\mathbf x\ \mathrm P(\mathbf x)
\int\limits_{\sigma(\mathcal S)} 
\mathrm d\mathbf s\ \mathrm P(\mathbf s|\mathbf x)
\ln \frac{\mathrm P(\mathbf s|\mathbf x)}{\mathrm P(\mathbf s)}
\qquad(3)</span></span> which is precisely the <em>mutual information between <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span></em>. It depends on both, characteristics of the communication channel and the statistics of the input signal. Notably the <span class="math inline">\mathrm I(\mathcal S,\mathcal X)</span> is symmetric under exchange of <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> such that we can express it as <span id="eq:mi_form2"><span class="math display">
\mathrm I(\mathcal S,\mathcal X) = \mathrm H(\mathcal X) - \mathrm H(\mathcal X|\mathcal S) = 
\int\limits_{\sigma(\mathcal S)} 
\mathrm d\mathbf s\ \mathrm P(\mathbf s)
\int\limits_{\sigma(\mathcal X)} 
\mathrm d\mathbf x\ \mathrm P(\mathbf x|\mathbf s)
\ln \frac{\mathrm P(\mathbf x|\mathbf s)}{\mathrm P(\mathbf x)}\,,
\qquad(4)</span></span> resulting in a more useful formula for the Monte-Carlo estimation of the MI. Therefore, on average, a response reduces the uncertainty about the signal by exactly the same amount that a signal reduces the uncertainty about the possible responses.</p>

</section>
<section id="information-transmission-for-time-varying-signals" class="level3" data-number="2.1.2">
<h3 data-number="3.1.2"><span class="header-section-number">3.1.2</span> Information Transmission for Time-Varying Signals</h3>
<p>Biochemical networks may store information about the signal in the time-dependency of the response, for example in cellular Ca<sup>2+</sup> signaling information seems to be encoded in the timing and duration of Calcium bursts <span class="citation" data-cites="2010.Tostevin 2008.Boulware 2020.Richards">[<a href="#ref-2010.Tostevin" role="doc-biblioref">15</a>,<a href="#ref-2008.Boulware" role="doc-biblioref">18</a>,<a href="#ref-2020.Richards" role="doc-biblioref">19</a>]</span>. For the case where the signal can be regarded as slowly changing with respect to the response, Cepeda-Humerez, et. al. propose a Monte-Carlo technique for the estimation of the MI that includes information that is stored in the full temporal dynamics of the response <span class="citation" data-cites="2019.Cepeda-Humerez">[<a href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">20</a>]</span>. As described in their work, that method is limited to situations that are well-described by a finite number of discrete signals.</p>
<p>Often however, biochemical networks not only respond to instantaneous signal levels but also to changes in the signal over time. [reference needed]. Therefore, we build on the technique in <span class="citation" data-cites="2019.Cepeda-Humerez">[<a href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">20</a>]</span> by extending it to allow for time-varying, stochastic signals as well. In this way we aim to find a novel way to compute the MI for time-varying signals <em>and</em> responses for general biochemical networks.</p>
<p>The study of time-varying quantities motivates the use of the <em>information rate</em> which is the asymptotic rate at which the MI between signal and response increases <span class="citation" data-cites="2010.Tostevin">[<a href="#ref-2010.Tostevin" role="doc-biblioref">15</a>]</span> <span id="eq:information_rate"><span class="math display">
\mathrm I_R = \lim\limits_{T\rightarrow\infty} \frac{\mathrm I(\mathcal S_T,\mathcal X_T)}{T}
\qquad(5)</span></span> where <span class="math inline">\mathcal S_T</span> and <span class="math inline">\mathcal X_T</span> are random variables over <em>trajectories</em> of length <span class="math inline">T</span>. By <em>trajectories</em> we denote an entire time-trace of the signal or response, instead of singular values at specific times. Since eq. <a href="#eq:information_rate">5</a> describes the information gained by the cell in a unit time interval it may be an important quantity for the cell to optimize for.</p>
<p>Hence, we find that the fundamental building block for the computation of the information rate at the cellular level is to estimate the mutual information between trajectories of finite length. In the remainder of this thesis, we describe methods to compute the mutual information between trajectories <span class="math inline">\mathcal S_T,\mathcal X_T</span> based on a stochastic model of the biochemical signaling network.</p>
</section>
</section>
<section id="stochastic-modeling-of-biochemical-networks" class="level2" data-number="2.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Stochastic Modeling of Biochemical Networks</h2>
<ul>
<li>There exist model-free methods to quantify the entropies associated with signals and responses</li>
<li>These can only yield an upper bound for the entropy</li>
<li>In practice, biochemical networks may operate far from that bound(?)</li>
</ul>
<section id="markov-processes" class="level3" data-number="2.2.1">
<h3 data-number="3.2.1"><span class="header-section-number">3.2.1</span> Markov Processes</h3>
<ul>
<li>memoryless</li>
</ul>
</section>
<section id="chemical-master-equation" class="level3" data-number="2.2.2">
<h3 data-number="3.2.2"><span class="header-section-number">3.2.2</span> Chemical Master Equation</h3>
<p>As a model for the biochemical processing that takes place inside a cell we suppose that all interactions can be described by a chemical networks composed of different molecular species and reactions between them. Such networks can be described by a <em>chemical master equation</em> which makes it possible to compute all the probabilities associated with the time-evolution of such a system.</p>
<p>For illustrative purposes, let’s consider a highly simplified model of gene expression consisting of two components and four reactions <span id="eq:reaction_network1"><span class="math display"> \begin{gathered}
\emptyset \xrightarrow{\kappa} S \xrightarrow{\lambda} \emptyset\\
S \xrightarrow{\rho} S + X\\
X \xrightarrow{\mu}\emptyset\,.
\end{gathered} \qquad(6)</span></span> Here <span class="math inline">S</span> and <span class="math inline">X</span> are arbitrary chemical species whose particle counts we want to describe stochastically. The constants <span class="math inline">\kappa, \lambda, \rho, \mu</span> determine the rates at which the individual reactions occur. Hence, for every signal particle there is a constant rate <span class="math inline">\rho</span> to be sensed by the cell which triggers the creation of an <span class="math inline">X</span>. Additionally, <span class="math inline">X</span> particles decays by themselves over time with a per-particle rate of <span class="math inline">\mu</span>. Assuming a well stirred system in thermal equilibrium, it can be shown that the probabilities for the individual reactions happening at least once in the time interval <span class="math inline">[t, t+\mathrm\delta t]</span> are <span id="eq:transition_probabilities"><span class="math display">
\begin{aligned}
p^{(\kappa)}_{[t, t+\mathrm\delta t]} = \kappa\delta t + \mathcal{O}(\delta t^2)\\
p^{(\lambda)}_{[t, t+\mathrm\delta t]}(s) = s\lambda\delta t + \mathcal{O}(\delta t^2)\\
p^{(\rho)}_{[t, t+\mathrm\delta t]}(s) = s\rho\delta t + \mathcal{O}(\delta t^2)\\
p^{(\mu)}_{[t, t+\mathrm\delta t]}(x) = x\mu\delta t + \mathcal{O}(\delta t^2)
\end{aligned}
\qquad(7)</span></span> where <span class="math inline">s</span> and <span class="math inline">x</span> denote the particle numbers of the respective species at time <span class="math inline">t</span>. Consequently, the probability for <em>any</em> of the reactions to occur at least once in the time interval <span class="math inline">[t, t+\mathrm\delta t]</span> is <span id="eq:exit_probability"><span class="math display">p_{[t, t+\mathrm\delta t]}(s, x) = (\kappa + s\lambda + s\rho + x\mu)\ \mathrm \delta t + \mathcal{O}(\delta t^2)\qquad(8)</span></span></p>
<p>Using these expressions we can write down the so-called <em>chemical master equation</em> for this network. Let <span class="math inline">\mathrm P_{s,x}(t)</span> be the probability that the system is in state <span class="math inline">(s, x)</span> at time <span class="math inline">t</span>. Assuming that at most one reaction happens in the small time-interval <span class="math inline">[t, t+\delta t]</span> we can use the transition probabilities from eqns. <a href="#eq:transition_probabilities">7</a>, <a href="#eq:exit_probability">8</a> to write <span><span class="math display">
\begin{aligned}
\mathrm P_{s,x}(t + \delta t) = \phantom{+}p^{(\kappa)}_{[t, t+\mathrm\delta t]}\ \mathrm P_{s-1,x}(t)\\ +
p^{(\lambda)}_{[t, t+\mathrm\delta t]}(s + 1)\ \mathrm P_{s+1,x}(t)\\ +
p^{(\rho)}_{[t, t+\mathrm\delta t]}(s)\ \mathrm P_{s,x-1}(t)\\ +
p^{(\mu)}_{[t, t+\mathrm\delta t]}(x + 1)\ \mathrm P_{s, x + 1}(t)\\ + 
\left[1 - p_{[t, t+\mathrm\delta t]}(s, x)\right]\ \mathrm P_{s,x}(t)
\end{aligned}
\qquad(9)</span></span> and by taking the limit <span class="math inline">\delta t\rightarrow 0</span> we arrive at the chemical master equation <span id="eq:chemical_master_equation"><span class="math display">
\begin{aligned}
\frac{\partial \mathrm P_{s,x}(t)}{\partial t} = \lim\limits_{\delta t\rightarrow 0} \frac{\mathrm P_{s,x}(t + \delta t) -  \mathrm P_{s,x}(t)}{\delta t}\\
= \kappa\ \mathrm P_{s-1,x}(t) +
(s+1)\lambda\ \mathrm P_{s+1,x}(t) +
s\rho\ \mathrm P_{s,x-1}(t) +
(x+1)\mu\ \mathrm P_{s, x + 1}(t)\\ \phantom{=} - 
(\kappa + s\lambda + s\rho + x\mu)\ \mathrm P_{s,x}(t)
\end{aligned}
\qquad(10)</span></span> In an analogous way a chemical master equation can be derived for any biochemical network <span class="citation" data-cites="2009.Gardiner">[<a href="#ref-2009.Gardiner" role="doc-biblioref">14</a>]</span> and thus forms the basis for our further computations. Stochastic processes that can be described by a master equation are generally called <em>jump processes</em> and provide a useful abstraction for the processes that we want to consider.</p>
</section>
<section id="jump-processes" class="level3" data-number="2.2.3">
<h3 data-number="3.2.3"><span class="header-section-number">3.2.3</span> Jump Processes</h3>
<p>Since particle counts can’t ever become negative, eq. <a href="#eq:chemical_master_equation">10</a> describes a Markov process in continuous time with the state space <span class="math inline">\{(s, x) | s\in\mathbb{N}_0, x\in\mathbb{N}_0\}</span>. In general, every continuous-time Markov process with a discrete state space obeys a master equation. Such processes are also commonly called <em>jump processes</em> since they generate discontinuous sample paths <span class="citation" data-cites="2017.Weber">[<a href="#ref-2017.Weber" role="doc-biblioref">21</a>]</span>.</p>
<p>A jump process with state space <span class="math inline">\mathcal{U}</span> and an initial state <span class="math inline">\mathbf{x}_0\in\mathcal{U}</span> at time <span class="math inline">t_0</span> generates trajectories that can be described by a sequence of pairs <span class="math inline">(\mathbf{x}_i, t_i)_{i=1,2,\ldots}</span> where at every <em>transition time</em> <span class="math inline">t_i</span> there occurs a jump in state space <span class="math inline">\mathbf{x}_{i-1}\rightarrow \mathbf{x}_{i}</span>. As illustrated in eq. <a href="#eq:chemical_master_equation">10</a> the master equation encodes the transition rates for all possible state changes in the system. Similarly, for an arbitrary jump process we can formulate the master equation <span id="eq:general_master_eq"><span class="math display">
\frac{\partial \mathrm P(\mathbf x, t|\mathbf x_0, t_0)}{\partial t} = \sum\limits_{\mathbf x^\prime\in\mathcal U} \left[
w_t(\mathbf x, \mathbf x^\prime)\ \mathrm P(\mathbf x^\prime, t|\mathbf x_0, t_0)
- w_t(\mathbf x^\prime, \mathbf x)\ \mathrm P(\mathbf x, t|\mathbf x_0, t_0)
\right]
\qquad(11)</span></span> where <span class="math inline">w_t(\mathbf x^\prime, \mathbf x)</span> specifies the rate for the transition <span class="math inline">\mathbf x \rightarrow \mathbf x^\prime</span> at time <span class="math inline">t</span> and <span class="math inline">w_t(\mathbf x, \mathbf x) = 0</span>. The first term of the sum in eq. <a href="#eq:general_master_eq">11</a> is known as the <em>gain</em> since it describes how probability flows from other states into the current one while the second term is called <em>loss</em> as it expresses how much probability flows away from the current state. This form of the master equation allows us to find a relatively simple expression for the probability of individual trajectories of jump processes.</p>
</section>
<section id="probability-densities-of-trajectories" class="level3" data-number="2.2.4">
<h3 data-number="3.2.4"><span class="header-section-number">3.2.4</span> Probability Densities of Trajectories</h3>
<p>From eqns. <a href="#eq:mi_form1">3</a>, <a href="#eq:mi_form2">4</a> we can see immediately that the computation of the mutual information between two random variables relies on the calculation of (conditional) probability densities for these variables. Our interest in this thesis lies in the computation of the mutual information for time-varying signals and responses. Hence, we need to evaluate the mutual information between random variables whose individual samples are <em>entire trajectories</em>. To do this we require the notion of probability for a given trajectory, based on a given biochemical model for a cell. In the following derivation we show how the master equation as formulated in eq. <a href="#eq:general_master_eq">11</a> makes it possible to compute the trajectory probability exactly for the corresponding reaction network. In the next chapter we will then discuss how to use these results in practice to compute the conditional probability of a response <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> for a biochemical network and a known signal.</p>
<p>By the probability of a trajectory with <span class="math inline">N</span> jumps we denote joint probability density <span class="math inline">\mathrm P(\mathbf x_0, t_0;\ldots;\mathbf x_N,t_N)</span>. We include the initial state <span class="math inline">\mathbf x_0, t_0</span> in the probability since the initial condition itself is usually given by a probability distribution. Using conditional probabilities we can write <span id="eq:trajectory_probability"><span class="math display">
\begin{aligned}
\mathrm P(\mathbf x_0, t_0;\ldots;\mathbf x_N,t_N) =\; \mathrm P(\mathbf x_0,t_0)\,\mathrm P(\mathbf x_1,t_1|\mathbf x_0,t_0)\,\mathrm P(\mathbf x_2,t_2|\mathbf x_1,t_1;\mathbf x_0,t_0)\cdots\\
\mathrm P(\mathbf x_N,t_N|\mathbf x_{N-1},t_{N-1};\ldots;\mathbf x_0,t_0)\,.
\end{aligned}
\qquad(12)</span></span> We can make use of the fact that jump processes are Markov processes to simplify eq. <a href="#eq:trajectory_probability">12</a> such that every conditional probability only explicitly depends on the immediately preceding state <span id="eq:trajectory_probability_product"><span class="math display">
\begin{aligned}
\mathrm P(\mathbf x_0, t_0;\ldots;\mathbf x_N,t_N) = \mathrm P(\mathbf x_0,t_0)\,\mathrm P(\mathbf x_1,t_1|\mathbf x_0,t_0)\,\mathrm P(\mathbf x_2,t_2|\mathbf x_1,t_1)\cdots \mathrm P(\mathbf x_N,t_N|\mathbf x_{N-1},t_{N-1})\\
= \mathrm P(\mathbf x_0,t_0)\,\prod\limits^{N}_{i=1} \mathrm P(\mathbf x_i,t_i|\mathbf x_{i-1},t_{i-1})
\,.
\end{aligned}
\qquad(13)</span></span> Hence the expression for the probability of a trajectory contains two distinct kinds of probability distributions, a) the probability of the initial condition <span class="math inline">\mathrm P(\mathbf x_0,t_0)</span> and b) the transition probabilities for every step in the trajectory given by <span class="math inline">\mathrm P(\mathbf x_i,t_i|\mathbf x_{i-1},t_{i-1})</span>. The initial condition <span class="math inline">\mathrm P(\mathbf x_0,t_0)</span> depends on the specific problem and will often be taken to be the steady-state distribution. For the transition probabilities however, we can find a simple expression in terms of the master equation.</p>
<p>The transition probability <span class="math inline">\mathrm P(\mathbf x_i,t_i|\mathbf x_{i-1},t_{i-1})</span> describes the probability for a small segment of the trajectory from <span class="math inline">t_{i-1}</span> to <span class="math inline">t_i</span> where first, the system is at state <span class="math inline">\mathbf x_{i-1}</span> for a duration <span class="math inline">t_i - t_{i-1}</span> and then makes a jump <span class="math inline">\mathbf x_{i-1}\rightarrow \mathbf x_{i}</span>. We are now going to derive how to express the probabilities of the constant part as well as the probability of the jump using only terms from the master equation given in eq. <a href="#eq:general_master_eq">11</a>. At the start of the segment, the probability for there to be no jump until at least <span class="math inline">t  t_{i-1}</span> is called the <em>survival probability</em> <span class="math inline">S(\mathbf x_{i-1}, t_{i-1}, t)</span>. By noticing that the change in the survival probability is given by the <em>loss</em> term of the master equation <span><span class="math display">
S(\mathbf x_{i-1}, t_{i-1}, t+\delta t) = S(\mathbf x_{i-1}, t_{i-1}, t) \left[ 1-\delta t
\sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t_{i-1}}(\mathbf x^\prime, \mathbf x_{i-1}) + \mathcal O(\delta t^2) \right]
\qquad(14)</span></span> we can motivate the differential equation <span><span class="math display">
\frac{\partial S(\mathbf x_{i-1}, t_{i-1}, t)}{\partial t} = - S(\mathbf x_{i-1}, t_{i-1}, t) \sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t_{i-1}}(\mathbf x^\prime, \mathbf x_{i-1})
\qquad(15)</span></span> with the solution <span id="eq:survival_probability"><span class="math display">
S(\mathbf x_{i-1}, t_{i-1}, t) = \exp\left( -\int\limits^{t}_{t_{i-1}}\mathrm dt^\prime 
\sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t^\prime}(\mathbf x^\prime, \mathbf x_{i-1})
\right)\,.
\qquad(16)</span></span> The expression <span class="math inline">S(\mathbf x_{i-1}, t_{i-1}, t)</span> is the probability for no reaction happening from time <span class="math inline">t_{i-1}</span> until <em>at least</em> <span class="math inline">t</span>. The survival probability therefore is the cumulative probability distribution for the <em>waiting time</em> <span class="math inline">\tau_{i-1} = t - t_{i-1}</span>, i.e. using standard notation we can write <span class="math inline">\mathrm P(\tau_{i-1} \geq \delta) = S(\mathbf x_{i-1}, t_{i-1}, t_{i-1}+\delta)</span>. Since the probability for the waiting time to be <em>exactly</em> <span class="math inline">\tau_{i-1}=t_i-t_{i-1}</span> is <em>zero</em> we instead compute the probability density <span id="eq:survival_probability_density"><span class="math display">\mathrm P(\tau_{i-1} = t_i-t_{i-1}) =
\left. 
\frac{\partial\mathrm P(\tau_{i-1}  \delta)}{\partial\delta} 
\right|_{\delta = t_i-t_{i-1}} = 
\left. 
\frac{\partial [1 - S(\mathbf x_{i-1}, t_{i-1}, t_{i-1} + \delta)]}{\partial\delta}
\right|_{\delta = t_i-t_{i-1}}\,.
\qquad(17)</span></span></p>
<p>The jump <span class="math inline">\mathbf x_{i-1}\rightarrow \mathbf x_{i}</span> at time <span class="math inline">t_i</span> itself happens with probability <span id="eq:jump_probability"><span class="math display">\mathrm P(\mathbf x_{i-1}\rightarrow \mathbf x_{i}, t_i) = \frac{w_t(\mathbf x_{i}, \mathbf x_{i-1})}{\sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t}(\mathbf x^\prime, \mathbf x_{i-1})}\,.\qquad(18)</span></span> Combining the jump probability with the survival probability we can thus express the transition probability density by the multiplication <span><span class="math display">
\mathrm P(\mathbf x_i,t_i|\mathbf x_{i-1},t_{i-1}) = 
\mathrm P(\tau_{i-1} = t_i-t_{i-1})\;
\mathrm P(\mathbf x_{i-1}\rightarrow \mathbf x_{i}, t_i)
\qquad(19)</span></span> and by inserting the results from eqns. <a href="#eq:survival_probability">16</a>-<a href="#eq:jump_probability">18</a> we arrive at the expression <span id="eq:transition_probability"><span class="math display">
\mathrm P(\mathbf x_i,t_i|\mathbf x_{i-1},t_{i-1}) = w_t(\mathbf x_{i}, \mathbf x_{i-1})
\exp\left( -\int\limits^{t_i}_{t_{i-1}}\mathrm dt^\prime 
\sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t^\prime}(\mathbf x^\prime, \mathbf x_{i-1})
\right)
\,.
\qquad(20)</span></span></p>
<p>Therefore eq. <a href="#eq:transition_probability">20</a> plugged into eq. <a href="#eq:trajectory_probability_product">13</a> allows the exact computation of probability densities for arbitrary stochastic trajectories. The results were derived in enough generality such that time-dependent transition rates are explicitly allowed. We will see that the analytical expression for the probability of a stochastic trajectory is central for the estimation of the mutual information throughout this thesis. Eqns. <a href="#eq:trajectory_probability_product">13</a>, <a href="#eq:transition_probability">20</a> will be used to compute the conditional probability <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> for stochastically generated signal and response trajectories <span class="math inline">\mathbf s</span> and <span class="math inline">\mathbf x</span>. Furthermore, the survival probability and the jump probability introduced in this section form the basis of the <em>Stochastic Simulation Algorithm</em> that is introduced in the following subsection.</p>
</section>
<section id="sec:ssa" class="level3" data-number="2.2.5">
<h3 data-number="3.2.5"><span class="header-section-number">3.2.5</span> Generating Stochastic Trajectories for Jump Processes</h3>
<p>One main ingredient for a computational recipe to calculate the mutual information is the formula for the probability of a trajectory, as derived in the previous section. Of equal importance is the correct generation of stochastic realizations for the biochemical model we intend to study. So far we showed how to model any biochemical network as a <em>jump process</em> through the formulation of the chemical master equation. In the previous section we were able to derive an equation for the probability of a trajectory using only terms from the master equation. Similarly, we can formulate the <em>stochastic simulation algorithm</em> which efficiently generates trajectories for any jump process with a known master equation. In the following we explain the variant named <em>direct Gillespie alogithm</em> after its inventor <span class="citation" data-cites="1976.Gillespie">[<a href="#ref-1976.Gillespie" role="doc-biblioref">16</a>]</span>.</p>
<p>The direct Gillespie algorithm is an efficient and exact procedure to generate stochastic trajectories for jump processes. Starting from an initial state <span class="math inline">\mathbf x_0</span> at time <span class="math inline">t_0</span> it generates a trajectory <span class="math inline">\mathbf x = (\mathbf x_0, t_0;\ldots;\mathbf x_N, t_N)</span> that is a realization of the corresponding stochastic process. Since the trajectories of a jump process are constant segments, separated by discontinuous jumps, at every point in time the system either remains unchanged or it performs an instantaneous jump. Therefore the algorithm works in two phases that are repeated over and over until a trajectory of the desired length is generated.</p>
<p>In the first phase we compute the stochastic waiting time <span class="math inline">\tau</span> until the next <em>event</em> occurs. Given that we are currently at time <span class="math inline">t_{i-1}</span> and state <span class="math inline">\mathbf x_{i-1}</span>, the probability for the waiting time being <span class="math inline">\tau\geq t-t_{i-1}</span> is given by the survival probability from eq. <a href="#eq:survival_probability">16</a>. By the inverse function method we can generate a correctly distributed waiting time <span class="math inline">\tau</span> using a random variate <span class="math inline">u</span> that is uniformly distributed between 0 and 1 and then solving the equation <span id="eq:inverse_function_method"><span class="math display">
u = 1-\exp\left( -\int\limits^{t_{i-1} + \tau}_{t_{i-1}}\mathrm dt^\prime 
\sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t^\prime}(\mathbf x^\prime, \mathbf x_{i-1}) \right)
\qquad(21)</span></span> for <span class="math inline">\tau</span>. We then set <span class="math inline">t_i = t_{i-1} + \tau</span>. For general transition rates <span class="math inline">w_{t^\prime}</span> eq. <a href="#eq:inverse_function_method">21</a> will have no analytical solution and it may be necessary to use approximate numerical integration techniques to solve for <span class="math inline">\tau</span>. If however the transition rates are time-independent for a given state we find the simple solution <span><span class="math display">
\tau = -\frac{\ln(1-u)}{\sum\limits_{\mathbf x^\prime\in\mathcal U} w_{t_{i-1}}(\mathbf x^\prime, \mathbf x_{i-1})}\,.
\qquad(22)</span></span></p>
<p>After the first phase we already know the time of the next event. Therefore all that remains to do is to decide which reaction should happen. The probability for the individual jumps is given by eq. <a href="#eq:jump_probability">18</a> and thus we can make a weighted choice between all reactions according to their probabilities. Using this choice we have found the next state <span class="math inline">\mathbf x_i</span> and we have finished one step in the stochastic simulation.</p>
<p>Using both of</p>

</section>
</section>
<section id="sec:simple_model" class="level2" data-number="2.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> A Simple Model of Gene Expression</h2>
<p>In the course of this thesis we explore computational methods for the estimation of the mutual information in cellular reaction networks. To test and analyze our algorithms we perform computations for a very simple biochemical network for gene expression, consisting in merely four reactions and two species. It represents one of the simplest possible problems that a Monte-Carlo approach should be able to solve. Consequently, an estimation procedure that fails even on this simple model will almost certainly not provide satisfactory results for more realistic and complex networks. So on one hand we use a very simple biochemical network as a minimal system that an algorithm must be able to solve. On the other hand this model for gene expression has already been studied from an information theoretical point of view. Its simple structure allowed Tostevin, et. al. <span class="citation" data-cites="2010.Tostevin">[<a href="#ref-2010.Tostevin" role="doc-biblioref">15</a>]</span> to derive precise analytical approximations for the mutual information that we can use to test the results of our computational estimates against. In the following we describe the biochemical network and derive some useful analytical results.</p>
<p>We begin by specifying the 4 reactions that make up a simple model for gene expression <span id="eq:simple_reaction_network"><span class="math display">
\begin{gathered}
\emptyset \xrightarrow{\kappa} S \xrightarrow{\lambda} \emptyset\\
S \xrightarrow{\rho} S + X\\
X \xrightarrow{\mu}\emptyset
\end{gathered}
\qquad(23)</span></span> and note that it is the same network that was already used in eq. <a href="#eq:reaction_network1">6</a>. It includes two species, <span class="math inline">S</span> and <span class="math inline">X</span> that represent the signal and the response, respectively. The signal dynamics are fully described by the first two reactions, i.e. a birth-death process where signals are “born” stochastically with a constant rate <span class="math inline">\kappa</span> and every signal particle has a constant decay rate of <span class="math inline">\lambda</span>. The response dynamics are given by the other two reactions in eq. <a href="#eq:simple_reaction_network">23</a>. Each signal particle can stochastically produce a response with rate <span class="math inline">\rho</span> and every response itself decays with rate <span class="math inline">\mu</span>. The stochastic process that corresponds to the full reaction network under well-mixed conditions is described by a chemical master equation that we anticipatingly already derived for this network in eq. <a href="#eq:chemical_master_equation">10</a>. While the stochastic formulation describes the full reaction dynamics (assuming the system is well-mixed) we can understand many of its properties from a deterministic description.</p>
<p>The average number of signal particles <span class="math inline">s(t)</span> is described by the deterministic rate equation <span id="eq:det_s"><span class="math display">
\partial_t s(t) = \kappa - \lambda\ s(t)\,.
\qquad(24)</span></span> This ODE has a fixed point that represents the steady-state average of the signal <span class="math inline">\bar s = \kappa / \lambda</span>. In a similar way we can deterministically describe the average number of response particles <span class="math inline">x(t)</span> using the ODE <span id="eq:det_x"><span class="math display">
\partial_t x(t) = \rho\ s(t) - \mu\ x(t)\,.
\qquad(25)</span></span> Analogous to the signal we have a steady state average for the response <span class="math inline">\bar x = \rho\bar s / \mu</span>. In this case, the deterministic equations are not only useful to derive steady-state averages but can also be used to understand <em>correlations</em> between the components of the system. If <span class="math inline">S_t</span> is the stochastic count of signal particles at time <span class="math inline">t</span> we call <span class="math inline">C_{ss}(t, t^\prime) = \langle S_t S_{t^\prime}\rangle</span> the <em>autocorrelation function</em> of <span class="math inline">\mathcal S</span>. Similarly we can also define correlation functions between the signal and the response, such as <span class="math inline">C_{sx}(t, t^\prime) = \langle S_t X_{t^\prime}\rangle</span>, where by <span class="math inline">X_t</span> we denote the stochastic number of X molecules at time <span class="math inline">t</span>. Thus, in total we have four different correlation functions <span class="math inline">C_{ss}, C_{sx}, C_{xs},</span> and <span class="math inline">C_{xx}</span>. If we assume the system is in steady state, the correlation functions do only depend on the time-difference <span class="math inline">t^\prime - t</span> such that we can write <span class="math inline">C_{\alpha\beta}(t, t^\prime) = C_{\alpha\beta}(t^\prime - t)</span> <span class="citation" data-cites="2009.Gardiner">[<a href="#ref-2009.Gardiner" role="doc-biblioref">14</a>]</span>. For simple biochemical networks like eq. <a href="#eq:simple_reaction_network">23</a> it is relatively straightforward to analytically derive the correlation functions for the steady state.</p>
<p>Since the deterministic eqns. <a href="#eq:det_s">24</a>, <a href="#eq:det_x">25</a> are both <em>first-order</em> ODEs we say that the biochemical system has <em>linear equations of motions</em> such that for some matrix <span class="math inline">A(t)</span> and vector <span class="math inline">\xi(t)</span> we can write <span><span class="math display">
\frac{\partial \mathbf z(t)}{\partial t} = A(t)\ \mathbf z(t) + \xi(t)
\qquad(26)</span></span> with <span class="math inline">\mathbf z(t) = (s(t),x(t))^T</span>. We say that the corresponding Markov process describes a <em>linear system</em>. In the following we make use of the fact that for linear systems we can apply the <em>regression theorem</em> <span class="citation" data-cites="2009.Gardiner">[<a href="#ref-2009.Gardiner" role="doc-biblioref">14</a>]</span> <span><span class="math display">\partial_tC_{ij}(t) = -\sum_k A_{ik}(t)C_{kj}(t)\qquad(27)</span></span> where <span class="math inline">C_{ij}</span> are the correlation functions. Specifically, for our biochemical network we find the following set of coupled differential equations for the correlation functions <span><span class="math display">
\begin{aligned}
\partial_t C_{ss}(t) = -\lambda\ C_{ss}(t) \\
\partial_t C_{sx}(t) = \rho\ C_{ss}(t)-\mu\ C_{sx}(t) \\
\partial_t C_{xs}(t) = -\lambda\ C_{xs}(t) \\
\partial_t C_{xx}(t) = \rho\ C_{xs}(t)-\mu\ C_{xx}(t)
\end{aligned}
\qquad(28)</span></span> with the solutions for <span class="math inline">t\geq0</span> (assuming steady-state initial conditions) <span id="eq:correlation_functions"><span class="math display">
\begin{aligned}
C_{ss}(t) = \frac\kappa\lambda e^{-\lambda t} \\
C_{sx}(t) = \frac{\rho\kappa}{\lambda(\lambda - \mu)} 
\left[ \left( 1 + \frac{\lambda - \mu}{\lambda + \mu} \right) e^{-\mu t} - e^{-\lambda t} \right] \\
C_{xs}(t) = \frac{\rho\kappa}{\lambda(\lambda + \mu)} e^{-\lambda t}  \\
C_{xx}(t) = \frac{\rho^2 \kappa}{\lambda(\lambda^2 - \mu^2)} \left( e^{-\mu t} - e^{-\lambda t} \right) + \left( 1 + \frac{\rho}{\lambda + \mu} \right) \frac{\rho \kappa}{\lambda \mu} e^{-\mu t}\,.
\end{aligned}
\qquad(29)</span></span> Since by definition <span class="math inline">C_{\alpha\beta}(-t) = C_{\beta\alpha}(t)</span>, from eq. <a href="#eq:correlation_functions">29</a> we know the complete correlation functions for the system in steady state. The correlation functions are plotted in fig. <a href="#fig:correlation">2</a> to visualize the system behavior.</p>
<figure>
<img src="figures/correlation.svg" id="fig:correlation" alt="" /></img><figcaption>Figure 2: Correlation functions for the steady state <span class="math inline">C_{\alpha\beta}</span> from eq. <a href="#eq:correlation_functions">29</a>, plotted as functions of time. They describe how the deviations from the mean correlate over time. The solid lines represent the autocorrelation functions whereas the dashed lines display correlations between the signal and response. The slight peak at <span class="math inline">t^\prime-t\approx70</span> of <span class="math inline">C_{sx}(t^\prime-t)=\langle S_t X_{t^\prime} \rangle</span> shows that the chemical interaction between <span class="math inline">S</span> and <span class="math inline">X</span> leads to positive correlations between them. For the reaction rates the values from tbl. <a href="#tbl:k">1</a> were used.</figcaption>
</figure>
<p>The steady-state averages and the correlation functions represent the first and second moments of the trajectories of <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span>. By discarding all higher-order moments and discretizing time we build an approximate stochastic model for the chemical reaction network that allows further analytic results. Since we will approximate the trajectories using samples form multivariate normal distributions, this method is often called the <em>Gaussian approximation</em>. For a given discretization <span class="math inline">t_1t_2\cdotst_d</span> we describe the signal and response trajectories as a vector of values at discrete sample times. For simplicity the values are taken to be deviations from the average e.g. we discretize a signal as <span class="math inline">\mathbf s = \left(s(t_1)-\bar{s},\ldots,s(t_d)-\bar{s}\right)^T</span>. In the following we define a multivariate probability density <span class="math inline">\mathrm P(\mathbf{s}, \mathbf{x})</span> for the signal and response trajectories such that the resulting approximate system has identical correlation functions to the full biochemical network.</p>
<p>Hence we consider the case where the joint probability distribution <span class="math inline">\mathrm P(\mathbf{s}, \mathbf{x})</span> is given by a multivariate normal distribution <span id="eq:joint_multivariate"><span class="math display">
\mathrm P(\mathbf{s}, \mathbf{x}) = \frac{1}{\sqrt{\left( 2\pi  \right)^{2d} \det Z}} \;\exp\left[-\frac12\ (\mathbf s^T\; \mathbf x^T)\ Z^{-1}\ \binom{\mathbf s}{\mathbf x}\right]
\qquad(30)</span></span> where <span class="math inline">\mathbf s, \mathbf x \in \mathbb R^d</span> are the signal and response vectors respectively. The symmetric positive-definite covariance matrix <span class="math inline">Z\in\mathbb R^{2d\times 2d}</span> has the block form <span id="eq:corr_z"><span class="math display">
Z =  \begin{pmatrix}
C_{ss}  C_{xs} \\
C_{sx}  C_{xx}
\end{pmatrix}
\qquad(31)</span></span> with matrices <span class="math inline">C_{\alpha\beta}\in\mathbb R^{d\times d}</span>. The correlation functions in eq. <a href="#eq:correlation_functions">29</a> then give us the elements of the matrix blocks <span id="eq:covariance_from_corr"><span class="math display">
(C_{\alpha\beta})_{ij} = C_{\alpha\beta}(t_j - t_i)\,.
\qquad(32)</span></span> For the joint distribution in eq. <a href="#eq:joint_multivariate">30</a> there exists a simple analytical expression to compute the mutual information between <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> <span class="citation" data-cites="2010.Tostevin 1948.Shannon">[<a href="#ref-1948.Shannon" role="doc-biblioref">7</a>,<a href="#ref-2010.Tostevin" role="doc-biblioref">15</a>]</span> <span id="eq:analytical_mi"><span class="math display">
\mathrm I(\mathcal S, \mathcal X) = \frac 12 \ln\left( \frac{\det C_{ss} \det C_{xx}}{\det Z} \right)
\qquad(33)</span></span> which will be our benchmark to compare the proposed Monte-Carlo estimation procedure against. In a similar way we can also acquire analytical equations for both the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> and the conditional entropy <span class="math inline">\mathrm H(\mathcal X | \mathcal S)</span>.</p>
<p>While we can use eq. <a href="#eq:analytical_mi">33</a> to directly evaluate the mutual information for trajectories using discretized time, Tostevin, et. al. <span class="citation" data-cites="2010.Tostevin">[<a href="#ref-2010.Tostevin" role="doc-biblioref">15</a>]</span> derive—specifically for this reaction network—a formula to analytically compute the mutual information rate (in nats per unit time) in the limit of infinitely fine discretization <span id="eq:analytical_rate"><span class="math display">
I_R = \frac{\lambda}{2}\left( \sqrt{1 + \frac{\rho}{\lambda}} -1 \right)\,.
\qquad(34)</span></span></p>
<p>In this subsection we analyzed a simple, yet non-trivial example of a biochemical network for which we intend to compute the mutual information using Monte-Carlo techniques. Since we were able to derive the correlation functions for this network, we can make use of the Gaussian approximation to estimate the mutual information using eq. <a href="#eq:analytical_mi">33</a>. That approximation will turn out to be very useful to understand the accuracy of Monte-Carlo estimates. To make the different results in this thesis comparable we used consistent parameter values for the reaction constants that are shown in tbl. <a href="#tbl:k">1</a>.</p>
<div id="tbl:k">
<table>
<caption>Table 1: Values of the reaction constants along with the steady-state averages, correlation times and approximate information rate from eq. <a href="#eq:analytical_rate">34</a>. The values for the reaction constants were used for all computations unless stated otherwise.</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\kappa</span></th>
<th style="text-align: center;"><span class="math inline">\lambda</span></th>
<th style="text-align: center;"><span class="math inline">\rho</span></th>
<th style="text-align: center;"><span class="math inline">\mu</span></th>
<th style="text-align: center;"><span class="math inline">\bar s</span></th>
<th style="text-align: center;"><span class="math inline">\bar x</span></th>
<th style="text-align: center;"><span class="math inline">\tau_s</span></th>
<th style="text-align: center;"><span class="math inline">\tau_x</span></th>
<th style="text-align: center;"><span class="math inline">I_R</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">200</td>
<td style="text-align: center;">180</td>
<td style="text-align: center;">0.00183</td>
</tr>
</tbody>
</table>
</div>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-2002.Elowitz">
<p>[1] M.B. Elowitz, A.J. Levine, E.D. Siggia, P.S. Swain, Stochastic Gene Expression in a Single Cell, Science. 297 (2002) 1183–1186. <a href="https://doi.org/10.1126/science.1070919">https://doi.org/10.1126/science.1070919</a>.</p>
</div>
<div id="ref-2008.Faisal">
<p>[2] A.A. Faisal, L.P.J. Selen, D.M. Wolpert, Noise in the nervous system, Nature Reviews Neuroscience. 9 (2008) 292–303. <a href="https://doi.org/10.1038/nrn2258">https://doi.org/10.1038/nrn2258</a>.</p>
</div>
<div id="ref-1990.Parsons">
<p>[3] P.A. Parsons, Fluctuating Asymmetry: An Epigenetic Measure of Stress, Biological Reviews. 65 (1990) 131–145. <a href="https://doi.org/10.1111/j.1469-185x.1990.tb01186.x">https://doi.org/10.1111/j.1469-185x.1990.tb01186.x</a>.</p>
</div>
<div id="ref-2011.Hallatschek">
<p>[4] O. Hallatschek, Noise Driven Evolutionary Waves, PLoS Computational Biology. 7 (2011) e1002005. <a href="https://doi.org/10.1371/journal.pcbi.1002005">https://doi.org/10.1371/journal.pcbi.1002005</a>.</p>
</div>
<div id="ref-2014.Tsimring">
<p>[5] L.S. Tsimring, Noise in biology, Reports on Progress in Physics. 77 (2014) 026601. <a href="https://doi.org/10.1088/0034-4885/77/2/026601">https://doi.org/10.1088/0034-4885/77/2/026601</a>.</p>
</div>
<div id="ref-2020.Leifer">
<p>[6] I. Leifer, F. Morone, S.D.S. Reis, J.S. Andrade, M. Sigman, H.A. Makse, Circuits with broken fibration symmetries perform core logic computations in biological networks, PLOS Computational Biology. 16 (2020) e1007776. <a href="https://doi.org/10.1371/journal.pcbi.1007776">https://doi.org/10.1371/journal.pcbi.1007776</a>.</p>
</div>
<div id="ref-1948.Shannon">
<p>[7] C.E. Shannon, A Mathematical Theory of Communication, Bell System Technical Journal. 27 (1948) 379–423. <a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x">https://doi.org/10.1002/j.1538-7305.1948.tb01338.x</a>.</p>
</div>
<div id="ref-2009.Tkačik">
<p>[8] G. Tkačik, A.M. Walczak, W. Bialek, Optimizing information flow in small genetic networks, Physical Review E. 80 (2009) 031920. <a href="https://doi.org/10.1103/physreve.80.031920">https://doi.org/10.1103/physreve.80.031920</a>.</p>
</div>
<div id="ref-2020.Uda">
<p>[9] S. Uda, Application of information theory in systems biology., Biophysical Reviews. 12 (2020) 377–384. <a href="https://doi.org/10.1007/s12551-020-00665-w">https://doi.org/10.1007/s12551-020-00665-w</a>.</p>
</div>
<div id="ref-2006.Cover">
<p>[10] T.M. Cover, J.A. Thomas, Elements of Information Theory, 2nd ed., John Wiley  Sons, 2006.</p>
</div>
<div id="ref-1908.Langevin">
<p>[11] P. Langevin, Sur la théorie du mouvement brownien, C. R. Acad. Sci. (1908) 530–533.</p>
</div>
<div id="ref-2010.Kunita">
<p>[12] H. Kunita, Itô’s stochastic calculus: Its surprising power for applications, Stochastic Processes and Their Applications. 120 (2010) 622–652. <a href="https://doi.org/10.1016/j.spa.2010.01.013">https://doi.org/10.1016/j.spa.2010.01.013</a>.</p>
</div>
<div id="ref-1997.Bunkin">
<p>[13] F.V. Bunkin, B.B. Kadomtsev, Y.L. Klimontovich, N.I. Koroteev, P.S. Landa, V.P. Maslov, Y.M. Romanovskii, In memory of Ruslan Leont’evich Stratonovich, Physics-Uspekhi. 40 (1997) 751–752. <a href="https://doi.org/10.1070/pu1997v040n07abeh000259">https://doi.org/10.1070/pu1997v040n07abeh000259</a>.</p>
</div>
<div id="ref-2009.Gardiner">
<p>[14] C. Gardiner, Stochastic Methods, 4th ed., Springer-Verlag, Berlin Heidelberg, 2009.</p>
</div>
<div id="ref-2010.Tostevin">
<p>[15] F. Tostevin, P.R. ten Wolde, Mutual information in time-varying biochemical systems, Physical Review E. 81 (2010) 061917. <a href="https://doi.org/10.1103/physreve.81.061917">https://doi.org/10.1103/physreve.81.061917</a>.</p>
</div>
<div id="ref-1976.Gillespie">
<p>[16] D.T. Gillespie, A general method for numerically simulating the stochastic time evolution of coupled chemical reactions, Journal of Computational Physics. 22 (1976) 403–434. <a href="https://doi.org/10.1016/0021-9991(76)90041-3">https://doi.org/10.1016/0021-9991(76)90041-3</a>.</p>
</div>
<div id="ref-2001.Gillespie">
<p>[17] D.T. Gillespie, Approximate accelerated stochastic simulation of chemically reacting systems, The Journal of Chemical Physics. 115 (2001) 1716–1733. <a href="https://doi.org/10.1063/1.1378322">https://doi.org/10.1063/1.1378322</a>.</p>
</div>
<div id="ref-2008.Boulware">
<p>[18] M.J. Boulware, J.S. Marchant, Timing in Cellular Ca2+ Signaling, Current Biology. 18 (2008) R769–R776. <a href="https://doi.org/10.1016/j.cub.2008.07.018">https://doi.org/10.1016/j.cub.2008.07.018</a>.</p>
</div>
<div id="ref-2020.Richards">
<p>[19] D.M. Richards, J.J. Walker, J. Tabak, Ion channel noise shapes the electrical activity of endocrine cells, PLOS Computational Biology. 16 (2020) e1007769. <a href="https://doi.org/10.1371/journal.pcbi.1007769">https://doi.org/10.1371/journal.pcbi.1007769</a>.</p>
</div>
<div id="ref-2019.Cepeda-Humerez">
<p>[20] S.A. Cepeda-Humerez, J. Ruess, G. Tkačik, Estimating information in time-varying signals., PLoS Computational Biology. 15 (2019) e1007290. <a href="https://doi.org/10.1371/journal.pcbi.1007290">https://doi.org/10.1371/journal.pcbi.1007290</a>.</p>
</div>
<div id="ref-2017.Weber">
<p>[21] M.F. Weber, E. Frey, Master equations and the theory of stochastic path integrals, Reports on Progress in Physics. 80 (2017) 046601. <a href="https://doi.org/10.1088/1361-6633/aa5ae2">https://doi.org/10.1088/1361-6633/aa5ae2</a>.</p>
</div>
</div>
</section>
</section>
<section id="monte-carlo-estimate-of-the-mutual-information" class="level1" data-number="1">
<h1 data-number="3"><span class="header-section-number">3</span> Monte Carlo Estimate of the Mutual Information</h1>
<p>Equipped with analytical formulae for the computation of trajectory probabilities and with methods for efficient stochastic simulation, we can start to develop estimates for the mutual information. The basis for our method is eq. <strong>¿eq:mi_form2?</strong>; specifically we separate the mutual information into two parts that are computed independently, the <em>marginal entropy</em> <span class="math inline">\mathrm H(\mathcal X)</span> and the <em>conditional entropy</em> <span class="math inline">\mathrm H(\mathcal X|\mathcal S)</span>. Since signals and responses are time-varying, both entropies involve integrals over spaces of trajectories which are high-dimensional. At high dimensionality, direct numerical integration is not viable and instead, we use Monte-Carlo approaches based on random sampling of signals and responses.</p>
<p>While Monte-Carlo methods comprise a wide variety of approaches to stochastically evaluate integrals or sums the common idea is easily stated. We have a state space <span class="math inline">U</span> and a probability distribution <span class="math inline">p_U</span> on that state space. The problem is to numerically evaluate integrals of the form <span><span class="math display">
F = \langle f(u) \rangle = \int\limits_{U} \mathrm du\ p_U(u)\; f(u)
\qquad(1)</span></span> where <span class="math inline">f: U\rightarrow\mathbb R</span> is some function of interest. If <span class="math inline">U</span> is high-dimensional it is very time-consuming to estimate it by direct numerical integration. Instead, we generate random samples <span class="math inline">u_1,u_2,\ldots</span> from the probability distribution <span class="math inline">p_U</span> such that by the <em>law of large numbers</em> we have the equality <span id="eq:inf_mc_estimate"><span class="math display">
F = \lim_{N\rightarrow\infty} \frac{\sum^N_{i=1} f(u_i)}{N}
\qquad(2)</span></span> i.e. the sample average of random samples converges towards their mean. In practice, we can’t evaluate the limit in eq. <a href="#eq:inf_mc_estimate">2</a> and we approximate <span class="math inline">F</span> using a finite number <span class="math inline">N</span> of random samples <span><span class="math display">
\hat{F} = \frac{\sum^N_{i=1} f(u_i)}{N}\,.
\qquad(3)</span></span> The variance of Monte-Carlo estimates typically decreases much faster than TODO. Monte-Carlo methods depend on the efficient and correct sampling of the corresponding probability distribution. In this thesis …</p>
<p>In this chapter we will show how to use Monte-Carlo integration to compute the mutual information between stochastic trajectories. The computation requires the estimation of two quantities, marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> and the conditional entropy <span class="math inline">\mathrm H(\mathcal X|\mathcal S)</span>. We will show how to perform Monte-Carlo estimates for both entropies, however as we will describe the marginal entropy turns out to be computationally much more difficult to estimate. We conclude the chapter with a thorough analysis of the challenges that arise by …</p>
<section id="monte-carlo-estimate-for-the-marginal-entropy" class="level2" data-number="1.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Monte-Carlo Estimate for the Marginal Entropy</h2>
<p>We start by considering an abstract system, consisting of two random variables <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> representing the possible signals and responses, respectively. We will assume the availability of efficient computational methods to generate random samples from either of these random variables. Later in this chapter we will describe some methods for random sample generation. In this subsection we show how to use Monte-Carlo techniques to estimate the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> while in the following subsection we describe a similar method to estimate the conditional entropy <span class="math inline">\mathrm H(\mathcal X|\mathcal S)</span>.</p>
<p>We intend to compute the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> using Monte-Carlo (MC) sampling to evaluate the necessary integrals. First, given a number of random samples <span class="math inline">(\mathbf x_i)_{i=1,\ldots,N_x}</span> taken from <span class="math inline">\mathcal X</span> we propose as an estimate for the entropy <span id="eq:mc_entropy"><span class="math display">
\mathrm H(\mathcal X) = -\int\mathrm d\mathbf x\ \mathrm P(\mathbf x)\ln \mathrm P(\mathbf x) \approx - \frac{\sum\limits_{i=1}^{N_x} \ln\mathrm P(\mathbf x_i)}{N_x} \,.
\qquad(4)</span></span> I.e. using numerous response samples, we compute the sample average of their individual log-probabilities <span class="math inline">\ln\mathrm P(\mathbf x_i)</span>. As explained in the following section, from a biochemical of a cell we are not able to directly compute <span class="math inline">\mathrm P(\mathbf x_i)</span>. We do however have an efficient way of <em>generating</em> the responses <span class="math inline">\mathbf x_1,\mathbf x_2,\ldots</span> using the stochastic simulation algorithm.</p>
<p>Nonetheless, we see from eq. <a href="#eq:mc_entropy">4</a> that we <em>do</em> have to evaluate <span class="math inline">\mathrm P(\mathbf x_i)</span> for every generated sample. To solve this problem we choose to evaluate <span class="math inline">\mathrm P(\mathbf x_i)</span> by doing another nested Monte-Carlo integration using signal samples <span class="math inline">(\mathbf s_j)_{j=1,\ldots,N_s}</span> from <span class="math inline">\mathcal S</span> to write <span id="eq:mc_marginal"><span class="math display">
\mathrm P(\mathbf x_i) = \int\mathrm d\mathbf s\ \mathrm P(\mathbf s)\ \mathrm P(\mathbf x_i|\mathbf s) \approx \frac{\sum\limits_{j=1}^{N_s} \mathrm P(\mathbf x_i | \mathbf s_j)}{N_s} \,.
\qquad(5)</span></span> Hence, for every response sample <span class="math inline">\mathbf x_i</span> we have to perform a sample average over the conditional probabilities <span class="math inline">\mathrm P(\mathbf x_i|\mathbf s_j)</span>. Again, anticipating results from the following section, we make use of the fact that a stochastic model for a biochemical network allows us to efficiently compute <span class="math inline">\mathrm P(\mathbf x_i|\mathbf s_j)</span>. Therefore it seems viable to use eq. <a href="#eq:mc_marginal">5</a> to compute the marginal probability for a given response.</p>
<p>While for a low-dimensional signal space it is feasible to instead compute the marginalization integral eq. <a href="#eq:mc_marginal">5</a> using direct evaluation <span class="citation" data-cites="2019.Cepeda-Humerez">[<a href="#ref-2019.Cepeda-Humerez" role="doc-biblioref">1</a>]</span> we choose to use a nested MC simulation to also be able to handle high-dimensional signal spaces. This is crucial since time-varying signals are described by high-dimensional trajectories.</p>
<p>We can summarize the estimation procedure for the marginal entropy using the equation <span id="eq:mc_entropy_notation"><span class="math display">
\mathrm H(\mathcal X) = -\left\langle \ln \left\langle \mathrm P(\mathbf x | \mathbf s) \right\rangle_{\mathrm P(\mathbf s)} \right\rangle_{\mathrm P(\mathbf x)}
\qquad(6)</span></span> where we use the notation <span class="math inline">\langle f(x)\rangle_{g(x)}</span> for the expected value of <span class="math inline">f(x)</span> when <span class="math inline">x</span> is distributed according to the probability density given by <span class="math inline">g(x)</span>. Thus when thinking in mathematical terms we have the shorthand <span class="math inline">\langle f(x)\rangle_{g(x)} \equiv\int \mathrm dx\ g(x) f(x)</span>. We can also easily translate this notation into a Monte-Carlo estimate, i.e. <span class="math inline">\langle f(x)\rangle_{g(x)} = \lim\limits_{N\rightarrow\infty}\frac{\sum_{i=1}^N f(x_i)}{N}</span> where <span class="math inline">x_1, x_2,\ldots</span> are independent samples of the probability distribution given by <span class="math inline">g(x)</span>.</p>
</section>
<section id="estimating-the-conditional-entropy" class="level2" data-number="1.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Estimating the Conditional Entropy</h2>
<p>We can also estimate the <em>conditional entropy</em> using MC averages over trajectories. We express the conditional entropy using the notation introduced in eq. <a href="#eq:mc_entropy_notation">6</a> <span><span class="math display">
\mathrm H(\mathcal X|\mathcal S) = -\iint \mathrm d\mathbf s\mathrm d\mathbf x\ \mathrm P(\mathbf s)\mathrm P(\mathbf x | \mathbf s) \ln\mathrm P(\mathbf x|\mathbf s) = -\left\langle\langle\ln\mathrm P(\mathbf x | \mathbf s)\rangle_{\mathrm P(\mathbf x | \mathbf s)} \right\rangle_{\mathrm P(\mathbf s)}
\qquad(7)</span></span> to show that we require nested Monte Carlo integrations to evaluate the integral. We first generate signal samples <span class="math inline">\mathbf s_1, \ldots, \mathbf s_{N_s}</span> from the density <span class="math inline">\mathrm P(\mathbf s)</span>. Let <span class="math inline">\mathbf x_i^1,\ldots,\mathbf x_i^{N_x}</span> be response samples generated from <span class="math inline">\mathrm P(\mathbf x | \mathbf s_i)</span>. The Monte Carlo estimate for the conditional entropy then reads <span id="eq:conditional_entropy_estimate"><span class="math display">
\mathrm H(\mathcal X|\mathcal S) \approx - \frac1{N_s N_x} \sum\limits_{i=1}^{N_s} \sum\limits_{j=1}^{N_x} \ln\mathrm P(\mathbf x_i^j | \mathbf s_i)\,.
\qquad(8)</span></span></p>
<p>Using Monte-Carlo computations we can in principle compute the mutual information between arbitrary random variables.</p>
</section>
<section id="monte-carlo-simulations-for-trajectories" class="level2" data-number="1.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Monte-Carlo Simulations for Trajectories</h2>
<ul>
<li>Idea: Use SSA to generate response trajectories for given signals</li>
<li>The signals themselves are taken to be realizations of a given stochastic process</li>
<li>Using a set of predefined signals, we compute many responses</li>
<li>from a set of generated responses we can estimate the conditional entropy</li>
<li>and with some additional work the marginal entropy</li>
</ul>
<section id="general-stochastic-dynamics-of-signals" class="level3" data-number="1.3.1">
<h3 data-number="3.3.1"><span class="header-section-number">3.3.1</span> General Stochastic Dynamics of Signals</h3>
<p>In the previous section we found that both, the Monte-Carlo computation of the marginal entropy and of the conditional entropy require the generation of stochastic samples of the signal. This is not surprising since the stochastic dynamics of the signal reflect the amount of information that it contains. For example, if the signal is governed by mostly noise, then even the most efficient biochemical network could not extract a lot of meaningful information out of it. Therefore, to compute the mutual information between the signal and the responses, apart from modeling the biochemical network that processes the signal we also have to model the signal-generating process.</p>
<p>Generally, any kind of noisy signal can be modeled by a <em>stochastic process</em>. In many physically relevant cases, these processes arise as the solutions of SDEs that describe the underlying deterministic physics of the signal together with a <em>noise term</em> that gives rise to the stochastic nature of the signal trajectories. An example for such a process is the <em>Ornstein-Uhlenbeck process</em> that describes the random motion of a diffusing particle in a harmonic potential well <span class="citation" data-cites="2009.Gardiner">[<a href="#ref-2009.Gardiner" role="doc-biblioref">2</a>]</span>. It represents a combination of a deterministic harmonic oscillator together with fluctuations arising from the diffusion process. For the kinds of stochastic processes that are described by a SDE there exist many numerical methods to generate approximate signals trajectories. A simple, yet effective method to generate stochastic realizations of SDEs is the <em>Euler–Maruyama method</em> that is a generalization of the Euler method for integrating ODEs <span class="citation" data-cites="1992.Kloeden">[<a href="#ref-1992.Kloeden" role="doc-biblioref">3</a>]</span>. Using such methods we can in principle choose any integrable SDE as the signal-generating process for the computation of the mutual information.</p>
<p>If we want to investigate the simple reaction network for gene expression given in eq. <strong>¿eq:simple_reaction_network?</strong> we find that the signal dynamics are themselves described by a reaction network. In that case it is possible to generate <em>exact</em> stochastic realizations of signal trajectories using a stochastic simulation algorithm as discussed in sec. <strong>¿sec:ssa?</strong>.</p>
</section>
<section id="generating-responses-for-time-varying-signals" class="level3" data-number="1.3.2">
<h3 data-number="3.3.2"><span class="header-section-number">3.3.2</span> Generating Responses for Time-Varying Signals</h3>
<p>Both, the estimate for the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> and the estimate for the conditional entropy <span class="math inline">\mathrm H(\mathcal X|\mathcal S)</span> require the generation of appropriate responses to a given time-varying signal. To find stochastically correct responses for a given signal we have to understand how the biochemical network interacts with the signal. In many cases the signal itself is a molecular species that participates in the reaction network. In this scenario, an abundance of signal directly leads to an increased rate of all reactions in which the signal molecule acts as a reactant. In other cases the signal may be a thermodynamic quantity as for example the environmental temperature. Changes in temperature usually effect the rates of <em>all</em> reactions in a chemical reaction network. Thus, in general we think of a signal as a quantity whose value affects some or all of the reaction rates of the biochemical network at a given instant. Since we model the signal as a time-varying process, for a given realization of the signal we can describe the corresponding responses using a master equation with time-dependent reaction rates.</p>
<p>We describe the coupling of the biochemical network to the signal through an explicit dependence of the reaction rates from eq. <strong>¿eq:general_master_eq?</strong> on the signal level <span class="math inline">s(t)</span>. Thus we write the master equation for the responses as <span id="eq:general_master_eq2"><span class="math display">
\frac{\partial \mathrm P(x, t|x_0, t_0, \mathbf s)}{\partial t} = \sum\limits_{x^\prime\in\mathcal U} \left[
w_t(x, x^\prime, s(t))\ \mathrm P(x^\prime, t|x_0, t_0, \mathbf s)
- w_t(x^\prime, x, s(t))\ \mathrm P(x, t|x_0, t_0, \mathbf s)
\right]
\qquad(9)</span></span> which shows the explicit dependence of the stochastic dynamics on the given signal trajectory <span class="math inline">\mathbf s</span>. Since we assume that the reaction rates are the <em>only</em> way in which the signal trajectory affects the response we conclude that stochastic realizations of the process described by eq. <a href="#eq:general_master_eq2">9</a> are distributed according to the conditional distribution <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span>.</p>
<p>The formulation of the master equation with an explicit dependence on the signals makes it possible to perform the Monte-Carlo estimates as described above. Specifically, by making use of results derived in the previous chapter we can perform three crucial operations needed for the computational estimate of the mutual information.</p>
<section id="generation-of-response-trajectories-according-to-mathrm-pmathbf-xmathbf-s" class="level4" data-number="1.3.2.1">
<h4 data-number="3.3.2.1"><span class="header-section-number">3.3.2.1</span> Generation of response trajectories according to <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span></h4>
<p>As already described above, for any signal trajectory <span class="math inline">\mathbf s</span> we can formulate the master equation as written in eq. <a href="#eq:general_master_eq2">9</a> and use the stochastic simulation algorithm for time-dependent reaction rates to generate correctly distributed response trajectories.</p>
</section>
<section id="generation-of-response-trajectories-according-to-mathrm-pmathbf-x" class="level4" data-number="1.3.2.2">
<h4 data-number="3.3.2.2"><span class="header-section-number">3.3.2.2</span> Generation of response trajectories according to <span class="math inline">\mathrm P(\mathbf x)</span></h4>
<p>Similarly we can generate independent draws from the distribution <span class="math inline">\mathrm P(\mathbf x)</span> by first generating a stochastic realization <span class="math inline">\mathbf s</span> of the signal from the corresponding stochastic process and then generating exactly one response according to <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span>.</p>
</section>
<section id="compuation-of-mathrm-pmathbf-xmathbf-s" class="level4" data-number="1.3.2.3">
<h4 data-number="3.3.2.3"><span class="header-section-number">3.3.2.3</span> Compuation of <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span></h4>
<p>Finally, for any signal-response pair of trajectories, we can compute the conditional probability <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> using the formulae for the trajectory probability derived before in eqns. <strong>¿eq:trajectory_probability_product?</strong>, <strong>¿eq:transition_probability?</strong> and inserting the reaction rates for the given signal trajectory <span class="math inline">\mathbf s</span>.</p>
<ul>
<li>Note that the definition of the signal and responses as done in this section implies a strict separation of signal and response (make figure?). We will discuss this issue at the end of this thesis in section TODO</li>
</ul>

</section>
</section>
<section id="sec:initial_condition" class="level3" data-number="1.3.3">
<h3 data-number="3.3.3"><span class="header-section-number">3.3.3</span> Probability Distribution of the Initial State</h3>
<p>We have shown that we can use the stochastic simulation algorithm (SSA) to simulate response trajectories for a given signal. Note however, that the SSA needs us to specify the initial copy numbers of all species in the biochemical network. From this initial state we can then evolve the stochastic dynamics of the reactions in time. Hence, we have to think about the correct choice of the initial condition. In some cases it might be reasonable to have the same predefined initial condition for all responses that are simulated, e.g. in the beginning there is no response <span class="math inline">x(t_0) = 0</span>. In many cases however, the initial states <span class="math inline">x_0</span> will be distributed according to some probability density <span class="math inline">\mathrm P(x_0,t_0)</span>. A common example are systems that start out in a <em>steady state</em>, i.e. at <span class="math inline">t_0</span> both the signal and the response are distributed according to their joint stationary distribution <span class="math inline">p_{S,X}(s,x)</span>.</p>
<p>In that case, to set up the initial conditions correctly, we start by generating one signal trajectory whose initial point <span class="math inline">s_0</span> is drawn from the signal’s stationary distribution <span class="math inline">p_S(s_0)</span>. Thus, to ensure that the initial condition is drawn from <span class="math inline">p_{S,X}(s,x)</span>, we need to pick the initial condition of the response <span class="math inline">x_0</span> from the conditional distribution <span class="math inline">p_{X|S}(x_0|s_0)</span>. For our simulations, we estimate that conditional distribution in a separate computation for every signal that is generated.</p>
<p>If the signal dynamics in steady state are time-reversible, we can estimate the distribution function <span class="math inline">p_{X|S}(x_0|s_0)</span> for a given <span class="math inline">s_0</span> by generating time-reversed signal trajectories. The idea is to generate <span class="math inline">N_\text{past}</span> signal trajectories of duration <span class="math inline">t_\text{past}</span>, <em>backwards in time</em>, starting from <span class="math inline">s_0</span> at time <span class="math inline">t_0</span> that represent possible “pasts” of the system. For every such trajectory we then generate a response trajectory of the same duration <em>forward in time</em>. That is, the response starts at time <span class="math inline">t_0-t_\text{past}</span> with some arbitrary initial state <span class="math inline">x_\text{past}</span> and continues until time <span class="math inline">t_0</span>. Since we generate <span class="math inline">N_\text{past}</span> signals into the past, we end up with <span class="math inline">N_\text{past}</span> response trajectories, whose end points at <span class="math inline">t_0</span> are distributed according to <span class="math inline">p_{X|S}(x_0|s_0)</span>.</p>
<p>From these points <span class="math inline">x^{(1)}_0, \ldots, x^{(N_\text{past})}_0</span> we estimate the distribution function <span class="math inline">p_{X|S}(x_0|s_0)</span> using Gaussian kernel density estimation (KDE) <span class="citation" data-cites="1956.Rosenblatt 1962.Parzen">[<a href="#ref-1956.Rosenblatt" role="doc-biblioref">4</a>,<a href="#ref-1962.Parzen" role="doc-biblioref">5</a>]</span>. The KDE yields a smooth estimate of the conditional distribution <span class="math inline">p_{X|S}(x_0|s_0)</span> from the sample points. This estimated distribution is used in two different ways 1. TODO 2. TODO</p>
<p>In summary, as long as we can formulate a stochastic process that describes the signal dynamics <em>and</em> we understand how the signal level affects the reaction rates of the biochemical network, we can in principle use the Monte-Carlo procedure described in the previous section to estimate the mutual information. From the signal’s SDE we generate stochastic realizations using appropriate numerical integrators for SDEs such as the <em>Euler–Maruyama method</em> or the <em>stochastic simulation algorithm</em>. For every signal realization we have shown how to use the SSA to generate corresponding response trajectories. In the following section we will use these methods on a simple model of gene expression to see how the method is implemented in practice.</p>

</section>
</section>
<section id="returning-to-the-simple-model-of-gene-expression" class="level2" data-number="1.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span> Returning to the Simple Model of Gene Expression</h2>
<p>To evaluate the estimation procedure described so far in this chapter, we used it to compute the mutual information for the simple biochemical network introduced in sec. <strong>¿sec:simple_model?</strong>. As the initial condition we assumed that the system is in the steady state such that we were able to compare our Monte Carlo estimates with the analytical results from eq. <strong>¿eq:analytical_mi?</strong>. We generated all signals and responses using a stochastic simulation algorithm (SSA) for the reaction network in eq. <strong>¿eq:simple_reaction_network?</strong>. The reaction rates were chosen as specified in tbl. <strong>¿tbl:k?</strong> and the computed mutual information is always presented in units of <em>nats</em>, where <span class="math inline">1\ \text{nat} = (1/\ln 2)\, \text{bits}</span>.</p>
<section id="simulating-signals-and-responses" class="level3" data-number="1.4.1">
<h3 data-number="3.4.1"><span class="header-section-number">3.4.1</span> Simulating Signals and Responses</h3>
<p>In the model, the signal dynamics arise from the reactions <span class="math inline">\emptyset\xrightarrow{\kappa} S, S\xrightarrow{\lambda}\emptyset</span> that describe a simple birth-death process. Therefore, to generate signal trajectories we used the SSA with the initial copy numbers distributed according to the stationary distribution <span class="citation" data-cites="2009.Gardiner">[<a href="#ref-2009.Gardiner" role="doc-biblioref">2</a>]</span> <span><span class="math display">P_S(s_0) = e^{-\kappa/\lambda} \frac{(\kappa/\lambda)^{s_0}}{s_0!}\qquad(10)</span></span> for <span class="math inline">s_0\in\mathbb{N}_0</span>. The trajectories generated by the SSA consist of piecewise constant segments in between the transition times <span class="math inline">t_0\ldotst_{N}</span>. We can thus describe a trajectory <span class="math inline">\mathbf s</span> as a function <span class="math inline">s: [t_0, t_N]\rightarrow\mathbb{N}_0</span> given by <span id="eq:piecewise_const"><span class="math display">
s(t) = \sum^{N-1}_{i=0} s_i\ \theta(t-t_{i}) \theta(t_{i+1}-t) 
\qquad(11)</span></span> where <span class="math inline">s_1,\ldots,s_{N-1}</span> are the sequence of copy numbers of <span class="math inline">S</span> and <span class="math inline">\theta</span> is the Heaviside function. When we generate response trajectories corresponding to a given signal trajectory, the transition rate <span class="math inline">w_t(x+1, x)</span> for the reaction <span class="math inline">S\xrightarrow{\rho} S+X</span> is proportional to the function in eq. <a href="#eq:piecewise_const">11</a>, i.e.  <span id="eq:transition_rate"><span class="math display">w_t(x+1, x) = \rho\ s(t)\,.\qquad(12)</span></span> Eq. <a href="#eq:transition_rate">12</a> thus precisely specifies how a given signal trajectory interacts with the response. We use eqns. <strong>¿eq:inverse_function_method?</strong>, <a href="#eq:piecewise_const">11</a>, <a href="#eq:transition_rate">12</a> to compute the stochastic waiting times inside the SSA for the response trajectories.</p>
<p>To use the SSA for the generation of response trajectories, we need to solve eq. <strong>¿eq:inverse_function_method?</strong> which includes performing a time integral of the transition rates. The expression in eq. <a href="#eq:piecewise_const">11</a> allows us to integrate a signal trajectory with respect to time to arrive at <span id="eq:piecewise_linear"><span class="math display">
\int^t_{t_0} \mathrm d\tau\ s(\tau) = \sum^{N-1}_{i=0} s_i \left[ (t-t_i) \ \theta(t-t_i) - (t-t_{i+1}) \ \theta(t-t_{i+1}) \right]
\qquad(13)</span></span> which naturally is a piecewise linear function of <span class="math inline">t</span>. Using eq. <a href="#eq:piecewise_linear">13</a> it is then straightforward to solve eq. <strong>¿eq:inverse_function_method?</strong> for <span class="math inline">u</span> and use the SSA as described in sec. <strong>¿sec:ssa?</strong> to generate response trajectories. For response trajectories, we set the initial copy number <span class="math inline">x_0</span> of <span class="math inline">X</span> according to the empirically generated distribution <span class="math inline">\mathrm P(x_0|s_0)</span>.</p>
<p>Similarly, for the computation of the likelihood <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> we use eqns. <strong>¿eq:transition_probability?</strong>, <strong>¿eq:trajectory_probability_product?</strong> which also depend on time integrals of transition rates. Hence using the results in this section, we can generate stochastic realizations of signal trajectories and corresponding response trajectories. In other words, we can draw samples from the distributions <span class="math inline">\mathrm P(\mathbf s)</span> and <span class="math inline">\mathrm P(\mathbf x| \mathbf s)</span> which we will use to estimate the mutual information.</p>
</section>
<section id="consistent-bias-in-comparisons-with-analytic-approximations" class="level3" data-number="1.4.2">
<h3 data-number="3.4.2"><span class="header-section-number">3.4.2</span> Consistent Bias in Comparisons with Analytic Approximations</h3>
<p>The Monte Carlo estimate of the mutual information (MI) was performed using two independent computations, a) an average over the <em>likelihoods</em> <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> of random responses with respect to their corresponding signals in eq. <a href="#eq:conditional_entropy_estimate">8</a> that yields the conditional entropy and b) an average over the <em>marginal probability densities</em> <span class="math inline">\mathrm P(\mathbf x)</span> of sampled responses in eq. <a href="#eq:mc_entropy">4</a> for the marginal entropy. The difference of these two quantities is our estimate of the MI <span class="math inline">\mathrm I(\mathcal S, \mathcal X) = \mathrm H(\mathcal X) - \mathrm H(\mathcal X|\mathcal S)</span>.</p>
<p>It is crucial to note that the two independent computations involved in the MI are not of equal difficulty. The evaluation of <span class="math inline">\mathrm P(\mathbf x)</span> requires a nested Monte Carlo simulation eq. <a href="#eq:mc_marginal">5</a> for every generated response. The inner compuation of <span class="math inline">\mathrm P(\mathbf x)</span> can suffer especially high Monte Carlo variance since in eq. <a href="#eq:mc_marginal">5</a> the sampling distribution <span class="math inline">\mathrm P(\mathbf s)</span> may have only very little overlap with the integrand <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span>. Specifically, it might be the case that most of the generated signals <span class="math inline">\mathbf s_1,\ldots,\mathbf s_{N_S}\sim\mathrm P(\mathcal S)</span> contribute very weakly to the integral since their likelihoods <span class="math inline">\mathrm P(\mathbf x|\mathbf s_i)\approx 0</span> for almost all <span class="math inline">i</span>. Consequently, only a very small number of signals may actually determine the estimate of <span class="math inline">\mathrm P(\mathbf x)</span> which leads to a high variance of the estimate. In conclusion, we expect the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> to be more difficult to estimate than the conditional entropy <span class="math inline">\mathrm H(\mathcal X|\mathcal S)</span>. This expectation is confirmed by the results in this chapter.</p>
<p>In order to understand how the inner Monte Carlo compuation of <span class="math inline">\mathrm P(\mathbf x)</span> influences the estimate of the MI we performed an array of simulations with different values of <span class="math inline">N_S</span>. The number <span class="math inline">N_S</span> specifies how many signals we generate for every nested Monte Carlo computation of <span class="math inline">\mathrm P(\mathbf x)</span>. We expect that increasing <span class="math inline">N_S</span> leads to a better estimate of the marginal density for every response and therefore improves the estimate of the MI. We compare the simulation results with a reference value for the MI that was obtained by a Gaussian approximation. Using eq. <strong>¿eq:analytical_mi?</strong> we can analytically compute the MI <span class="math inline">\mathrm I(\mathcal S_T, \mathcal X_T)</span> between trajectories of duration <span class="math inline">T</span> and using eq. <strong>¿eq:analytical_rate?</strong> the information rate <span class="math inline">I_R</span> between <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span>. The analytically obtained values for the MI and the information rate are shown as red dotted lines in figs. <a href="#fig:a">1</a>, <a href="#fig:b">2</a>. From a single simulation of the MI with a trajectory duration of <span class="math inline">T_\text{max}</span> we can similarly compute the MI <span class="math inline">\mathrm I(\mathcal S_T, \mathcal X_T)</span> for any <span class="math inline">T\in[0, T_\text{max}]</span> by simply truncating all trajectories to duration <span class="math inline">T</span>. An estimate for the information rate can be obtained by approximating the limit in eq. <strong>¿eq:analytical_rate?</strong> <span><span class="math display">
\hat I_R = \frac{\mathrm I(\mathcal S_{T_\text{max}}, \mathcal X_{T_\text{max}})}{T_\text{max}}
\qquad(14)</span></span> assuming <span class="math inline">T_\text{max} \gg \tau</span> where <span class="math inline">\tau</span> is the longest timescale in the system.</p>
<figure>
<img src="figures/mutual_information_traj.svg" id="fig:a" alt="" /></img><figcaption>Figure 1: Estimates of the mutual information <span class="math inline">\mathrm I(\mathcal S_T, \mathcal X_T)</span> for varying trajectory duration <span class="math inline">T</span>. Every line shows an estimate of <span class="math inline">\mathrm I(\mathcal S_T, \mathcal X_T) = \mathrm H(\mathcal X_T) - \mathrm H(\mathcal X_T|\mathcal S_T)</span> where the marginal and the conditional entropy were computed in separate simulations. For the marginal entropy we generated <span class="math inline">2\times 10^5</span> independent responses per simulation and for every response <span class="math inline">\mathbf x</span> computed the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> using <span class="math inline">N_S</span> signal trajectories. Hence, this figure shows how the nested estimate of the marginal density influences the overall result. While increasing <span class="math inline">N_S</span> helps, all simulations consistently over-estimate the mutual information when compared to the analytic reference result computed using eq. <strong>¿eq:analytical_mi?</strong>. The estimation error appears to increase linearly with trajectory length and therefore leads to a biased estimate of the information rate. For the conditional entropy we generated <span class="math inline">2\times 10^5</span> signals trajectories and for every signal we generated <span class="math inline">10^3</span> response trajectories for the Monte Carlo average in eq. <a href="#eq:conditional_entropy_estimate">8</a>.</figcaption>
</figure>
<p>In fig. <a href="#fig:a">1</a> we show the the results of the different simulations to compute the MI between trajectories of varying durations <span class="math inline">T</span>. We start by describing the features that all simulations have in common. In all cases we see a linear increase of the mutual information with trajectory length. The linearity is to be expected for trajectory durations <span class="math inline">T\gg\tau</span> where <span class="math inline">\tau</span> is the correlation time of the system <span class="citation" data-cites="2010.Tostevin">[<a href="#ref-2010.Tostevin" role="doc-biblioref">6</a>]</span>. If the signal is much longer than the correlation time of the system it is impossible for any future response to still gain information about the beginning of the signal. Hence, for short trajectories, the increase in MI per unit time may be smaller than the asymptotic information rate since the signal has not yet reached the maximal integration length of the system. Thus, while there exist situations where for small <span class="math inline">T</span> the MI increases faster than linear, analytic computations using the Gaussian approximation confirm a fully linear increase of the MI from the start for the simple reaction network under consideration. In fig. <a href="#fig:a">1</a>, we show the result of eq. <strong>¿eq:analytical_mi?</strong> for the Gaussian approximation as the dotted “reference” line.</p>
<p>For trajectory length <span class="math inline">T = 0</span> fig. <a href="#fig:a">1</a> shows that all estimates—including the analytical result—coincide at a small non-zero value for their mutual information. This value is the mutual information between the initial conditions of the signal and the response. The agreement of all simulations shows that using the approach detailed in sec. <a href="#sec:initial_condition">1.3.3</a> we were able correctly estimate the conditional distribution <span class="math inline">\mathrm P(x_0|s_0)</span>. For every response needed during our simulations we first generated 1000 signals backwards in time for <span class="math inline">T_\text{past} = 500</span> to choose a correct starting point for the response and to correctly compute the likelihood <span class="math inline">\mathrm P(x_0|s_0)</span> of the initial condition.</p>
<figure>
<img src="figures/information_rate_traj.svg" id="fig:b" alt="" /></img><figcaption>Figure 2: Estimated information rate <span class="math inline">I_R=\mathrm I(\mathcal S_T, \mathcal X_T)/T</span> from the same data that was used in fig. <a href="#fig:a">1</a>. The reference line represents the analytical result <span class="math inline">I_R = 0.00183</span> from eq. <strong>¿eq:analytical_rate?</strong>. For a correct Monte Carlo simulation we expect the estimated information rate to converge towards the reference line as <span class="math inline">T\rightarrow\infty</span>. However, while we see that the estimates converge towards a stable value for large <span class="math inline">T</span>, all simulations considerably over-estimate the information rate. Even though for increasing <span class="math inline">N_S</span> the estimates <em>do</em> improve we can not acquire reasonable results for the simulations shown.</figcaption>
</figure>
<p>Thus, we see from fig. <a href="#fig:a">1</a> that the estimated MI grows linearly with <span class="math inline">T</span> and that all estimates agree on the MI for <span class="math inline">T=0</span>. However, we see that each of the MI curves has a different slope. All Monte Carlo simulations significantly over-estimate the slope of the analytical reference line. As <span class="math inline">N_S</span> increases we see a slight decrease of the MI slope, however even for largest simulation with <span class="math inline">N_S=1000</span> the slope differs by more than 50% from the analytical reference. Further increasing <span class="math inline">N_S</span> seems to yield diminishing returns. Hence, from the simulations we can’t seem to accurately compute the information rate since it strongly depends on estimating the MI slopes correctly.</p>
<p>Asymptotically for <span class="math inline">T\rightarrow\infty</span> the slope of the MI with respect to the trajectory duration <span class="math inline">T</span> converges towards the information rate <span class="math inline">I_R</span>. In fig. <a href="#fig:b">2</a> we see that all simulations show the convergence of the estimated information rate <span class="math inline">I_R\approx \mathrm I(\mathcal S_T, \mathcal X_T) / T</span> to a stable value already at <span class="math inline">T\approx 150</span>. We again find that we over-estimate the information rate for simulations with <span class="math inline">N_S\in\{10, 20, 50, 100, 200, 500, 1000\}</span> even though we see slight improvement for larger <span class="math inline">N_S</span>. We propose that even further increasing <span class="math inline">N_S</span> and thus spending more CPU time per simulation is not worthwhile to improve the estimates.</p>
<figure>
<img src="figures/information_rate_traj_long.svg" id="fig:c" alt="" /></img><figcaption>Figure 3: Estimated information rate <span class="math inline">I_R=\mathrm I(\mathcal S_T, \mathcal X_T)/T</span> for three estimate with very large <span class="math inline">N_S</span>. The reference line represents the analytical result <span class="math inline">I_R = 0.00183</span> from eq. <strong>¿eq:analytical_rate?</strong>. This plot highlights that even strong increases of <span class="math inline">N_S</span> beyond <span class="math inline">10^3</span> do not yield accurate results for the information rate. Our conclusion from this is that the simple Monte Carlo approach is too naïve and we have to find another way to improve accuracy, instead of spending more CPU time.</figcaption>
</figure>
<p>To support that claim, in fig. <a href="#fig:c">3</a> we show the results of two additional simulation with very high <span class="math inline">N_S</span> and compare them to the analytical reference and the MI for <span class="math inline">N_S=1000</span>. Even for these very resource-intensive simulations we don’t get better approximations for the information rate than for <span class="math inline">N_S=1000</span>. From these results we conclude that our approach is plagued by some more fundamental problem that needs to be solved with other means than merely using more computational resources.</p>
<p>While we expect the main cuprit to be the nested Monte Carlo estimates of the marginal density <span class="math inline">\mathrm P(\mathbf x)</span>, it is difficult to obtain convincing evidence for that claim using the results shown so far. For an indivdual response trajectory <span class="math inline">\mathbf x</span> we don’t have a way to judge the accuracy of our estimate of <span class="math inline">\mathrm P(\mathbf x)</span>. The only analytical result that we can use to check our results is the MI from the Gaussian approximation which is shown as the reference line in figs. <a href="#fig:a">1</a>-<a href="#fig:c">3</a>. Therefore we decided to use the same Monte Carlo procedure to compute the MI with a simpler stochastic description of the signal and response trajectories which allows us to analytically validate all intermediate results. Thus, instead of using the SSA to fully simulate the signal and response dynamics we make the Gaussian approximation as introduced in sec. <strong>¿sec:simple_model?</strong>. Using that approximation, generating a signal or response amounts to taking a draw from a multivariate normal distributions with known covariance matrix.</p>
</section>
</section>
<section id="gaussian-approximation" class="level2" data-number="1.5">
<h2 data-number="3.5"><span class="header-section-number">3.5</span> Gaussian Approximation</h2>
<p>Clearly, there is an issue with the computation of the mutual information (MI) for trajectories that prevents the accurate estimation using the simple Monte Carlo strategy shown above. In figs. <a href="#fig:a">1</a>-<a href="#fig:c">3</a> we saw that we consistently over-estimate the information rate regardless of the amount of computing time that was invested. To allow a deeper analysis of the underlying issue we repeated the estimates of the MI using a simpler, Gaussian model for signals and responses. Instead of simulating trajectories exactly in continuous time using the SSA, we choose a small time-interval <span class="math inline">\Delta t</span> which we use to discretize the system. Conversely, while the SSA simulates individual reactions that lead to a discrete jumps in the trajectories, in the Gaussian approximation the copy numbers are approximated by continuous variables. Hence, we switch from a <em>discrete states and continuous time</em> description to a <em>continuous states and discrete time</em> approximation of the biochemical network.</p>
<section id="time-discretization" class="level3" data-number="1.5.1">
<h3 data-number="3.5.1"><span class="header-section-number">3.5.1</span> Time Discretization</h3>
<p>We discretize the time axis using a set of equidistant points <span class="math inline">t_n = n\Delta t</span> for <span class="math inline">n=1,\ldots,d</span>. A signal trajectory is described a <span class="math inline">d</span>-dimensional vector <span class="math inline">\mathbf s = (s(t_1), \ldots, s(t_d))^T</span> where <span class="math inline">s(t_i)</span> describes the deviation of the signal from its mean value <span class="math inline">\bar s</span> at time <span class="math inline">t_i</span>. The null vector therefore represents a trajectory that remains constant at <span class="math inline">\bar s</span> for its entire duration whereas a non-zero vector indicates fluctuations. The Gaussian approximation for a biochemical network uses the correlation functions to derive a multivariate normal distribution such that the discretized system dynamics approximate the true stochastic dynamics of the network. Given a time-discretization we can use eq. <strong>¿eq:covariance_from_corr?</strong> compute the covariance matrices <span class="math inline">C_{ss}, C_{sx}, C_{xs}, C_{xx}</span> from the correlation functions in eq. <strong>¿eq:correlation_functions?</strong>. From these covariance matrices we can derive all stochastic properties of the Gaussian approximation.</p>
<p>The signal dynamics are given by the probability distribution <span><span class="math display">
\mathrm P(\mathbf{s}) = \frac{1}{\sqrt{\left( 2\pi  \right)^{d} \det C_{ss}}} \;\exp\left[-\frac12\ \mathbf s^T\ C_{ss}^{-1}\ \mathbf s\right]\,,
\qquad(15)</span></span> and similarly the response dynamics are determined by the marginal distribution <span id="eq:analytical_marginal"><span class="math display">
\mathrm P(\mathbf{x}) = \frac{1}{\sqrt{\left( 2\pi  \right)^{d} \det C_{xx}}} \;\exp\left[-\frac12\ \mathbf x^T\ C_{xx}^{-1}\ \mathbf x\right]\,.
\qquad(16)</span></span> Notably, eq. <a href="#eq:analytical_marginal">16</a> allows us to analytically compute the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> without performing a Monte Carlo estimate of the integral <span class="math inline">\int\mathrm d\mathbf s\ \mathrm P(\mathbf s)\,\mathrm P(\mathbf x|\mathbf s)</span>. The joint distribution of <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> is given in eq. <strong>¿eq:joint_multivariate?</strong> which is a <span class="math inline">2d</span>-dimensional multivariate normal density function with covariance matrix <span id="eq:corr_z2"><span class="math display">
Z =  \begin{pmatrix}
C_{ss}  C_{xs} \\
C_{sx}  C_{xx}
\end{pmatrix}\,.
\qquad(17)</span></span></p>
<figure>
<img src="matrix_plots.png" id="fig:corr" alt="" /></img><figcaption>Figure 4: Matrix plots of the full correlation matrix <span class="math inline">Z</span> from eq. <a href="#eq:corr_z2">17</a> for different values of dimensionality <span class="math inline">d</span> and <span class="math inline">\Delta t</span>. Brighter colors indicate higher matrix element values. We can clearly observe the block structure of <span class="math inline">Z</span> in every matrix plot. For every matrix plot, the element with coordinates <span class="math inline">(i,j)</span> in the top left quadrant shows the correlations <span class="math inline">\langle s(i\Delta t) s(j \Delta t)\rangle</span>. In the top right quadrant we see the correlations <span class="math inline">\langle s(i\Delta t) x(j \Delta t)\rangle</span> and in the lower quadrants we see <span class="math inline">\langle x(i\Delta t) s(j \Delta t)\rangle</span> and <span class="math inline">\langle x(i\Delta t) x(j \Delta t)\rangle</span> on the left and right side respectively. The product <span class="math inline">T = d\Delta t</span> is the duration of the signal and response trajectories. The quantity <span class="math inline">d\Delta t</span> also serves as a rough measure of the sparsity of the correlation matrices (i.e. the fraction of matrix elements lower than some cutoff). Along diagonals from bottom left to top right, the product <span class="math inline">T = d \Delta t</span> is constant. Indeed, we see that along these diagonals the sparsity is roughly constant. Yet, as we move along such a diagonal of equal sparsity <span class="math inline">d\Delta t</span> but increasing dimensionality <span class="math inline">d</span> we see correlation matrices that display the same features in a gradually more refined and smooth way.</figcaption>
</figure>
<p>Using this discretization we have two parameters left to tune. We can freely choose the number <span class="math inline">d</span> and offsets <span class="math inline">\Delta t</span> of our time samples. The duration of the trajectories <span class="math inline">\mathbf s</span> and <span class="math inline">\mathbf x</span> is given by the product <span class="math inline">T=d\Delta t</span>. In fig. <a href="#fig:corr">4</a> we show matrix plots of the joint covariance matrix <span class="math inline">Z</span> for different values of <span class="math inline">d</span> and <span class="math inline">\Delta t</span>. We can also observe that <span class="math inline">d</span> determines the dimensionality of the problem while the product <span class="math inline">d \Delta t</span> serves as a measure for the sparsity of the correlation matrices.</p>
<p>Note that the choice of <span class="math inline">\Delta t</span> affects how well the discretized trajectories approximate physical continuous-time trajectories. Thus, usually we would have to choose <span class="math inline">\Delta t</span> to be relatively small such that the discretized process has similar dynamics compared to the continuous Gaussian process. For our purposes, this consideration is of secondary importance. We are merely comparing the Monte-Carlo estimates for the mutual information to the analytic results, obtained by computing the determinants of the covariance matrices. For a consistent Monte-Carlo procedure we should expect convergence of the estimates to the analytic results given enough computing time. That is, while the choices of <span class="math inline">d</span> and <span class="math inline">\Delta t</span> should not affect the correctness of our procedure, it very well may strongly affect the computational resources needed for efficient estimation.</p>
</section>
<section id="direct-importance-sampling" class="level3" data-number="1.5.2">
<h3 data-number="3.5.2"><span class="header-section-number">3.5.2</span> Direct Importance Sampling</h3>
<p>We want to use this fully Gaussian model to understand how the sample sizes of the different Monte Carlo steps affect the estimate and whether there exists a bias in the approximation. We calculate the marginal entropy as a Monte Carlo average over the logarithms of the marginal distribution densities of <span class="math inline">N_x</span> sampled responses as shown in eq. <a href="#eq:mc_entropy">4</a>. The evaluation of the marginal density itself requires a Monte Carlo average over <span class="math inline">N_s</span> sampled signals (eq. <a href="#eq:mc_marginal">5</a>). Hence to evaluate the marginal density we need to perform nested averaging as shown in eq. <a href="#eq:mc_entropy_notation">6</a>. We performed this procedure for various values of <span class="math inline">N_s</span> and <span class="math inline">N_x</span> and compared the estimate with reference results using the analytical expression for the entropy of a multivariate Gaussian distribution.</p>
<p>Both, increase of <span class="math inline">N_x</span> and increase of <span class="math inline">N_s</span> should lead to an improved estimate of <span class="math inline">\mathrm H(\mathcal X)</span>. To understand the accuracy of an estimate with a given <span class="math inline">N_s</span> and <span class="math inline">N_x</span> we repeat the estimation procedure multiple times and compute the mean and the standard deviation of the individual estimation results.</p>
<figure>
<img src="relative_error_responses.svg" id="fig:rel_err_responses" alt="" /></img><figcaption>Figure 5: Top: relative error for the marginal entropy as a function of <span class="math inline">1/N_x</span>. Bottom: empirical variance of ensembles of 144 estimates. The solid lines show a linear extrapolation of the data points for <span class="math inline">N_x \rightarrow\infty</span>. All estimates were performed using a constant number of signal samples <span class="math inline">N_s = 400</span> and for <span class="math inline">d = 200</span>. The linear extrapolation in the bottom plot indicates that we do predict the variance of the results to vanish in the limit of infinite sampling. This behavior is generally expected for Monte Carlo estimates. Strikingly however, we find that there is a consistent offset of the average estimate from the correct result, even in the limit <span class="math inline">N_x \rightarrow\infty</span>. We see that the bias scales with the sparsity of the covariance matrices. The relative error is computed using <span class="math inline">\mathrm H_\text{estimate}/\mathrm H_\text{analytical} - 1</span> where <span class="math inline">\mathrm H_\text{estimate}=\sum^{M}_{i=1} \hat{\mathrm H}_i/M</span> is the average over the results of the <span class="math inline">M=144</span> marginal entropy estimates that were performed using eq. <a href="#eq:mc_entropy_notation">6</a> and <span class="math inline">\mathrm H_\text{analytical}</span> is the value resulting from an analytical computation of the marginal entropy. The empirical variance shown is <span class="math inline">\sum^{M}_{i=1} (\hat{\mathrm H}_i - \mathrm H_\text{estimate})^2/M</span>.</figcaption>
</figure>
<p>In fig. <a href="#fig:rel_err_responses">5</a> we see how the relative error of our estimate varies with the number of simulated responses <span class="math inline">N_x</span>. Here use the same number of signals per response <span class="math inline">N_s</span> for all estimates. While—as expected—the variance of the estimate decreases when we increase <span class="math inline">N_x</span> we find that especially for very sparse covariance matrices we consistently over-estimate the marginal entropy. Indeed, we find that the systematic bias in our results seems to be independent of <span class="math inline">N_x</span>.</p>
<p>We found that the bias is stronger for correlation matrices with higher sparsities <span class="math inline">d\Delta t</span>. Since the sparsity grows with trajectory duration we can expect an increasingly strong over-estimation for longer trajectories. The sparsity can be increased either by decreasing the time-resolution or by increasing the dimensions of the covariance matrix. To understand how these parameters relate to each other we tested how the estimation error changes when we increase the dimensionality of the correlation matrices while the sparsity remains constant.</p>
<p>Fig. <a href="#fig:sparsity">6</a> shows how large the estimation error for the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> is on average for different levels of sparsity. We see that in all cases that increasing the sparsity leads to larger errors in the estimates. Additionally we find that for a given sparsity value, the estimates with high-dimensional covariance matrices are slightly worse. As we keep increasing the number of dimensions <span class="math inline">d</span> at constant sparsity <span class="math inline">d\Delta t</span>, thus decreasing <span class="math inline">\Delta t</span>, the matrices gradually become a more faithful representation of the continuous correlation functions of the system (see fig. <a href="#fig:corr">4</a>). Extrapolating the lines in fig. <a href="#fig:sparsity">6</a> we project that for very large covariance matrices, the sparsity is the only determining factor of the estimation bias.</p>
<figure>
<img src="sparsity.svg" id="fig:sparsity" alt="" /></img><figcaption>Figure 6: Absolute error of marginal entropy estimates for different values of the sparsity <span class="math inline">d\Delta t</span> of the correlation matrices. We see that for high dimensionality the lines of constant sparsity become increasingly flat. This indicates that for high-dimensional systems the sparsity of the covariance matrix is a good measure for the difficulty of correct estimation. We therefore claim that the bias of the entropy estimate for the Gaussian system primarily depends on the sparsity of the covariance matrix. Note that for lower numbers of dimensions the covariance matrices of along the diagonals of equal sparsity look more blocky (see fig. <a href="#fig:corr">4</a>). That may be an indicator why the estimation error is not constant for a given sparsity at lower dimensions.</figcaption>
</figure>
<figure>
<img src="error_grid.svg" id="fig:error_regression" alt="" /></img><figcaption>Figure 7: Relative error <span class="math inline">\mathrm H_\text{estimate}/\mathrm H_\text{analytical} - 1</span> as a function of <span class="math inline">1/N_s</span>. We can see that the relative error in the marginal entropy estimate increases with the sparsity <span class="math inline">d\Delta t</span> (i.e. with trajectory duration). The linear extrapolating lines emphasize that there is a noticeable but very slight decrease in error as <span class="math inline">N_s\to\infty</span>. This seems puzzling since for infinite sampling we should expect the error to vanish. Apparently for high-sparsity covariance matrices we need extraordinarily many signal samples to achieve unbiased estimates.</figcaption>
</figure>
<p>As a next step we investigated how changes in the sampling for the marginal density <span class="math inline">\mathrm P(\mathbf x_i)</span> affect the estimation bias. Thus in fig. <a href="#fig:error_regression">7</a> we show how the increase of simulated signals per response <span class="math inline">N_s</span> improves the estimate of the marginal entropy. Here we again see that for high number of dimensions we over-estimate the marginal entropy. An increase of <span class="math inline">N_s</span> does lead to slightly less over-estimation but the linear extrapolation indicates that even if we choose enormously high values for <span class="math inline">N_s</span> we can not expect to reduce the bias substantially.</p>
<p>For a given number of samples, the fraction of the trajectory space probed by the Monte Carlo scheme is lower for longer durations. Therefore, for a given number of Monte Carlo samples we expect the estimate to become worse for longer trajectories, i.e. when the sparsity of the covariance matrix is high. This is confirmed by our results. Furthermore and more surprisingly we find that we consistently over-estimate the marginal entropy and while increasing <span class="math inline">N_s</span> <em>does</em> reduce the bias slightly it appears to require an astronomically high sampling in signal trajectory space to reach arbitrary low errors. An increase in <span class="math inline">N_x</span> however reduces the variance of the results but does not influence the bias at all.</p>
<p>Thus we are lead to believe that the main difficulty in estimating the marginal entropy is the Monte-Carlo marginalization of the probability density function. To estimate <span class="math inline">\mathrm P(\mathbf x)</span> we sample signals from the marginal distribution <span class="math inline">\mathrm P(\mathbf s)</span> and average over the likelihoods <span class="math inline">\mathrm P(\mathbf x | \mathbf s)</span>. However as the space of signals becomes increasingly vast for longer trajectories, it becomes more and more unlikely to sample a signal <span class="math inline">\mathbf s</span> where <span class="math inline">\mathbf x</span> has a non-vanishing likelihood of occurring. Hence the duration of the trajectories strongly influences the bias of the marginal entropy computation and we are well advised to keep the trajectories as short as possible. To capture the essential system dynamics however, the trajectories must be at least as long as the longest timescale <span class="math inline">\tau</span> in the system. If we are interested in the marginal entropy for timescales longer than the longest timescale in the system we can then use the fact that trajectory pieces of duration <span class="math inline"> \tau</span> become independent of each other and we can add the individual entropies of these pieces to get the full entropy for such a long trajectory. For example, if we were interested in the marginal entropy of trajectories of duration <span class="math inline">T=\ell\tau</span> where <span class="math inline">\ell\in\mathbb N^+</span> we could approximate it by estimating the entropy <span class="math inline">\hat{H}_\tau</span> of trajectories of duration <span class="math inline">\tau</span> and then take <span class="math inline">\ell \hat{H}_\tau</span> as an approximation for <span class="math inline">\hat{H}_{\ell\tau}</span>. While performing the estimate <span class="math inline">\hat{H}_\tau</span> is computationally much cheaper than directly estimating <span class="math inline">\hat{H}_{\ell\tau}</span> and therefore for a given amount of CPU-time we get a lower systematic bias of the estimate <span class="math inline">\hat{H}_\tau</span>, the bias of <span class="math inline">\ell \hat{H}_\tau</span> of course still scales linearly with <span class="math inline">\ell</span>. Therefore it is still in our best interest to reduce the systematic bias of the marginal entropy as much as possible.</p>
</section>
<section id="sec:umbrella" class="level3" data-number="1.5.3">
<h3 data-number="3.5.3"><span class="header-section-number">3.5.3</span> Umbrella Sampling</h3>
<p>To get a better estimate of <span class="math inline">\mathrm P(\mathbf x)</span> we decided to use <em>umbrella sampling</em>, i.e. to bias our sampling strategy towards signals that we expect to have a high likelihood for the given response. Since Monte-Carlo estimates depend on the distribution of the chosen samples we must correct our estimate by re-weighing the samples accordingly.</p>
<p>More specifically, given a sampling distribution <span class="math inline">w(\mathbf s)</span> (which is normalized like a probability density function) we can write <span><span class="math display">
\mathrm P(\mathbf x) = \int \mathrm d\mathbf s\ w(\mathbf s)\frac{\mathrm P(\mathbf s)\mathrm P(\mathbf x | \mathbf s)}{w(\mathbf s)} = \left\langle \frac{\mathrm P(\mathbf s)\mathrm P(\mathbf x | \mathbf s)}{w(\mathbf s)} \right\rangle_{w(\mathbf s)}
\qquad(18)</span></span> which shows us how to compute <span class="math inline">\mathrm P(\mathbf x_i)</span> from signal trajectories <span class="math inline">\mathbf s_1^w, \ldots, \mathbf s_{N_s}^w</span> which are distributed according to the sampling distribution given by <span class="math inline">w</span>: <span><span class="math display">
\mathrm P(\mathbf x_i) \approx \frac1{N_s} \sum\limits_{j=1}^{N_s} \frac{\mathrm P(\mathbf s_j^w)\mathrm P(\mathbf x_i | \mathbf s_j^w)}{w(\mathbf s_j^w)} \equiv P_{\mathbf x_i, N_s}^w \,.
\qquad(19)</span></span></p>
<p>The choice of the sampling distribution <span class="math inline">w</span> has a direct impact on the variance of an ensemble of estimates <span class="math inline">P_{\mathbf x_i, N_s}^w</span>. Indeed, for any given <span class="math inline">\mathbf x_i</span> there is an optimal choice for the sampling distribution <span class="math inline">w_\text{opt}</span> such that the variance of the estimates vanishes. This optimal choice is given by <span class="math inline">w_\text{opt}(\mathbf s) = \mathrm P(\mathbf s | \mathbf x_i)</span> which is easily confirmed by the calculation <span id="eq:opt_sampling"><span class="math display">
P_{\mathbf x_i, N_s}^{w_\text{opt}} = \frac1{N_s}\sum\limits_{j=1}^{N_s} \frac{\mathrm P(\mathbf s_j^w)\mathrm P(\mathbf x_i | \mathbf s_j^w)}{\mathrm P(\mathbf s_j^w | \mathbf x_i)} = \frac1{N_s}\sum\limits_{j=1}^{N_s} \mathrm P(\mathbf x_i)
\qquad(20)</span></span> where in the last step we applied Bayes’ rule. Since the expression above is completely independent of the chosen signal samples the result is deterministic and thus has zero variance. We also see from eq. <a href="#eq:opt_sampling">20</a> that in practice we can’t directly use <span class="math inline">w_\text{opt}(\mathbf s) = \mathrm P(\mathbf s | \mathbf x_i)</span> as our sampling distribution since the evaluation of <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i) = \frac{\mathrm P(\mathbf x_i|\mathbf s) \mathrm P(\mathbf s)}{\mathrm P(\mathbf x_i)}</span> itself depends on <span class="math inline">\mathrm P(\mathbf x_i)</span> which is precisely the quantity we are interested in estimating.</p>
<figure>
<img src="sampling2.svg" id="fig:rel_err_opt" alt="" /></img><figcaption>Figure 8: Relative error as a function of the dimensionality <span class="math inline">d</span>. The solid lines show the results using non-optimized sampling while the dashed lines show the results when using a sampling distribution close to the optimal distribution <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span>. We see that with optimized sampling there is no consistent over-estimation anymore. All estimated were done using <span class="math inline">d = 200</span> dimensional covariance matrices.</figcaption>
</figure>
<p>Instead, we can try to obtain a sampling distribution that is as close as possible to <span class="math inline">w_\text{opt}(\mathbf s)</span>. A known approach involves using random samples from <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i)</span> to pick the most optimal sampling distribution from a family of candidate distributions <span class="citation" data-cites="2011.Chan">[<a href="#ref-2011.Chan" role="doc-biblioref">7</a>]</span>. Generating so-called <em>posterior samples</em> from <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i) \sim \mathrm P(\mathbf x_i|\mathbf s) \mathrm P(\mathbf s)</span> is generally possible without knowledge of the normalization factor <span class="math inline">\mathrm P(\mathbf x_i)</span> e.g. by using Metropolis-Sampling <span class="citation" data-cites="1991.Müller 1994.Tierney">[<a href="#ref-1991.Müller" role="doc-biblioref">8</a>,<a href="#ref-1994.Tierney" role="doc-biblioref">9</a>]</span>. To test within the Gaussian framework whether such an approach to importance sampling could work in principle, we generate 400 posterior samples by directly sampling from the analytically known posterior distribution <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i)</span>. We compute the empirical mean <span class="math inline">\bar{\mathbf s}</span> and the empirical covariance <span class="math inline">\bar C_{\mathbf s|\mathbf x_i}</span> of these samples as parameter estimates for a multivariate Gaussian <span class="math inline">\mathcal N(\bar{\mathbf s}, \bar C_{\mathbf s|\mathbf x_i})</span> and use the latter as an optimized sampling distribution.</p>
<p>In fig. <a href="#fig:rel_err_opt">8</a> we show that using optimized sampling we can strongly reduce the systematic bias in marginal entropy estimation. As expected, importance sampling is especially useful when the sparsity is very high, i.e. the trajectories are long. It is clear that for longer trajectories we expect <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i)</span> to be a much more narrow sampling distribution than <span class="math inline">\mathrm P(\mathbf s)</span> whenever the <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> are not completely independent. Consequently, it becomes more and more unlikely to obtain a sample <span class="math inline">s^\prime</span> from <span class="math inline">\mathrm P(\mathbf s)</span> such that <span class="math inline">\mathrm P(s^\prime | \mathbf x_i)  \epsilon</span> for any <span class="math inline">\epsilon  0</span> and therefore more difficult to accurately estimate <span class="math inline">\mathrm P(\mathbf x_i)</span> using an unbiased sampling distribution.</p>

</section>
<section id="estimating-the-conditional-entropy-1" class="level3" data-number="1.5.4">
<h3 data-number="3.5.4"><span class="header-section-number">3.5.4</span> Estimating the Conditional Entropy</h3>
<figure>
<img src="conditional.svg" id="fig:conditional" alt="" /></img><figcaption>Figure 9: Comparison of the relative error of conditional entropy estimates versus marginal error estimates. The relative errors are shown on a logarithmic scale as a function of the sparsity. We can see that the relative error for the estimate of the conditional entropy is a few orders of magnitude smaller than the estimates of the marginal entropy. All estimates were performed with <span class="math inline">N_x=25600</span> and <span class="math inline">N_s=1000</span>.</figcaption>
</figure>
<p>For both, marginal entropy and conditional entropy we have to evaluate the likelihood <span class="math inline">\mathrm P(\mathbf x| \mathbf s)</span> a total of <span class="math inline">N_s N_x</span> times. To compare the accuracy of we performed estimates of the marginal entropy with and without optimized sampling together with estimates of the conditional entropy for <span class="math inline">N_s = 1000</span> and <span class="math inline">N_x = 25600</span>. In fig. <a href="#fig:conditional">9</a> we show the relative error of both, marginal and conditional entropy estimates as a function of the sparsity. We find that the estimate of the conditional entropy is very accurate regardless of sampling size. Even with optimized sampling the marginal entropy estimate is roughly two orders of magnitude worse than a comparable conditional entropy estimate.</p>
</section>
</section>
<section id="discussion" class="level2" data-number="1.6">
<h2 data-number="3.6"><span class="header-section-number">3.6</span> Discussion</h2>
<p>Since both the estimate of the marginal entropy and of the conditional entropy require the computation of two nested Monte-Carlo averages one could expect the results of both estimates to be of similar accuracy. Yet we find that computing the marginal entropy is much more challenging than computing the conditional entropy. While analyzing the estimation procedure for the marginal entropy we found the main source of error to arise from the computation of the marginal probability density <span class="math inline">\mathrm P(\mathbf x)</span>. While the computation of this density suffers from high Monte-Carlo variance when we are not carefully optimizing our trajectory sampling procedure, the real issue arises in the next step when we have to <em>compute the logarithm of the marginal probability density</em> to estimate the marginal entropy <span class="math inline">\mathrm H(\mathcal X) \approx \sum^{N_x}_{i=1}-\ln\mathrm P(\mathbf x_i) / N_x</span> from our sampled response trajectories (see also eq. <a href="#eq:mc_entropy_notation">6</a>). For us, computing <span class="math inline">\ln\mathrm P(\mathbf x_i)</span> means computing the logarithm of an average. Taking the logarithm—which is concave function—of a Monte-Carlo average leads to a consistent bias. We see the existence of this bias in our results since we consistently over-estimate the marginal entropy. Indeed, the reason why it is much easier to get a good estimate of the conditional entropy is that in the latter case we have to average the logarithm of a quantity (see eq. <strong>¿eq:conditional_entropy?</strong>) rather than taking the logarithm of an average, as we need for the marginal entropy.</p>
<p>We can thus conclude that the main difficulty of obtaining a good estimate for the mutual information between trajectories lies in the efficient and accurate computation of the marginal entropy. A viable approach for this seems to be to use importance sampling in the signal space in the computation of the marginal probability density. Our results indicate that such an approach could also work for trajectories generated using a fully stochastic model of a biochemical network. Another direction to pursue might be to use the replica trick, based on the mathematical identity that <span class="math inline">\ln Z = \lim_{n\to 0} (Z^n-1) / n</span>. This may allow us to eliminate the systematic bias by circumventing the need to take the logarithm of an estimate.</p>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-2019.Cepeda-Humerez">
<p>[1] S.A. Cepeda-Humerez, J. Ruess, G. Tkačik, Estimating information in time-varying signals., PLoS Computational Biology. 15 (2019) e1007290. <a href="https://doi.org/10.1371/journal.pcbi.1007290">https://doi.org/10.1371/journal.pcbi.1007290</a>.</p>
</div>
<div id="ref-2009.Gardiner">
<p>[2] C. Gardiner, Stochastic Methods, 4th ed., Springer-Verlag, Berlin Heidelberg, 2009.</p>
</div>
<div id="ref-1992.Kloeden">
<p>[3] P.E. Kloeden, E. Platen, Numerical Solution of Stochastic Differential Equations, 1992.</p>
</div>
<div id="ref-1956.Rosenblatt">
<p>[4] M. Rosenblatt, Remarks on Some Nonparametric Estimates of a Density Function, The Annals of Mathematical Statistics. 27 (1956) 832–837. <a href="https://doi.org/10.1214/aoms/1177728190">https://doi.org/10.1214/aoms/1177728190</a>.</p>
</div>
<div id="ref-1962.Parzen">
<p>[5] E. Parzen, On Estimation of a Probability Density Function and Mode, The Annals of Mathematical Statistics. 33 (1962) 1065–1076. <a href="https://doi.org/10.1214/aoms/1177704472">https://doi.org/10.1214/aoms/1177704472</a>.</p>
</div>
<div id="ref-2010.Tostevin">
<p>[6] F. Tostevin, P.R. ten Wolde, Mutual information in time-varying biochemical systems, Physical Review E. 81 (2010) 061917. <a href="https://doi.org/10.1103/physreve.81.061917">https://doi.org/10.1103/physreve.81.061917</a>.</p>
</div>
<div id="ref-2011.Chan">
<p>[7] J.C.C. Chan, D.P. Kroese, Improved cross-entropy method for estimation, Statistics and Computing. 22 (2011) 1031–1040. <a href="https://doi.org/10.1007/s11222-011-9275-7">https://doi.org/10.1007/s11222-011-9275-7</a>.</p>
</div>
<div id="ref-1991.Müller">
<p>[8] P. Müller, A Generic Approach to Posterior Integration and Gibbs Sampling, Purdue University, 1991.</p>
</div>
<div id="ref-1994.Tierney">
<p>[9] L. Tierney, Markov Chains for Exploring Posterior Distributions, The Annals of Statistics. 22 (1994) 1701–1728. <a href="https://doi.org/10.1214/aos/1176325750">https://doi.org/10.1214/aos/1176325750</a>.</p>
</div>
</div>
</section>
</section>
<section id="directed-sampling-in-trajectory-space" class="level1" data-number="1">
<h1 data-number="4"><span class="header-section-number">4</span> Directed Sampling in Trajectory Space</h1>
<p>In the previous chapters we established a technique to compute the mutual information between time-variable signals and responses using Monte-Carlo integration together with stochastic simulations. In practice we found that this method often severely over-estimates the mutual information. In the previous chapter we came to the conclusion that the root of the biased estimates is the computation of the marginal probability density <span class="math inline">\mathrm P(\mathbf x)</span>.</p>
<p>The fundamental identity for the prediction of model parameters <span class="math inline">\mathbf s</span> given some data or response <span class="math inline">\mathbf x</span> is Bayes’ theorem <span id="eq:bayes_thm"><span class="math display">
\mathrm P(\mathbf s | \mathbf x) = \frac{\mathrm P(\mathbf x|\mathbf s)\ \mathrm P(\mathbf s)}{\mathrm P(\mathbf x)}
\qquad(1)</span></span> which describes how the observation of <span class="math inline">\mathbf x</span> changes the probability distribution for the signals from <span class="math inline">\mathrm P(\mathbf s)</span> to <span class="math inline">\mathrm P(\mathbf s | \mathbf x)</span>. In statistics, one usually denotes <span class="math inline">\mathrm P(\mathbf s)</span> as the <em>prior</em>, <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> as the <em>likelihood</em>, <span class="math inline">\mathrm P(\mathbf x)</span> as the <em>evidence</em> (or <em>marginal likelihood</em>) and <span class="math inline">\mathrm P(\mathbf s | \mathbf x)</span> as the <em>posterior</em> distribution. It is no accident that for the description of statistical inference we reuse the same letters <span class="math inline">\mathbf x</span> and <span class="math inline">\mathbf s</span> as in the previous chapters. Indeed, at its core, the biochemical network performs statistical inference of the signal from the data given by its response. Thus, for now, we are going to change the perspective and look at the problem through the eyes of a Bayesian statistician.</p>
<p>From the statistician’s point of view, we have a <em>model</em> with a set of parameters <span class="math inline">\mathbf s = (s_1, s_2,\ldots)^T</span> that we want to fit to the observations or data <span class="math inline">\mathbf x</span>. The Bayesian approach involves choosing a reasonable <em>prior</em>, i.e. making an educated guess for the distribution <span class="math inline">\mathrm P(\mathbf s)</span> using justifiable assumptions about the underlying system. Using eq. <a href="#eq:bayes_thm">1</a>, the statistician can compute the <em>posterior</em> probability distribution of the model parameters <span class="math inline">\mathrm P(\mathbf s | \mathbf x)</span> from the observations <span class="math inline">\mathbf x</span>. This involves computing the <em>likelihood</em> <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> and the <em>evidence</em> <span class="math inline">\mathrm P(\mathbf x)</span> of the acquired data <span class="math inline">\mathbf x</span> for the given model. Usually, models are chosen that make it easy to compute the likelihood of some data given the model parameters. It is the computation of the <em>evidence</em> <span class="math inline">\mathrm P(\mathbf x)</span> which usually requires more sophisticated computational methods <span class="citation" data-cites="2014.Held">[<a href="#ref-2014.Held" role="doc-biblioref">1</a>]</span>. In most cases, the evidence is estimated using the identity <span class="math inline">\mathrm P(\mathbf x)=\int\mathrm d\mathbf s\ \mathrm P(\mathbf s, \mathbf x)</span> which has motivated the use of the term <em>marginal likelihood</em>. In the following section we show the evolution of methods to compute such integrals in statistical science.</p>
<section id="previous-work-on-the-computation-of-the-marginal-likelihood" class="level2" data-number="1.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Previous Work on the Computation of the Marginal Likelihood</h2>
<p>The estimation of the marginal density <span class="math inline">\mathrm P(\mathbf x)=\int\mathrm d\mathbf s\ \mathrm P(\mathbf s, \mathbf x)</span> is an important ingredient for Bayesian statistics, and is used for example in the computation of so-called <em>Bayes factors</em> for hypothesis testing.</p>
<p>Written as <span id="eq:marginal_as_mean"><span class="math display">
\mathrm P(\mathbf x) = \langle \mathrm P(\mathbf x|\mathbf s) \rangle_{\mathrm P(\mathbf s)}
\qquad(2)</span></span> the marginal density is an example of an expectation value with respect to a potentially complex distribution. For simple distributions, expectations can be approximated by a simple Monte-Carlo approach, taking the sample average <span class="math inline">1/N \sum^N_{i=1} \mathrm P(\mathbf x|\mathbf s_i)</span> of <span class="math inline">N</span> independent random samples <span class="math inline">\mathbf s_1,\ldots,\mathbf s_N</span> generated from <span class="math inline">\mathrm P(\mathbf s)</span>. That is, we estimate the marginal density using samples from the <em>prior</em> and averaging over their likelihoods. As demonstrated in the previous chapters, this method is not very efficient when the individual signals <span class="math inline">\mathbf s_i</span> are actually trajectories. Once the space of possible signals is sufficiently large it becomes extremely unlikely to sample a <span class="math inline">\mathbf s^\prime</span> such that <span class="math inline">\mathrm P(\mathbf x|\mathbf s^\prime)</span> presents a strong contribution to the mean. A well-known approach to circumvent this problem is <em>importance sampling</em>.</p>
<section id="importance-sampling" class="level3" data-number="1.1.1">
<h3 data-number="4.1.1"><span class="header-section-number">4.1.1</span> Importance Sampling</h3>
<p>In importance sampling, we choose a different distribution than the prior from which to generate samples. Let <span class="math inline">\hat{\mathbf s}_1, \ldots,\hat{\mathbf s}_N</span> be samples drawn from a distribution with a known density function <span class="math inline">\hat q</span>. Then we can estimate eq. <a href="#eq:marginal_as_mean">2</a> as <span id="eq:importance_sampling"><span class="math display">
\hat{\mathrm P}^{(q)}(\mathbf x) = \frac{1}{N} \sum^N_{i=1} \frac{\mathrm P(\hat{\mathbf s}_i)\,\mathrm P(\mathbf x | \hat{\mathbf s}_i)}{\hat q(\hat{\mathbf s}_i)} \equiv 
\frac{1}{N} \sum^N_{i=1} \frac{q(\hat{\mathbf s}_i)}{\hat q(\hat{\mathbf s}_i)}
\qquad(3)</span></span> where by <span class="math inline">q(\mathbf s)=\mathrm P(\mathbf s)\,\mathrm P(\mathbf x|\mathbf s)</span> we denote the unnormalized posterior distribution (note that the posterior is <span class="math inline">\mathrm P(\mathbf s|\mathbf x) = q(\mathbf s)/C</span> with <span class="math inline">C=\mathrm P(\mathbf x)</span>). This is precisely the approach that was described in sec. <strong>¿sec:umbrella?</strong> using the term <em>umbrella sampling</em>. For this section we will continue to use the statisticians’ terminology of <em>importance sampling</em>. The choice of <span class="math inline">\hat q</span> requires crucial consideration for eq. <a href="#eq:importance_sampling">3</a> to yield a good estimate. To reduce the variance of the ratio <span class="math inline">q(\hat{\mathbf s}_i) / \hat q(\hat{\mathbf s}_i)</span>, the sampling distribution <span class="math inline">\hat q</span> should be similar to the posterior and have tails no thinner than <span class="math inline">q</span> <span class="citation" data-cites="1997.Diciccio">[<a href="#ref-1997.Diciccio" role="doc-biblioref">2</a>]</span>. In practice it is often very difficult to find an adequate choice for <span class="math inline">\hat q</span>, especially in high-dimensional spaces. Therefore, it has been suggested to choose an approproate sampling function using one or more <em>posterior samples</em> i.e. random samples taken from the posterior distribution <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span> <span class="citation" data-cites="1997.Diciccio 2011.Chan 2014.Chan 2014.Perrakis">[<a href="#ref-1997.Diciccio" role="doc-biblioref">2</a>–<a href="#ref-2014.Perrakis" role="doc-biblioref">5</a>]</span>. Even if it is possible to acquire a sufficient amount of posterior samples, these methods usually require the choice of an appropriate family of distributions from which the sampling distribution is picked. Since in our case, the individual <span class="math inline">\mathbf s</span> are entire trajectories it is unclear what a useful family of distributions would be.</p>
<p>Some authors have instead proposed methods to compute the marginal density <em>directly</em> from the posterior samples without the need to pick a separate sampling distribution <span class="math inline">\hat q</span>. This promises to be more efficient than using prior samples since we don’t face the problem of generating mostly irrelevant signals for a given response. However, the generation of random samples from <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span> is often a non-trivial problem. Thus, there have been proposed a variety of Markov chain Monte Carlo methods to generate approximately independent samples from the posterior distribution <span class="citation" data-cites="1994.Tierney 1990.Gelfand 1987.Tanner 2001.Neal 2018.Warne">[<a href="#ref-1994.Tierney" role="doc-biblioref">6</a>–<a href="#ref-2018.Warne" role="doc-biblioref">10</a>]</span>. We will leave the discussion of efficient posterior sampling for later and assume for now to have a set of corresponding samples available.</p>
</section>
<section id="estimating-the-marginal-density-from-posterior-samples" class="level3" data-number="1.1.2">
<h3 data-number="4.1.2"><span class="header-section-number">4.1.2</span> Estimating the Marginal Density from Posterior Samples</h3>
<p>Let <span class="math inline">\tilde{\mathbf s}_1,\ldots,\tilde{\mathbf s}_N</span> be independent posterior draws. Newton, et. al. <span class="citation" data-cites="1994.Newton">[<a href="#ref-1994.Newton" role="doc-biblioref">11</a>]</span> propose the harmonic mean estimator <span id="eq:harmonic_rule"><span class="math display">
\hat{\mathrm P}^{(\text{harm.})}(\mathbf x) = \left[ \frac{1}{N} \sum^N_{i=1} \mathrm P(\mathbf x|\tilde{\mathbf s}_i)^{-1} \right]^{-1}\,,
\qquad(4)</span></span> i.e. the marginal likelihood is estimated by the harmonic mean of the likelihoods of a sample from the posterior distribution. It has been noted that this estimate is rather unstable because of the occasional occurence of a value <span class="math inline">\tilde{\mathbf s}_i</span> with a small likelihood and hence a large effect on the final result <span class="citation" data-cites="1994.Newton">[<a href="#ref-1994.Newton" role="doc-biblioref">11</a>]</span>. The estimate in eq. <a href="#eq:harmonic_rule">4</a> can therefore be improved using an arbitrary probability density <span class="math inline">f</span> as proposed by Gelfand, et. al. <span class="citation" data-cites="1994.Gelfand">[<a href="#ref-1994.Gelfand" role="doc-biblioref">12</a>]</span> <span id="eq:reciprocal_importance"><span class="math display">
\hat{\mathrm P}^{(\text{reciprocal})}(\mathbf x) = \left[ \frac{1}{N} \sum^N_{i=1} \frac{f(\tilde{\mathbf s}_i)}{q(\tilde{\mathbf s}_i)} \right]^{-1}\,.
\qquad(5)</span></span> If we choose <span class="math inline">f(\mathbf s)=\mathrm P(\mathbf s)</span> we recover the harmonic rule in eq. <a href="#eq:harmonic_rule">4</a>. If instead, we choose <span class="math inline">f</span> with tails thinner than <span class="math inline">q</span> this estimator is well-behaved <span class="citation" data-cites="1997.Diciccio">[<a href="#ref-1997.Diciccio" role="doc-biblioref">2</a>]</span>. This requirement for <span class="math inline">f</span> is the opposite as for importance sampling which lead to the estimate in eq. <a href="#eq:reciprocal_importance">5</a> being called <em>reciprocal importance sampling</em>. However, similarly as before it is often difficult to find a density <span class="math inline">f</span> that has sufficiently thin tails in all dimensions. Both, importance sampling and reciprocal importance sampling are special cases of a more general identity.</p>
</section>
<section id="bridge-sampling-and-beyond" class="level3" data-number="1.1.3">
<h3 data-number="4.1.3"><span class="header-section-number">4.1.3</span> Bridge Sampling and Beyond</h3>
<p>The idea of bridge sampling was first given by Bennet <span class="citation" data-cites="1976.Bennett">[<a href="#ref-1976.Bennett" role="doc-biblioref">13</a>]</span> for the simulation of free energy differences. Given two unnormalized probability densities, <span class="math inline">q_1</span> and <span class="math inline">q_2</span>, Meng and Wong <span class="citation" data-cites="1996.Meng">[<a href="#ref-1996.Meng" role="doc-biblioref">14</a>]</span> state the central identity of bridge sampling as <span id="eq:bridge_sampling"><span class="math display">
\frac{c_1}{c_2} = \frac{\langle q_1(\mathbf s)\,\alpha(\mathbf s) \rangle_2}{\langle q_2(\mathbf s)\,\alpha(\mathbf s) \rangle_1}
\qquad(6)</span></span> where <span class="math inline">c_1, c_2</span> are the normalization constants corresponding to <span class="math inline">q_1, q_2</span>, and <span class="math inline">\alpha</span> is an arbitrary function. <span class="math inline">\langle\,\rangle_i</span> denotes the expectation with respect to the distribution corresponding to <span class="math inline">q_i</span>. If we choose <span class="math inline">q_1(\mathbf s)=q(\mathbf s)</span> and <span class="math inline">q_2(\mathbf s)=\hat q(\mathbf s)</span> then for <span class="math inline">\alpha(\mathbf s)=1/\hat q(\mathbf s)</span> we get importance sampling as defined in eq. <a href="#eq:importance_sampling">3</a>. If we choose <span class="math inline">\alpha(\mathbf s) = [q_1(\mathbf s)\,q_2(\mathbf s)]^{-1}</span> we get <span><span class="math display">
\frac{c_1}{c_2} = \frac{\langle q^{-1}_2(\mathbf s) \rangle_2}{\langle q^{-1}_1(\mathbf s) \rangle_1}
\qquad(7)</span></span> which is a generalization of the harmonic rule in eq. <a href="#eq:harmonic_rule">4</a>.</p>
<p>For bridge sampling, Bennet, Meng and Wong <span class="citation" data-cites="1976.Bennett 1996.Meng">[<a href="#ref-1976.Bennett" role="doc-biblioref">13</a>,<a href="#ref-1996.Meng" role="doc-biblioref">14</a>]</span> discuss optimal choices for <span class="math inline">\alpha</span> such that the mean square error of the estimate is minimized. It turns out that a good choice of <span class="math inline">\alpha</span> acts as a <em>bridge</em> between the densities <span class="math inline">q_1</span> and <span class="math inline">q_2</span>, such that both the numerator and the denominator of eq. <a href="#eq:bridge_sampling">6</a> can be reliably computed. Hence, the name: bridge sampling.</p>
<p>It did not go unnoticed that techniques originally developed for the computation of free energy differences might be useful in Bayesian computation. Gelman and Weng <span class="citation" data-cites="1998.Gelman">[<a href="#ref-1998.Gelman" role="doc-biblioref">15</a>]</span> introduce <em>path sampling</em> which is a generalized form of <em>thermodynamic integration</em>. It takes the idea of bridge sampling one step further: instead of using one bridge to join two distributions <span class="math inline">q_1</span> and <span class="math inline">q_2</span> and compute the ratio of their normalization constants, thermodynamic integration constructs a continuous <em>path in distribution space</em> between <span class="math inline">q_1</span> and <span class="math inline">q_2</span> to further increase the efficiency. Another related method is <em>annealed importance sampling</em>, proposed by Neal <span class="citation" data-cites="2001.Neal">[<a href="#ref-2001.Neal" role="doc-biblioref">9</a>]</span>. It is based on simulated annealing, another technique originating in statistical physics.</p>
<p>We have seen that many methods to compute the marginal likelihood draw inspiration from statistical physics. Specifically we can map the computation of the normalization constant of a probability distribution to the simulation of free energy differences. In the next subsection we will introduce notation and terminology reminiscent of Statistical physics to describe our problem. In this way we can understand why those methods are so helpful for Bayesian computation. Using that description we show that both, Thermodynamic Integration and the Wang-Landau algorithm are very promising candidates for the computation of <span class="math inline">\mathrm P(\mathbf x)</span>.</p>
</section>
</section>
<section id="borrowing-terminology-from-statistical-physics" class="level2" data-number="1.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Borrowing Terminology from Statistical Physics</h2>
<p>The mutual information then measures the difference in entropies between these two distributions or in other words: <em>how much uncertainty about <span class="math inline">\mathbf s</span> the observation of <span class="math inline">\mathbf x</span> was able to remove</em>. For the computation of the <em>mutual information</em> between <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> we need to estimate the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> which requires averaging over the logarithm of the marginal densities <span class="math inline">\ln\mathrm P(\mathbf x_i)</span> for many samples <span class="math inline">\mathbf x_i\sim\mathcal X</span>. Since we only have access to the <em>prior</em> and the <em>likelihood</em> we have to compute the marginal likelihood as <span class="math inline">\mathrm P(\mathbf x) = \int \mathrm d\mathbf s\ \mathrm P(\mathbf s | \mathbf x) \mathrm P(\mathbf s)</span>. These kinds of integrals are very familiar to researchers in statistical physics albeit they use a different terminology to describe them. In the following we will describe how eq. <a href="#eq:bayes_thm">1</a> is analogous to the distribution of the canonical ensemble and how this analogy allows us to make use of efficient computational methods from statistical physics.</p>
<p>In the framework employed by statistical physics, Bayes’ theorem corresponds to the canonical ensemble distribution of <span class="math inline">\mathbf s</span> (for <span class="math inline">\beta=1</span>) <span><span class="math display">
\mathrm P(\mathbf s | \mathbf x) = \frac{1}{Z(\mathbf x)}\exp\left[-E(\mathbf s, \mathbf x)\right]
\qquad(8)</span></span> where the <em>partition function</em> is defined by <span class="math inline">Z(\mathbf x) = \int \mathrm d\mathbf s\ \exp\left[-E(\mathbf s, \mathbf x)\right]</span> and <span class="math inline">E(\mathbf s, \mathbf x)</span> denotes the total energy of the system at state <span class="math inline">\mathbf s</span>. In this context <span class="math inline">\mathbf x</span> is considered a parameter vector for the specific model used to compute the energy. In classical problems of statistical physics (such as e.g. the <em>Ising model</em>) the state space spans the single particle states <span class="math inline">\mathbf{s} = (\sigma_1,\ldots,\sigma_n)\in\Omega^n</span> for all particles and the energy is given by the <em>Hamiltonian</em> <span class="math inline">\mathcal H(\sigma_1,\ldots,\sigma_n;\mathbf x)</span> where <span class="math inline">\mathbf x</span> could contain parameters describing e.g. the interaction strength between neighboring spins. In our case however we define our energy function by comparison with eq. <a href="#eq:bayes_thm">1</a> as <span><span class="math display">E(\mathbf s, \mathbf x) = -\ln\mathrm P(\mathbf x|\mathbf s)-\ln\mathrm P(\mathbf s)\,.\qquad(9)</span></span> From this point of view the marginal density <span class="math inline">\mathrm P(\mathbf x) = Z(\mathbf x)</span> <em>is</em> the partition function of the canonical ensemble. In statistical physics the partition function is of central importance since its partial derivatives include all thermodynamic properties of a physical system. The free energy of the canonical ensemble is defined by <span class="math inline">\mathcal F(\mathbf x) = -\ln Z(\mathbf x)</span> (for <span class="math inline">\beta=1</span>) such that using this terminology we can write the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> as an average over the <em>“free energies of response trajectories”</em> <span><span class="math display">
\mathrm H(\mathcal X) = \int\mathrm d\mathbf x\ \mathrm P(\mathbf x)\ \mathcal F(\mathbf x) = \left\langle \mathcal F(\mathbf x) \right\rangle_{\mathrm P(\mathbf x)}\,.
\qquad(10)</span></span></p>
<p>Since the computation of the partition function is central to the solution of many statistical problems there has been done considerable work on efficient estimation of the partition function, the free energy and other related quantities such as the <em>density of states</em>.</p>
</section>
<section id="thermodynamic-integration" class="level2" data-number="1.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Thermodynamic Integration</h2>
<p>One well-established technique to estimate free energy (differences) is by thermodynamic integration (TI) <span class="citation" data-cites="1998.Gelman">[<a href="#ref-1998.Gelman" role="doc-biblioref">15</a>]</span>. It allows the accurate computation of the ratio between the normalization constants of two different probability distributions using a continuous path in <em>distribution space</em> that connects both. Since this strategy uses random samples taken from many different distributions along this path it is especially robust when the two distributions have very little overlap. For the computation of the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> we can (for a given <span class="math inline">\mathbf x</span>) define a suitable path in distribution space between <span class="math inline">\mathrm P(\mathbf s)</span> and <span class="math inline">\mathrm P(\mathbf s, \mathbf x)</span>. The normalization constants of these distributions are <span class="math inline">z_0 = 1</span> and <span class="math inline">z_1 = \mathrm P(\mathbf x)</span>, respectively such that the ratio <span class="math inline">r=z_1/z_0</span> of these normalization constants directly corresponds to the marginal density. Using TI we estimate this ratio using approximately independent samples from a <em>Markov chain Monte Carlo</em> (MCMC) simulation.</p>
<p>In the following sections we will give a quick summary of TI followed by an explanation of the Markov chain Monte Carlo simulation and a discussion of the resulting accuracy of the estimates.</p>
<section id="summary-of-the-technique" class="level3" data-number="1.3.1">
<h3 data-number="4.3.1"><span class="header-section-number">4.3.1</span> Summary of the Technique</h3>
<p>Let <span class="math inline">q_0</span> and <span class="math inline">q_1</span> be the unnormalized distribution functions and <span class="math inline">z_0, z_1</span> the corresponding normalization constants such that <span class="math inline">z_i=\int\mathrm d\mathbf s\ q_i(\mathbf s)</span>. Next we construct a path between <span class="math inline">q_0</span> and <span class="math inline">q_1</span>, parametrized by <span class="math inline">\theta\in[0,1]</span> such that <span class="math inline">q_\theta</span> smoothly connects the end points. We similarly define <span class="math inline">z(\theta)</span> as the normalization constant of <span class="math inline">q_\theta</span>. A smooth path that can be constructed for any pair of distributions <span class="math inline">(q_0, q_1)</span> is the <em>geometric path</em> given by <span class="math inline">q_\theta=q^{1-\theta}_0\ q^\theta_1</span>. Note however that variance of the estimate depends on the chosen path and that the geometric path is not the optimal path in general.</p>
<p>For the estimation of free energy differences we are interested in the ratio <span class="math inline">r=z(1)/z(0)</span>. To find an estimate we differentiate the logarithm of <span class="math inline">z(\theta)</span> with respect to <span class="math inline">\theta</span> to arrive at <span><span class="math display">
\frac{\mathrm d\ln z(\theta)}{\mathrm d\theta} = \frac{1}{z(\theta)} \frac{\partial}{\partial\theta}  \int\mathrm d\mathbf s\ q_\theta(\mathbf s) = \int\mathrm d\mathbf s\ \frac{q_\theta(\mathbf s)}{z(\theta)} \frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s) = \left\langle \frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s) \right\rangle_{p_\theta(\mathbf s)}
\qquad(11)</span></span> where <span class="math inline">p_\theta(\mathbf s) = q_\theta(\mathbf s)/z(\theta)</span> is the normalized probability distribution corresponding to <span class="math inline">q_\theta</span>. By analogy to the potential in statistical physics we define <span><span class="math display">
U(\mathbf s, \theta) = -\frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s)\,.
\qquad(12)</span></span> Now we can express the log-ratio <span class="math inline">\lambda=\ln r</span> by the integral <span id="eq:path_sampling_int"><span class="math display">
\lambda = \ln z(1) - \ln z(0) = -\int\limits^1_0 \mathrm d\theta\ \left\langle 
U(\mathbf s, \theta)
\right\rangle_{p_\theta(\mathbf s)}
\qquad(13)</span></span> which forms the basis of all thermodynamic integration estimates. One advantage of the TI estimators is that we directly estimate the log-ratio <span class="math inline">\lambda</span>, i.e. the free energy difference as opposed to the ratio of partition functions. Indeed, to eventually compute the marginal entropy <span class="math inline">\mathrm H(\mathcal X) = -\langle\ln P(\mathbf x)\rangle</span> we require the logarithm of the marginal density thus no further error is introduced by taking the logarithm of an estimated quantity.</p>
<p>Using the previous identities, one possible way to estimate <span class="math inline">\lambda</span> is to regard <span class="math inline">\theta</span> as a random variable with a density <span class="math inline">p(\theta)</span>, allowing us to compute the integral in eq. <a href="#eq:path_sampling_int">13</a> using the Monte Carlo estimator <span id="eq:lambda_mc"><span class="math display">
\hat{\lambda}_\text{MC} = -\frac{1}{n} \sum\limits^n_{i=1}\frac{U(\mathbf s_i, \theta_i)}{p(\theta_i)}
\qquad(14)</span></span> with draws <span class="math inline">(\mathbf s_1, \theta_1),\ldots,(\mathbf s_n, \theta_n)</span> from the joint probability density <span class="math inline">p(\mathbf s, \theta) = p_\theta(\mathbf s)\ p(\theta)</span>. Alternatively, we can perform numerical integration using the trapezoidal rule by evaluating the potential over values <span class="math inline">\theta_1\cdots\theta_{n-1}</span> between <span class="math inline">\theta_0=0</span> and <span class="math inline">\theta_n=1</span> <span id="eq:lambda_ni"><span class="math display">
\hat{\lambda}_\text{NI} = -\sum\limits^n_{i=1}\frac{
  \langle U(\mathbf s, \theta_{i-1}) \rangle_{p_{\theta_{i-1}}(\mathbf s) }
  + \langle U(\mathbf s, \theta_{i}) \rangle_{p_{\theta_{i}}(\mathbf s) }
  }{2} (\theta_i - \theta_{i-1})
\qquad(15)</span></span> where each average over the potential is performed using a Monte Carlo simulation.</p>
<p>To use these estimators for the computation of the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> at a given <span class="math inline">\mathbf x</span> we need to construct a path between the densities <span class="math inline">q_0(\mathbf s) = \mathrm P(\mathbf s)</span> and <span class="math inline">q_1(\mathbf s) = \mathrm P(\mathbf s)\mathrm P(\mathbf x|\mathbf s)</span>. For simplicity and convenience we choose the geometric path <span class="math inline">q_\theta(\mathbf s) = \mathrm P(\mathbf s)\ [\mathrm P(\mathbf x|\mathbf s)]^\theta</span>. Taking the logarithm of this density we get <span class="math inline">\ln q_\theta(\mathbf s) = \ln P(\mathbf s) + \theta \ln \mathrm P(\mathbf x|\mathbf s)</span> which prompts us to define the “energy” of a signal trajectory with respect to <span class="math inline">\theta</span> as <span><span class="math display">
E(\mathbf s, \theta) = -\ln q_\theta(\mathbf s) = -\ln P(\mathbf s) - \theta \ln \mathrm P(\mathbf x|\mathbf s)\,.
\qquad(16)</span></span> For <span class="math inline">\theta = 1</span> this definition of the energy matches our previous definition by analogy with the canonical ensemble whereas for <span class="math inline">\theta = 0</span> this definition of the energy is equivalent to the energy of a signal trajectory for a system where <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> are completely independent and thus <span class="math inline">\mathrm P(\mathbf s|\mathbf x) = \mathrm P(\mathbf s)</span>. Thus, this nomenclature also motivates the name “potential” for the quantity <span><span class="math display">
U(\mathbf s, \theta) = - \frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s) = \frac{\partial}{\partial\theta} E_\theta(\mathbf s) = -\ln \mathrm P(\mathbf x|\mathbf s)
\qquad(17)</span></span> i.e. <span class="math inline">\theta</span> acts as a <em>“knob”</em> that allows us to gradually turn the potential on or off. The potential term itself characterizes the amount of dependence between the random variables <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span>. Note that all energetic quantities depend on the specific response <span class="math inline">\mathbf x</span> (except at <span class="math inline">\theta=0</span>) even if this dependence is suppressed in the notation.</p>
<p>To use the TI estimators introduced in eqns. <a href="#eq:lambda_mc">14</a>, <a href="#eq:lambda_ni">15</a> we need to generate samples from arbitrary distributions along our chosen geometric path. Since we can compute the unnormalized densities of these distributions, we can use the Metropolis-Hastings algorithm as a very general method to sample from arbitrary distributions <span class="citation" data-cites="1970.Hastings">[<a href="#ref-1970.Hastings" role="doc-biblioref">16</a>]</span>.</p>
</section>
<section id="markov-chain-monte-carlo" class="level3" data-number="1.3.2">
<h3 data-number="4.3.2"><span class="header-section-number">4.3.2</span> Markov Chain Monte Carlo</h3>
<p>To generate approximately independent samples from a distribution given by the unnormalized density <span class="math inline">q_\theta</span> we start from an (in principle arbitrary) initial signal <span class="math inline">\mathbf s</span>. Next, a new signal <span class="math inline">\mathbf s^\prime</span> is proposed from the proposal distribution <span class="math inline">\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)</span> which is typically chosen to yield a <span class="math inline">\mathbf s^\prime</span> close to <span class="math inline">\mathbf s</span>. Then with some probability <span class="math inline">A(\mathbf s^\prime, \mathbf s)</span> we <em>accept</em> the new configuration and our first generated sample is <span class="math inline">\mathbf s_1 = \mathbf s^\prime</span>. Otherwise we <em>reject</em> the new configuration and our first sample is equal to the initial signal <span class="math inline">\mathbf s_1 = \mathbf s</span>. For the next iteration of the algorithm we then set our new initial signal to be <span class="math inline">\mathbf s \leftarrow \mathbf s_1</span> such that when we repeat this procedure many times we generate a sequence of signals <span class="math inline">\mathbf s_1, \mathbf s_2, \ldots</span> where each sample is a random value only directly dependent on the immediately preceding sample. Thus we have defined a Markov process that generates a <em>chain</em> of signals with the transition probability given by <span class="math inline">\mathrm P(\mathbf s \rightarrow \mathbf s^\prime) = T(\mathbf s \rightarrow \mathbf s^\prime)\,A(\mathbf s^\prime, \mathbf s)</span>. We want to choose the acceptance probability <span class="math inline">A(\mathbf s^\prime, \mathbf s)</span> such that the stationary distribution of this Markov process is precisely <span class="math inline">q_\theta</span>. It can be shown that the <em>Metropolis choice</em> <span id="eq:metropolis_acceptance"><span class="math display">
A(\mathbf s, \mathbf s^\prime) = \min\left( 1, \frac{q_\theta(\mathbf s^\prime)}{q_\theta(\mathbf s)} \frac{\mathrm T(\mathbf s^\prime \rightarrow \mathbf s)}{\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)} \right)
\qquad(18)</span></span> leads to the correct stationary distribution given that the system is ergodic.</p>

<figure>
<img src="figures/monte_carlo_sims.svg" id="fig:monte_carlo_sims" alt="" /></img><figcaption>Figure 1: Visualization of the log-likelihoods <span class="math inline">\ln\mathrm P(\mathbf x|\mathbf s)</span> and the acceptance rates <span class="math inline">\frac{\text{accepted}}{\text{accepted} + \text{rejected}}</span> during individual Monte-Carlo runs. Each MCMC run used a different value for <span class="math inline">\theta</span>, randomly chosen from the uniform distribution between 0 and 1. The <span class="math inline">x</span>-axis shows the sample numbers 1 to 100. Between one sample and the next one we skip 1000 accept-reject steps for which no statistics were collected.</figcaption>
</figure>
<figure>
<img src="figures/mcmc_covariance_comparison.svg" id="fig:mcmc_covariance" alt="" /></img><figcaption>Figure 2: Comparison of the covariance matrices obtained a) by computing the empirical covariance of 1000 approximately uncorrelated samples taken from the MCMC procedure (for <span class="math inline">\theta = 1</span>) and b) by analytically computing the covariance matrix of the normal distribution <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span>. The proposal distribution is a multivariate normal distribution with covariance <span class="math inline">\Sigma=\sigma^{-2} \mathbb I</span>, with a value of <span class="math inline">\sigma=0.01</span>.</figcaption>
</figure>
<p>For the Gaussian system we choose the proposal distribution <span class="math inline">\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)</span> to be a multivariate normal distribution centered around <span class="math inline">\mathbf s</span> and with uniform covariance <span class="math inline">\Sigma=\sigma^{-2} \mathbb I</span>. In fig. <a href="#fig:mcmc_covariance">2</a> we show that using the Metropolis-Hastings algorithm we can generate samples with an appropriate distribution that matches the analytical expectation. In fig. <a href="#fig:thermodynamic_int_results">3</a> we show the averaged potentials for 216 MCMC runs for different values of <span class="math inline">\theta</span>. From these potentials we can the compute the marginal density using the estimator from eq. <a href="#eq:lambda_mc">14</a>. The results are very promising since the estimated value differs by merely 0.012 % from the analytically correct value of <span class="math inline">\mathrm P(\mathbf x)</span>.</p>
<figure>
<img src="figures/mcmc_theromdynamic_integration.svg" id="fig:thermodynamic_int_results" alt="" /></img><figcaption>Figure 3: Samples of the averaged potential for different values of <span class="math inline">\theta</span>. There are 216 samples for values of <span class="math inline">\theta</span> chosen uniformly distributed in the interval <span class="math inline">[0, 1]</span>. Every point is an individual MCMC simulation with 1000 approximately independent draws. The bars on the right show a histogram of the log-likelihoods. The TI estimate is the integral from <span class="math inline">\theta=0</span> to <span class="math inline">1</span> of the curve that the individual samples approximate. Using the estimate from eq. <a href="#eq:lambda_mc">14</a>, the estimated value differs by merely 0.012 % from the analytically correct value of <span class="math inline">\mathrm P(\mathbf x)</span>. This shows that given enough samples, TI is able to provide very accurate results for the marginal density.</figcaption>
</figure>
</section>
</section>
<section id="estimating-the-density-of-states" class="level2" data-number="1.4">
<h2 data-number="4.4"><span class="header-section-number">4.4</span> Estimating the Density of States</h2>

<p>In the context of statistical physics we often look at configurations of a system that can be described by a configuration <span class="math inline">\mathbf{n}\in\Omega</span> where <span class="math inline">\Omega</span> is the state space of the system. We can typically assign a probability (density) to each configuration. For example, let’s consider the canonical ensemble for a given inverse temperature <span class="math inline">\beta</span> and Hamiltonian <span class="math inline">\mathcal H</span> <span id="eq:canonical_probability"><span class="math display">
\mathrm{P}(\mathbf{n}) = \frac{1}{Z(\beta)} e^{-\beta \mathcal H(\mathbf{n})}
\qquad(19)</span></span> with the <em>partition function</em> <span class="math inline">Z(\beta)=\int \mathrm{d}\mathbf{n}\ e^{-\beta H(\mathbf{n})}</span>. The Hamiltonian assigns an energy to every state, i.e. for every state <span class="math inline">\mathbf{n}</span> we have an associated energy <span class="math inline">\mathcal H(\mathbf{n})</span>. To learn more about the distribution of energies in our system we can now define the <em>density of states</em> <span class="math inline">g(E)</span> which is proportional to the number of states with energy <span class="math inline">E</span>. More precisely, let <span class="math inline">\mathcal{N}</span> be a random variable uniformly distributed in the state space, then <span><span class="math display">
g(E) = \mathrm{P}\left(\mathcal H(\mathcal N) = E\right)\,.
\qquad(20)</span></span></p>
<p>While the density of states (<em>DOS</em>) thus describes the number of states at individual energy levels, the Boltzmann factor <span class="math inline">e^{-\beta E}</span> specifies the relative weight of states with energy <span class="math inline">E</span> in the canonical ensemble. That is, we can compute the ensemble average <span class="math inline">\langle f(\mathcal H(\mathbf{n}))\rangle</span> of any function <span class="math inline">f</span> that depends only on the energy of a given state as <span id="eq:def_dos"><span class="math display">
\langle f(\mathcal H(\mathbf{n}))\rangle = 
\frac{\int_\Omega\mathrm d\mathbf n\ f(\mathcal H(\mathbf n)) e^{-\beta \mathcal H(\mathbf{n})}}{\int_\Omega\mathrm d\mathbf n\ e^{-\beta \mathcal H(\mathbf{n})}} = 
\frac{
\int\mathrm dE\ f(E)\ g(E) e^{-\beta E}
 }{
   \int\mathrm dE\ g(E) e^{-\beta E}
 }
\qquad(21)</span></span> where <span class="math inline">\int_\Omega\mathrm d\mathbf{n}</span> denotes an integral over phase space. Eq. <a href="#eq:def_dos">21</a> motivates the common way of specifying the DOS using the Dirac delta function <span id="eq:dirac_dos"><span class="math display">
g(E) = \int\limits_\Omega \mathrm d\mathbf n\ \delta(\mathcal H(\mathbf n) - E)
\qquad(22)</span></span> which matches the intuition of plotting an energy histogram for uniformly chosen states. I.e. for discrete energies <span class="math inline">E_1  \cdots  E_n</span> (the histogram bins) and random states <span class="math inline">\mathbf n_1,\ldots,\mathbf n_N</span> we can approximate the DOS as <span id="eq:dos_histogram"><span class="math display">
g_\text{discrete}(E_i) = \frac1N \sum\limits^N_{j=1} \delta_{\mathcal H(\mathbf n_j), E_i}
\qquad(23)</span></span> where <span class="math inline">\delta_{\epsilon, E_i}</span> is <span class="math inline">1</span> if the energy <span class="math inline">\epsilon</span> falls inside the <span class="math inline">i</span>-th histogram bin and <span class="math inline">0</span> otherwise. As the number of random states and the number of histogram bins grow towards infinity, <span class="math inline">g_\text{discrete}</span> converges to eq. <a href="#eq:dirac_dos">22</a>.</p>
<p>For us, the DOS is of relevance because can be used to compute the partition function <span id="eq:partition_fn_from_dos"><span class="math display">
Z(\beta) = \int\limits_\Omega \mathrm{d}\mathbf{n}\ e^{-\beta H(\mathbf{n})} = \int \mathrm dE\ g(E) e^{-\beta E}
\qquad(24)</span></span> and thus the free energy. In the following we will discuss the Wang and Landau algorithm to estimate the DOS and evaluate its usefulness for the computation of the marginal density of a trajectory.</p>

<section id="wang-and-landau-algorithm" class="level3" data-number="1.4.1">
<h3 data-number="4.4.1"><span class="header-section-number">4.4.1</span> Wang and Landau Algorithm</h3>
<p>Since the state spaces <span class="math inline">\Omega</span> are usually very large, one typically resorts to Monte-Carlo methods to estimate the density of states. There one generates a sequence of states <span class="math inline">\mathbf{n}_i</span> that are approximately independent and distributed according to <span class="math inline">\mathrm{P}(\mathcal{N})</span>, e.g. by using the Metropolis-Hastings algorithm. For every sampled state <span class="math inline">\mathbf{n}_i</span> we can compute the Energy <span class="math inline">\mathcal H(\mathbf{n}_i)</span> and then approximate the density of states by a histogram of the energy values as in eq. <a href="#eq:dos_histogram">23</a>. To get an accurate estimate of the density of states for energy values <span class="math inline">E</span> where <span class="math inline">g(E)</span> is very small we need a lot of iterations since we will on average pick very few samples with low probability.</p>
<p>The approach of Wang and Landau <strong>???</strong> is instead to not generate samples that are distributed according to the equilibrium distribution <span class="math inline">\mathrm{P}(\mathbf{n})</span> but to adaptively vary the sampling distribution throughout the simulation. This is done such that for every energy value <span class="math inline">E</span> approximately the same number of samples are acquired such that the DOS can be accurately estimated even in regions of low density <span class="math inline">g(E)</span>.</p>
<p>The main idea is to perform a random walk in energy space such that on average all energy levels in a predefined interval are visited equally often. If we switch from energy space to state space this implies that the probability density for this random walk to visit a state <span class="math inline">\mathbf n</span> is proportional to the reciprocal density of states <span class="math inline">1/g[\mathcal H(\mathbf n)]</span>. Of course we can’t sample directly using the reciprocal DOS since it is unknown. Instead, at each step of the algorithm we slightly alter our sampling distribution until the histogram of energy values becomes <em>flat</em>. Once the histogram is flat we conclude that the adaptively altered sampling distribution represents precisely the reciprocal DOS.</p>
<p>To perform Wang-Landau sampling we have to define energy bins <span class="math inline">E_1,\ldots,E_n</span> that represent the range of energies that we want to compute the DOS for. We start by setting <span class="math inline">g(E_i)=1</span> for all <span class="math inline">i=1,\ldots,n</span>. Then—similarly to Metropolis-Hastings sampling—we iteratively propose and selectively accept new configurations such that the transition probability from energy level <span class="math inline">E_i\rightarrow E_j</span> is <span><span class="math display">
p(E_i\rightarrow E_j) = \min\left( 1, \frac{g(E_i)}{g(E_j)} \right)\,.
\qquad(25)</span></span> After each proposal we update a histogram of visited energies <span class="math inline">H(E_j)\leftarrow H(E_j) + 1</span> and modify the density of states at <span class="math inline">E_j</span> by a constant factor <span class="math inline">g(E_j)\leftarrow f\ g(E_j)</span>. This updating of the sampling distribution during the simulation is precisely what makes the random walk non-Markovian and promises fast convergence towards the correct DOS. We start the procedure with the factor <span class="math inline">f=\exp(1)=e</span>. Once the histogram <span class="math inline">H(E)</span> is sufficiently flat (we use 95% flatness) we update <span class="math inline">f\leftarrow \sqrt{f}</span> and reset the histogram to continue sampling. We continue the simulation, iteratively reducing <span class="math inline">f</span> until it reaches a small predefined threshold value which allows us to adjust the tradeoff between accuracy and simulation speed.</p>
<p>One important consideration is the choice of energy bins. Since we are interested in the computation of the partition function using eq. <a href="#eq:partition_fn_from_dos">24</a>, the relevant energies are those where the product <span class="math inline">g(E)e^{-\beta E}</span> is not vanishingly small. Additionally we have to take into account that the estimate for the DOS is not normalized. To be able to correctly normalize the DOS we have to ensure that the range of energy bins includes all energies where the DOS is non-vanishing.</p>
</section>
<section id="applying-wang-landau-to-the-computation-of-the-marginal-density" class="level3" data-number="1.4.2">
<h3 data-number="4.4.2"><span class="header-section-number">4.4.2</span> Applying Wang-Landau to the Computation of the Marginal Density</h3>
<section id="modified-dos" class="level4" data-number="1.4.2.1">
<h4 data-number="4.4.2.1"><span class="header-section-number">4.4.2.1</span> Modified DOS</h4>
<p>When working with statistical models such as the Ising model there is often a clear concept of the <em>state space</em> <span class="math inline">\Omega</span> and an associated volume of regions in state space such that integrals of the form <span class="math inline">\int_\Omega\mathrm d\mathbf n\ f(\mathbf n)</span> are well-defined for any <span class="math inline">f: \Omega\rightarrow\mathbb{R}</span>. However in the case where the individual states <span class="math inline">\mathbf n</span> represent stochastic trajectories it is not obvious what the meaning of such an integral should be. Therefore we use a modified DOS defined for a given response trajectory <span class="math inline">\mathbf x</span> by <span id="eq:modified_dos"><span class="math display">
\rho(U) = \int\mathrm d\mathbf s\ \mathrm P(\mathbf s)\,\delta(U(\mathbf s, \mathbf x) - U)
\qquad(26)</span></span> with <span class="math inline">U(\mathbf s, \mathbf x) = -\ln\mathrm P(\mathbf x|\mathbf s)</span>. In other words we are assigning a measure <span class="math inline">\mu</span> to our state space which is defined by the inherent probability density of the signals, such that <span class="math inline">\int\mu(\mathrm d\mathbf s) \equiv \int\mathrm d\mathbf s\ \mathrm P(\mathbf s)</span>. Thus we can express the marginal density of <span class="math inline">\mathbf x</span> analogously to eq. <a href="#eq:partition_fn_from_dos">24</a> by <span id="eq:modified_int"><span class="math display">
\mathrm P(\mathbf x) = \int\mathrm dU\ \rho(U)\,e^{-U}\,.
\qquad(27)</span></span></p>
</section>
<section id="modified-wang-landau-algorithm" class="level4" data-number="1.4.2.2">
<h4 data-number="4.4.2.2"><span class="header-section-number">4.4.2.2</span> Modified Wang-Landau algorithm</h4>
<p>We have to slightly adapt the Wang-Landau procedure described above so that it produces an estimate of the modified DOS. To account for the density <span class="math inline">\mathrm P(\mathbf s)</span> in eq. <a href="#eq:modified_dos">26</a> we need ensure we propose configurations, asymptotically distributed according to <span class="math inline">\mathrm P(\mathbf s)</span>, which we then—in a second step—accept or reject using the inverse DOS. However we can combine both of these steps into a single one by combining a Metropolis acceptance step with the usual Wang-Landau procedure. Our algorithm therefore consists of the following steps:</p>
<ol type="1">
<li>Set all entries of the modified DOS to 1, <span class="math inline">\rho(U_i)=1, i=1,\ldots,n</span>.</li>
<li>Set all entries of the histogram to 0, <span class="math inline">H(U_i)=0, i=1,\ldots,n</span>.</li>
<li>Loop until <span class="math inline">f\epsilon</span>.
<ol type="1">
<li>Propose a new configuration <span class="math inline">\mathbf s^\prime\sim T(\mathbf s\rightarrow \mathbf s^\prime)</span>.</li>
<li>Let <span class="math inline">U_i</span> be the potential of state <span class="math inline">\mathbf s</span> and <span class="math inline">U_j</span> the potential of state <span class="math inline">\mathbf s^\prime</span>.</li>
<li>Accept the new configuration with probability <span id="eq:modified_acceptance_probability"><span class="math display">A(\mathbf s^\prime, \mathbf s) = \min\left[1, \frac{\mathrm P(\mathbf s^\prime)}{\mathrm P(\mathbf s)} \frac{\rho(U_i)}{\rho(U_j)} \frac{T(\mathbf s^\prime\rightarrow \mathbf s)}{T(\mathbf s\rightarrow \mathbf s^\prime)} \right]\,.
 \qquad(28)</span></span></li>
<li>Let <span class="math inline">U^\star</span> be either <span class="math inline">U_j</span> if <span class="math inline">\mathbf s^\prime</span> was accepted or <span class="math inline">U_i</span> otherwise.</li>
<li>Update the histogram <span class="math inline">H(U^\star)\leftarrow H(U^\star)+1</span> and the DOS <span class="math inline">\rho(U^\star)\leftarrow f\,\rho(U^\star)</span>.</li>
<li>If the histogram <span class="math inline">H</span> is flat, set <span class="math inline">f\leftarrow\sqrt f</span> and reset <span class="math inline">H(U_i)=0, i=1,\ldots,n</span>.</li>
</ol></li>
</ol>
<p>The proposal distribution <span class="math inline">T</span> can in principle be arbitrary. The definition of the acceptance probability in eq. <a href="#eq:modified_acceptance_probability">28</a> illustrates that—once the simulation is converged—<span class="math inline">\rho</span> describes how we have to modify the state space density <span class="math inline">\mathrm P(\mathbf s)</span> such that we sample uniformly over all potentials.</p>
</section>
<section id="comparison-to-usual-wang-landau-algorithm" class="level4" data-number="1.4.2.3">
<h4 data-number="4.4.2.3"><span class="header-section-number">4.4.2.3</span> Comparison to usual Wang-Landau algorithm</h4>
<p>Usually the Wang-Landau algorithm is used to estimate the regular DOS <span class="math inline">g(E)=\int\mathrm d\mathbf s\ \delta(E(\mathbf s, \mathbf x) - E)</span> where <span class="math inline">E(\mathbf s, \mathbf x)=-\ln\mathrm P(\mathbf s, \mathbf x)</span>. We can easily verify that algebraically this definition of <span class="math inline">E(\mathbf s, \mathbf x)</span> satisfies equation eq. <a href="#eq:partition_fn_from_dos">24</a> such that <span><span class="math display">
Z = \mathrm P(\mathbf x) = \int\mathrm dE\ g(E)e^{-E}\,.
\qquad(29)</span></span> The Wang-Landau algorithm to compute the DOS <span class="math inline">g(E)</span> would be the same as the ones described above with the sole difference being the acceptance rate which would instead be <span id="eq:acceptance_probability"><span class="math display">
\tilde A(\mathbf s^\prime, \mathbf s) =  \min\left[1,\frac{\rho(U_i)}{\rho(U_j)} \frac{T(\mathbf s^\prime\rightarrow \mathbf s)}{T(\mathbf s\rightarrow \mathbf s^\prime)} \right]\,.
\qquad(30)</span></span> The difference between eq. <a href="#eq:modified_acceptance_probability">28</a> and eq. <a href="#eq:acceptance_probability">30</a> precisely reflects the fact that <span class="math inline">\rho(E)</span> and <span class="math inline">g(E)</span> are defined using different integration measures (<span class="math inline">\rho(E)</span> includes <span class="math inline">\mathrm P(\mathbf s)</span> in its integral in eq. <a href="#eq:modified_dos">26</a> while <span class="math inline">g(E)</span> does not). However the regular version of the Wang-Landau algorithm can’t be used in practice to compute the marginal density in the multivariate normal system that we are using since the regular DOS grows without bound as <span class="math inline">E\rightarrow\infty</span>: In our case the joint distribution <span class="math inline">\mathrm P(\mathbf s, \mathbf x)</span> is a multivariate normal distribution in <span class="math inline">2d</span> dimensions such that for any number <span class="math inline">\epsilon0</span> there exists a <span class="math inline">2d</span>-dimensional ellipsoid that contains all points such that <span class="math inline">E(\mathbf s, \mathbf x)\leq\epsilon</span>. The DOS <span class="math inline">g(\epsilon)</span> is precisely the volume of the <span class="math inline">2d-1</span> dimensional surface of this ellipsoid. As we increase <span class="math inline">\epsilon</span> the size of the ellipsoid also keeps increasing such that <span class="math inline">\lim_{\epsilon\rightarrow\infty} g(\epsilon)=\infty</span>. This behavior of the regular DOS makes it impossible to use the Wang-Landau algorithm to compute <span class="math inline">g(E)</span> since by its design the algorithm merely estimates the unnormalized DOS. For this reason we have to modify the DOS as is done in eq. <a href="#eq:modified_dos">26</a> which ensures that we can normalize the result of the Wang-Landau algorithm.</p>
</section>
<section id="connection-to-standard-monte-carlo-sampling" class="level4" data-number="1.4.2.4">
<h4 data-number="4.4.2.4"><span class="header-section-number">4.4.2.4</span> Connection to Standard Monte-Carlo Sampling</h4>
<p>When we perform a standard Monte-Carlo estimate of <span class="math inline">\mathrm{P}(\mathbf{x})</span> we generate independent samples <span class="math inline">\mathbf{s}_1,\ldots,\mathbf{s}_M</span>, all identically distributed according to <span class="math inline">\mathrm P(\mathbf{s})</span> and then compute <span><span class="math display">
\hat{\mathrm{P}}(\mathbf{x}) = \frac{1}{M} \sum\limits^M_{i=1} \mathrm{P}(\mathbf x|\mathbf s_i) \,.
\qquad(31)</span></span> This estimate is essentially the same as performing the integral from eq. <a href="#eq:modified_int">27</a> where the density of states <span class="math inline">\rho(U)</span> is just approximated as the histogram of the potentials <span class="math inline">U(\mathbf{s}_1),\ldots,U(\mathbf{s}_M)</span>. Specifically in the limit of the width of histogram bins approaching 0, the approximate modified density of states becomes <span class="math inline">\hat{\rho}(U)=1/M\ \sum^M_{i=1} \delta(U-U(\mathbf{s}_i))</span> and therefore <span><span class="math display">
\int\mathrm{d}U\ \hat{\rho}(U) e^{-U} = \frac{1}{M}\int\mathrm dU \left[\sum^M_{i=1} \delta(U-U(\mathbf{s}_i)) e^{-U}\right] = \frac{1}{M} \sum\limits^M_{i=1} e^{-U(\mathbf{s}_i)} = \hat{\mathrm{P}}(\mathbf{x})\,.
\qquad(32)</span></span></p>
<p>For the purpose of comparing estimates we can therefore associate the standard MC approach with computing the empirical histogram of potential values when sampling signals according to their marginal distribution. In the next section we will compare this empirical histogram to the DOS as computed using the Wang-Landau algorithm.</p>
</section>
</section>
<section id="example-results-for-a-wang-landau-simulation" class="level3" data-number="1.4.3">
<h3 data-number="4.4.3"><span class="header-section-number">4.4.3</span> Example Results for a Wang-Landau Simulation</h3>
<figure>
<img src="figures/normalized_densities.svg" id="fig:normalized_densities" alt="" /></img><figcaption>Figure 4: Illustrating the benefit of using the Wang-Landau algorithm for the multivariate normal system at different dimensionalities: The blue lines show the modified density of states from eq. <a href="#eq:modified_dos">26</a>, computed using a conventional MC simulation. The orange line represents the Boltzmann factor <span class="math inline">e^{-U}</span> and the green line shows the integrand of eq. <a href="#eq:modified_int">27</a> which is the product of the other two quantities. For visualization purposes, all functions where rescaled such that their integrals over the displayed interval equal 1. We see that especially at higher dimensionality there is very little overlap between the green and the blue line which leads to high inaccuracy in the computation of the marginal density. For all simulations we chose the covariance matrix using <span class="math inline">\Delta t = 64</span>.</figcaption>
</figure>
<p>Fig. <a href="#fig:normalized_densities">4</a> makes it clear why we expect Wang-Landau sampling to lead to a better estimate of the marginal density than the brute-force Monte-Carlo computation, especially in high-dimensional state spaces. For <span class="math inline">d=50</span> and <span class="math inline">d=200</span> most of the weight of the integral is in regions where <span class="math inline">\rho(E)\approx 0</span>. In these low density regions we usually get a very inaccurate estimation of the (modified) DOS by normal MC simulations since we only very occasionally sample a relevant state. The Wang-Landau algorithm ensures that for every energy there is a consistent sampling density and we get a good estimate of the DOS even in low-density regimes.</p>
<p>From fig. <a href="#fig:normalized_densities">4</a> we can also estimate for which range of potentials we must compute the DOS. Since the Boltzmann weight <span class="math inline">e^{-U}</span> strongly favors low-potential configurations it is important to compute the DOS for very low potentials even if it nearly vanishes there (i.e. in regions where the blue line vanishes but the green line has relevant weight).</p>
<figure>
<img src="figures/wl_dos.svg" id="fig:wl_dos" alt="" /></img><figcaption>Figure 5: Plots of estimates of the modified DOS from eq. <a href="#eq:modified_dos">26</a> compared on both linear and log scales. The blue line shows the Wang-Landau estimate while the orange line is a histogram estimate using unbiased sampling according to <span class="math inline">\mathrm P(\mathbf s)</span>. We see that especially in the low-potential regime the Wang-Landau estimate is much more accurate.</figcaption>
</figure>
<p>In fig. <a href="#fig:wl_dos">5</a> we display the estimated DOS using the Wang-Landau algorithm compared with a histogram estimate of the DOS using unbiased sampling. We see that in the highly relevant regime of low potential the Wang-Landau procedure allows us to get an accurate estimate of the DOS even though its density is as low as <span class="math inline">e^{-45}\approx 10^{-20}</span>. Using eq. <a href="#eq:modified_int">27</a> we compute the marginal density to be <span class="math inline">-664.01</span> whereas the “correct” value computed analytically is <span class="math inline">-664.24</span>. We thus find a relative error of <span class="math inline">0.03\%</span> in this estimate.</p>
<p>We have found two methods, Thermodynamic Integration and Wang-Landau sampling to show very promising results for the estimation of the marginal density. So far however, we have only tested these methods using the Gaussian approximation where it is especially easy to generate trial moves to be used in the MCMC schemes. Since in the Gaussian approximation a trajectory is described by a <span class="math inline">d</span>-dimensional vector <span class="math inline">\mathbf s = (s^1,\ldots,s^d)^T\in\mathbb{R}^d</span> we can simply generate a small <em>displacement vector</em> <span class="math inline">\xi\in\mathbb{R}^d</span> from an appropriate multivariate normal with sufficiently small covariance such that we have a proposal <span class="math inline">\mathbf s^\prime = (s^1 + \xi^1,\ldots,s^d + \xi^d)</span>. Given a symmetric distribution of displacements, the proposal is naturally also symmetric. With all that said, using the Gaussian approximation we can only describe a fairly limited range of stochastic processes. Since the signal dynamics are fully characterized by their first- and second-order statistics it fails to describe non-Markovian or discrete signals. Going beyond the Gaussian approximation, we are interested in signals that are described by a general stochastic differential equation (SDE). We have already discussed how to generate trajectories from SDEs in TODO. In the next section we will therefore explore some ideas for the generation of appropriate trial moves for such general stochastic trajectories.</p>
</section>
</section>
<section id="generating-proposal-trajectories-from-general-stochastic-dynamics" class="level2" data-number="1.5">
<h2 data-number="4.5"><span class="header-section-number">4.5</span> Generating Proposal Trajectories from General Stochastic Dynamics</h2>
<ul>
<li><p>Our goal is, given an initial trajectory <span class="math inline">\mathbf s</span>, to generate a correlated trajectory <span class="math inline">\mathbf s^\prime</span>, distributed according to <span class="math inline">e^{-E(\mathbf s)}</span> where <span class="math inline">E(\mathbf s) = -\ln \mathrm P(\mathbf s) + U(\mathbf s)</span></p></li>
<li><p>Generate trials from P(s), then accept/reject</p></li>
<li><p>Other interesting approaches: Guided proposals</p></li>
</ul>
</section>
<section id="marginalizing-out-individual-components-of-the-biochemical-network" class="level2" data-number="1.6">
<h2 data-number="4.6"><span class="header-section-number">4.6</span> Marginalizing Out Individual Components of the Biochemical Network</h2>
<p>So far, the computation of the mutual information is limited to the case where the signal directly interacts with the response…</p>
</section>
<section id="discussion" class="level2" data-number="1.7">
<h2 data-number="4.7"><span class="header-section-number">4.7</span> Discussion</h2>
<p>We have shown that methods originally developed for computing ensemble averages in statistical physics can be very successfully applied to the computation of marginal densities from a known joint density. Computing the marginal densities forms the basis for many Bayesian computations (including the computation of information theoretic quantities like the mutual information) and is therefore also relevant to a wide variety of researchers in fields outside of statistical physics. Before we can make use the algorithms from statistical physics we have to map quantities like <em>energy</em> and the <em>partition function</em> to the corresponding probability densities. Once these terms are properly defined we suddenly have access to a wide variety of literature on statistical physics to aid us with efficient computation of the marginal entropy. Specifically we evaluated the usefulness of thermodynamic integration and the Wang-Landau algorithm for multivariate normal distributions.</p>
<p>Using Markov Chain Monte Carlo sampling together with thermodynamic integration we were able to achieve very good accuracy in estimates of <span class="math inline">\mathrm P(\mathbf x)</span> with a reasonable amount of computation time. We do not find any inherent bias in the estimates as we did for the brute-force Monte-Carlo estimate. The drawback of TI is that we need to produce samples using MCMC sampling. In practice to efficiently generate samples we need to find a good proposal distribution <span class="math inline">\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)</span> that yields proposals <span class="math inline">\mathbf s^\prime</span> that are <em>nearby</em> the previous signal <span class="math inline">\mathbf s</span> such that there is on average a good chance that the proposal will be accepted according to eq. <a href="#eq:metropolis_acceptance">18</a>. On the other hand it is necessary for fast convergence that <span class="math inline">\mathbf s^\prime</span> is not <em>too close</em> to <span class="math inline">\mathbf s</span> such that the sample chain explores a sufficiently large portion of the state space. While for our toy model it is relatively easy to come up with reasonable proposals, for stochastic trajectories this is less clear. Therefore we have proposed some ideas for possible trial moves in the space of trajectories. Even though TI seems to be a promising method for the computation of marginal densities, we also tested another technique that was originally developed in physics of condensed matter, the <em>Wang-Landau algorithm</em>.</p>
<p>While we can achieve a very precise estimate for the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> using the estimated DOS from the Wang-Landau algorithm there remain some practical difficulties. For maximum efficiency and accuracy the different parameters affecting the procedure such as the required histogram flatness, the updating scheme of the <span class="math inline">f</span> parameter, and the choice of potential bins have to be tuned for a given problem. After some tuning of these parameters for the Gaussian system for a fixed set of covariance matrices we still find the estimation to be at least one order of magnitude slower in CPU time compared to thermodynamic integration. Therefore, at least for the Gaussian system thermodynamic integration seems to be better suited to compute the marginal density.</p>
<p>With that said, we do expect the Wang-Landau procedure to perform especially well in cases were there are many local minima of the potential. Here using TI we might get <em>“stuck”</em> in a specific minimum and thus not sample all relevant states. Therefore we suggest that while TI should be the method of choice for the computation of the marginal density for high dimensional systems, in specific cases it may make sense to try other approaches that are well-established in statistical physics, such as Wang-Landau.</p>
<p>Even if we can compute the mutual information more efficiently by using TI without estimating the DOS for individual responses it is worth noting that the intuitive picture behind the DOS shows very clearly why the brute-force Monte-Carlo estimates of the marginal density can converge very slowly. Particularly figs. <a href="#fig:normalized_densities">4</a>, <a href="#fig:wl_dos">5</a> illustrate why more advanced simulation methods are unavoidable for the computation of marginal densities in high-dimensional state spaces. Looking at plots of the DOS can help to understand structural properties about the system at hand and is much easier to visualize than the high-dimensional state space.</p>
</section>
</section>
<section id="conclusion" class="level1" data-number="2">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusion</h1>
<p>We are developing a novel approach to estimate the mutual information between a environmental signal and a cellular response, fully taking into account the time-dependent stochastic dynamics. In principle, this approach is applicable to any biochemical signaling network that can be described by a master equation. One main issue that we found is the computation of accurate estimates of the marginal density which is defined by the integral <span class="math inline">\mathrm P(\mathbf x) = \int \mathrm d\mathbf s\,\mathrm P(\mathbf s)\,\mathrm P(\mathbf x|\mathbf s)</span>. By understanding the close relationship between that integral and the estimation of free energy differences, we were able to employ powerful computational methods originating in statistical physics. In that regard we have produced some promising results, yet it is clear that the work is not completed until we can demonstrate an accurate estimate for the mutual information for a simple biochemical network.</p>
<section id="summary-of-main-results" class="level2" data-number="2.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Summary of Main Results</h2>
<p>To quantify the fidelity of biochemical networks, we motivated the computation of the <em>information rate</em> between a time-varying environmental signal and a cellular response. The information rate describes the (asymptotic) increase of mutual information (MI) with the duration of the signal. Using the very mild assumptions that a) the signal can be described by a stochastic differential equation, and b) the biochemical information processing network can be modeled by a master equation, we derived a general Monte Carlo procedure to compute the MI between signals and responses of arbitrary duration. It is based on our ability to generate independent sample signals and—for any given signal—the ability to generate an appropriate response. Crucially, we have shown, how for a given signal <span class="math inline">\mathbf s</span> and response <span class="math inline">\mathbf x</span> we can compute the so-called log-likelihood <span class="math inline">\ln\mathrm P(\mathbf x|\mathbf s)</span> using only terms from the master equation. One part of the Monte Carlo procedure consists in averaging these log-likelihoods for independently generated signals and responses. The second part of the computation is much harder since it consists in computing the average over the logarithm of the integrated likelihood <span class="math inline">\ln\int \mathrm d\mathbf s\,\mathrm P(\mathbf s)\,\mathrm P(\mathbf x|\mathbf s)</span> for different responses.</p>
<p>An important contribution of this thesis is the careful analysis of the issues that can arise while numerically computing integrals of that form. If we merely use a standard Monte Carlo computation to evaluate the integrated likelihood we find that we consistently over-estimate the overall information rate. By approximating the signals and responses as Gaussian processes we were able to understand where this problem comes from. When randomly generating signals, as the duration grows it becomes increasingly unlikely to occasionally stumble upon a signal that contributes to the integral <span class="math inline">\int \mathrm d\mathbf s\,\mathrm P(\mathbf s)\,\mathrm P(\mathbf x|\mathbf s)</span>. It is easy to imagine that a given, time-varying response <span class="math inline">\mathbf x</span> could only have arisen from a very narrow set of similar signals with the only difference between them being some small, insignificant fluctuations. In principle however, we have a huge variety of possible signal realizations that could have happened. We can understand that combing through the vast set of possible signals in search of that narrow subset of signals which contribute to the integral is very inefficient if done by brute force. It is not unlike searching for a needle in the haystack.</p>
<p>By having understood the problem we were able to infer what changes would lead to an improved estimate. The solution lies in the modification of the sampling strategy for the signals in such a way that we are more likely to find the strongly contributing ones. Pictorially speaking, this is perhaps comparable to the use of a metal proximity detector to help with the search of the needle. In the literature, there have been suggested multiple different but related ideas to modify sampling strategies in order to get more accurate results. While reviewing a few of the common methods we realized that many of these were inspired by techniques that originated in statistical physics for the estimation of free energy differences.</p>
<p>Thus, by changing the mathematical formulation of our problem we are able to see the computation of the marginal entropy akin to the computation of a free energy. Using this insight we have shown that using either of two well-known methods, <em>thermodynamic integration</em> and <em>Wang-Landau sampling</em> we are able to estimate the marginal likelihood much more efficiently for trajectories in the Gaussian approximation. While these ideas have not yet been tested on real stochastic trajectories, the results so far are very promising.</p>
<p>We propose that this thesis is an important step towards a general algorithmic framework to compute mutual information for arbitrary stochastic biological systems.</p>
</section>
<section id="outlook" class="level2" data-number="2.2">
<h2 data-number="5.2"><span class="header-section-number">5.2</span> Outlook</h2>
<ul>
<li>areas still to explore
<ul>
<li>test on “real systems”</li>
<li>efficient generation of proposal trajectories</li>
<li>look beyond biochemical networks, described by a master equation?</li>
</ul></li>
</ul>
</section>
</section>
<section id="references" class="level1 unnumbered" data-number="">
<h1 class="unnumbered" data-number="3">References</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-2014.Held">
<p>[1] L. Held, D.S. Bové, Applied Statistical Inference, in: Applied Statistical Inference, Springer Berlin Heidelberg, Berlin, Heidelberg, 2014: pp. 247–289.</p>
</div>
<div id="ref-1997.Diciccio">
<p>[2] T.J. Diciccio, R.E. Kass, A. Raftery, L. Wasserman, Computing Bayes Factors by Combining Simulation and Asymptotic Approximations, Journal of the American Statistical Association. 92 (1997) 903–915. <a href="https://doi.org/10.1080/01621459.1997.10474045">https://doi.org/10.1080/01621459.1997.10474045</a>.</p>
</div>
<div id="ref-2011.Chan">
<p>[3] J.C.C. Chan, D.P. Kroese, Improved cross-entropy method for estimation, Statistics and Computing. 22 (2011) 1031–1040. <a href="https://doi.org/10.1007/s11222-011-9275-7">https://doi.org/10.1007/s11222-011-9275-7</a>.</p>
</div>
<div id="ref-2014.Chan">
<p>[4] J.C.C. Chan, E. Eisenstat, Marginal Likelihood Estimation with the Cross-Entropy Method, Econometric Reviews. 34 (2014) 256–285. <a href="https://doi.org/10.1080/07474938.2014.944474">https://doi.org/10.1080/07474938.2014.944474</a>.</p>
</div>
<div id="ref-2014.Perrakis">
<p>[5] K. Perrakis, I. Ntzoufras, E.G. Tsionas, On the use of marginal posteriors in marginal likelihood estimation via importance sampling, Computational Statistics  Data Analysis. 77 (2014) 54–69. <a href="https://doi.org/10.1016/j.csda.2014.03.004">https://doi.org/10.1016/j.csda.2014.03.004</a>.</p>
</div>
<div id="ref-1994.Tierney">
<p>[6] L. Tierney, Markov Chains for Exploring Posterior Distributions, The Annals of Statistics. 22 (1994) 1701–1728. <a href="https://doi.org/10.1214/aos/1176325750">https://doi.org/10.1214/aos/1176325750</a>.</p>
</div>
<div id="ref-1990.Gelfand">
<p>[7] A.E. Gelfand, A.F.M. Smith, Sampling-Based Approaches to Calculating Marginal Densities, Journal of the American Statistical Association. 85 (1990) 398–409. <a href="https://doi.org/10.1080/01621459.1990.10476213">https://doi.org/10.1080/01621459.1990.10476213</a>.</p>
</div>
<div id="ref-1987.Tanner">
<p>[8] M.A. Tanner, W.H. Wong, The Calculation of Posterior Distributions by Data Augmentation, Journal of the American Statistical Association. 82 (1987) 528–540. <a href="https://doi.org/10.1080/01621459.1987.10478458">https://doi.org/10.1080/01621459.1987.10478458</a>.</p>
</div>
<div id="ref-2001.Neal">
<p>[9] R.M. Neal, Annealed importance sampling, Statistics and Computing. 11 (2001) 125–139. <a href="https://doi.org/10.1023/a:1008923215028">https://doi.org/10.1023/a:1008923215028</a>.</p>
</div>
<div id="ref-2018.Warne">
<p>[10] D.J. Warne, R.E. Baker, M.J. Simpson, Multilevel rejection sampling for approximate Bayesian computation, Computational Statistics  Data Analysis. 124 (2018) 71–86. <a href="https://doi.org/10.1016/j.csda.2018.02.009">https://doi.org/10.1016/j.csda.2018.02.009</a>.</p>
</div>
<div id="ref-1994.Newton">
<p>[11] M.A. Newton, A.E. Raftery, Approximate Bayesian Inference with the Weighted Likelihood Bootstrap, Journal of the Royal Statistical Society: Series B (Methodological). 56 (1994) 3–26. <a href="https://doi.org/10.1111/j.2517-6161.1994.tb01956.x">https://doi.org/10.1111/j.2517-6161.1994.tb01956.x</a>.</p>
</div>
<div id="ref-1994.Gelfand">
<p>[12] A.E. Gelfand, D.K. Dey, Bayesian Model Choice: Asymptotics and Exact Calculations, Journal of the Royal Statistical Society: Series B (Methodological). 56 (1994) 501–514. <a href="https://doi.org/10.1111/j.2517-6161.1994.tb01996.x">https://doi.org/10.1111/j.2517-6161.1994.tb01996.x</a>.</p>
</div>
<div id="ref-1976.Bennett">
<p>[13] C.H. Bennett, Efficient estimation of free energy differences from Monte Carlo data, Journal of Computational Physics. 22 (1976) 245–268. <a href="https://doi.org/10.1016/0021-9991(76)90078-4">https://doi.org/10.1016/0021-9991(76)90078-4</a>.</p>
</div>
<div id="ref-1996.Meng">
<p>[14] X.-L. Meng, W.H. Wong, Simulating Ratios of Normalizing Constants Via a Simple Identity: A Theoretical Exploration, Statistica Sinica. 6 (1996) 831—860. <a href="http://www.jstor.org/stable/24306045">http://www.jstor.org/stable/24306045</a>.</p>
</div>
<div id="ref-1998.Gelman">
<p>[15] A. Gelman, X.-L. Meng, Simulating normalizing constants: from importance sampling to bridge sampling to path sampling, Statistical Science. 13 (1998) 163–185. <a href="https://doi.org/10.1214/ss/1028905934">https://doi.org/10.1214/ss/1028905934</a>.</p>
</div>
<div id="ref-1970.Hastings">
<p>[16] W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications, Biometrika. 57 (1970) 97–109. <a href="https://doi.org/10.1093/biomet/57.1.97">https://doi.org/10.1093/biomet/57.1.97</a>.</p>
</div>
</div>
</section>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        
        

        

        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        

    </body>
</html>