<!DOCTYPE HTML>
<html lang="en-us" class="sidebar-visible no-js Light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Mutual Information between Trajectories</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.min.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
        <script>document.addEventListener("DOMContentLoaded", function () {
            var mathElements = document.getElementsByClassName("math");
            var regex = /\\qquad\W*\(([0-9]+)\)/;
            for (var i = 0; i < mathElements.length; i++) {
                var texText = mathElements[i].firstChild;
                if (mathElements[i].tagName == "SPAN") {
                    var tex_str = texText.data.replace(regex, "\\tag{$1}");
                    katex.render(tex_str, mathElements[i], {
                    displayMode: mathElements[i].classList.contains('display'),
                    throwOnError: false,
                    fleqn: false
                });
            }}});
        </script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "" : "Light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('Light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="expanded"><a href="index.html" class=""><span class="header-section-number">1</span> Preface
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html" class=""><span class="header-section-number">2</span> Mutual Information for Trajectories in a Gaussian Framework
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#introduction" class=""><span class="header-section-number">2.1</span> Introduction
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#monte-carlo-estimate-for-the-marginal-entropy" class=""><span class="header-section-number">2.2</span> Monte-Carlo Estimate for the Marginal Entropy
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#choice-of-covariance-matrices" class=""><span class="header-section-number">2.2.1</span> Choice of Covariance Matrices
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#direct-importance-sampling" class=""><span class="header-section-number">2.2.2</span> Direct Importance Sampling
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#umbrella-sampling" class=""><span class="header-section-number">2.2.3</span> Umbrella Sampling
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#estimating-the-conditional-entropy" class=""><span class="header-section-number">2.3</span> Estimating the Conditional Entropy
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#discussion" class=""><span class="header-section-number">2.4</span> Discussion
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#references" class="">References
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html" class=""><span class="header-section-number">3</span> Information theory for trajectories
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="information-theory-for-trajectories.html#monte-carlo-simulation" class=""><span class="header-section-number">3.1</span> Monte-Carlo simulation
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#estimating-the-likelihood" class=""><span class="header-section-number">3.2</span> Estimating the likelihood
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="information-theory-for-trajectories.html#the-probability-density-for-the-starting-point-of-a-trajectory" class=""><span class="header-section-number">3.2.1</span> The probability density for the starting point of a trajectory
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#the-transition-probabilities" class=""><span class="header-section-number">3.2.2</span> The transition probabilities
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#estimating-the-marginal-probability-of-response-trajectories" class=""><span class="header-section-number">3.2.3</span> Estimating the marginal probability of response trajectories
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#chemical-master-equation" class=""><span class="header-section-number">3.3</span> Chemical Master Equation
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#jump-processes" class=""><span class="header-section-number">3.4</span> Jump Processes
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#simulating-a-biochemical-network-driven-by-an-external-signal" class=""><span class="header-section-number">3.5</span> Simulating a Biochemical Network Driven by an External Signal
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#references" class="">References
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html" class=""><span class="header-section-number">4</span> Estimation Strategies Inspired by Statistical Physics
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#borrowing-terminology-from-statistical-physics" class=""><span class="header-section-number">4.1</span> Borrowing Terminology from Statistical Physics
                    </a>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#thermodynamic-integration" class=""><span class="header-section-number">4.2</span> Thermodynamic Integration
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#summary-of-ti" class=""><span class="header-section-number">4.2.1</span> Summary of TI
                    </a>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#markov-chain-monte-carlo" class=""><span class="header-section-number">4.2.2</span> Markov Chain Monte Carlo
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#estimating-the-density-of-states" class=""><span class="header-section-number">4.3</span> Estimating the Density of States
                    </a>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#wang-and-landau-algorithm" class=""><span class="header-section-number">4.4</span> Wang and Landau Algorithm
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#applying-wang-landau-to-the-computation-of-the-marginal-density" class=""><span class="header-section-number">4.4.1</span> Applying Wang-Landau to the Computation of the Marginal Density
                    </a>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#connection-to-standard-monte-carlo-sampling" class=""><span class="header-section-number">4.4.2</span> Connection to Standard Monte-Carlo Sampling
                    </a>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#results-for-wang-landau" class=""><span class="header-section-number">4.4.3</span> Results for Wang Landau
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="estimation-strategies-inspired-by-statistical-physics.html#references" class="">References
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="chapter_5.html" class="">
                    </a>
                    </li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                    </div>

                    <h1 class="menu-title">Mutual Information between Trajectories</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        <a href="https://github.com/manuel-rhdt/master-thesis" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <section id="index" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Preface</h1>
<p>This is a very early draft of my master’s thesis.</p>
</section>
<section id="mutual-information-for-trajectories-in-a-gaussian-framework" class="level1" data-number="1">
<h1 data-number="2"><span class="header-section-number">2</span> Mutual Information for Trajectories in a Gaussian Framework</h1>
<section id="introduction" class="level2" data-number="1.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Introduction</h2>
<p>After taking measurements of an uncertain quantity <span class="math inline">\mathcal S</span> we hope that the produced observations <span class="math inline">\mathcal X</span> can lead to a reduction of our uncertainty. We use entropies to quantify uncertainty and by rephrasing Bayes’ theorem as a relation of uncertainties <span><span class="math display">
\mathrm H(\mathcal S|\mathcal X) = \mathrm H(\mathcal X|\mathcal S) - \mathrm H(\mathcal X) + \mathrm H(\mathcal S) \equiv \mathrm H(\mathcal S) - \mathrm I(\mathcal S, \mathcal X)
\qquad(1)</span></span> we can read off that the observations <span class="math inline">\mathcal X</span> decrease our uncertainty in <span class="math inline">\mathcal S</span> on average by <span class="math inline">\mathrm I(\mathcal S, \mathcal X) = \mathrm H(\mathcal X) - \mathrm H(\mathcal X|\mathcal S)</span>. We call <span class="math inline">\mathrm I(\mathcal S, \mathcal X)</span> the <em>mutual information between <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span></em>, <span class="math inline">\mathrm H(\mathcal X)</span> is the <em>marginal entropy of <span class="math inline">\mathcal X</span></em> and <span class="math inline">\mathrm H(\mathcal X|\mathcal S)</span> the <em>conditional entropy of <span class="math inline">\mathcal X</span> given <span class="math inline">\mathcal S</span></em>. Therefore to understand e.g. the quality of our measurements (or of the measurement device) it can be insightful to be able to estimate the mutual information.</p>
<p>When we consider the point of view of a signal-processing device (e.g. a cell) we might be interested in cases where both the quantity <span class="math inline">\mathcal S</span> and the data <span class="math inline">\mathcal X</span> change over time. We then consider the values of the random variables <span class="math inline">\mathcal S, \mathcal X</span> to be trajectories or sequences of states over time. Trajectories are usually represented as high-dimensional vectors (e.g. as a sequence of states and transition times). Our motivation is to compute the mutual information between such trajectories. To do this we intend to generate trajectories using a fully stochastic model of a biochemical network based on its master equation to compute the likelihoods of individual trajectories. In these notes however we only consider a very simple multi-dimensional Gaussian system because it allows us to test and understand the pitfalls of information estimation for high-dimensional systems with relatively low amounts of computing power. Additionally for a multivariate Gaussian system there exists a simple analytical expressions for the mutual information that we use to verify our estimates.</p>
<p>Hence we consider the case where the joint probability distribution <span class="math inline">\mathrm P(\mathbf{s}, \mathbf{x})</span> is given by a multivariate normal distribution <span><span class="math display">
\mathrm P(\mathbf{s}, \mathbf{x}) = \frac{1}{\sqrt{\left( 2\pi  \right)^{2d} \det Z}} \;\exp\left[-\frac12\ (\mathbf s^T\; \mathbf x^T)\ Z^{-1}\ \binom{\mathbf s}{\mathbf x}\right]
\qquad(2)</span></span> where <span class="math inline">\mathbf s, \mathbf x \in \mathbb R^d</span> are the signal and response vectors respectively and the symmetric positive-definite covariance matrix <span class="math inline">Z\in\mathbb R^{2d\times 2d}</span> has the block form <span id="eq:corr_z"><span class="math display">
Z =  \begin{pmatrix}
C_{ss}  C_{xs} \\
C_{sx}  C_{xx}
\end{pmatrix}
\qquad(3)</span></span> with <span class="math inline">C_{\alpha\beta}\in\mathbb R^{d\times d}</span>. For this distribution there exists a simple analytical expression to compute the mutual information <span class="citation" data-cites="2010:Tostevin 1948:Shannon">[<a href="#ref-2010:Tostevin" role="doc-biblioref">1</a>,<a href="#ref-1948:Shannon" role="doc-biblioref">2</a>]</span> <span><span class="math display">
\mathrm I(\mathcal S, \mathcal X) = \frac 12 \ln\left( \frac{\det C_{ss} \det C_{xx}}{\det Z} \right)
\qquad(4)</span></span> which will be our benchmark to compare the proposed Monte-Carlo estimation procedure against. In a similar way we can also acquire analytical equations for both the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> and the conditional entropy <span class="math inline">\mathrm H(\mathcal X | \mathcal S)</span>.</p>
<p>We want to estimate the mutual information by separately computing the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> and the conditional entropy <span class="math inline">\mathrm H(\mathcal X | \mathcal S)</span> from simulated data. In the present case we have the full information about our system which allows us to generate correctly distributed random observations as test data.</p>
<p>As it turns out the main difficulty of our estimation procedure is to get an unbiased estimate of <span class="math inline">\mathrm H(\mathcal X)</span> whereas it is much more straightforward to get a good estimate for <span class="math inline">\mathrm H(\mathcal X | \mathcal S)</span>. Therefore in these notes we focus on the computation of the marginal entropy and consider the conditional entropy at the end.</p>
</section>
<section id="monte-carlo-estimate-for-the-marginal-entropy" class="level2" data-number="1.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Monte-Carlo Estimate for the Marginal Entropy</h2>
<p>We compute the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> using Monte-Carlo sampling to evaluate the necessary integrals. First we generate a number of samples <span class="math inline">(\mathbf x_i)_{i=1,\ldots,N_x}</span> that are distributed according to the distribution of <span class="math inline">\mathcal X</span>. We use these to estimate the entropy <span id="eq:mc_entropy"><span class="math display">
\mathrm H(\mathcal X) = -\int\mathrm d\mathbf x\ \mathrm P(\mathbf x)\ln \mathrm P(\mathbf x) \approx \frac{\sum\limits_{i=1}^{N_x} \ln\mathrm P(\mathbf x_i)}{N_x} \,.
\qquad(5)</span></span></p>
<p>It is important to realize that we do not actually need to know the distribution of <span class="math inline">\mathcal X</span> to do create appropriate Monte-Carlo samples. Since a stochastic model for trajectories provides us with the distributions <span class="math inline">\mathrm P(\mathbf s)</span> and <span class="math inline">\mathrm P(\mathbf x|\mathbf s)</span> we can generate samples from <span class="math inline">\mathrm P(\mathbf x)</span> by first generating a sample <span class="math inline">\mathbf s_j</span> from <span class="math inline">\mathrm P(\mathbf s)</span> and then use <span class="math inline">P(\mathbf x|\mathbf s_j)</span> to generate a sample <span class="math inline">\mathbf x_i</span>.</p>
<p>Nonetheless we see from eq. <a href="#eq:mc_entropy">5</a> that we <em>do</em> have to evaluate <span class="math inline">\mathrm P(\mathbf x_i)</span> for every generated sample. However, when we want to extend the method to stochastic trajectories then the distribution of the responses <span class="math inline">\mathrm P(\mathbf x)</span> is not known a priori anymore. Therefore we choose to evaluate <span class="math inline">\mathrm P(\mathbf x_i)</span> by doing a Monte-Carlo integration using signal samples <span class="math inline">(\mathbf s_j)_{j=1,\ldots,N_s}</span> that are distributed according to <span class="math inline">\mathrm P(\mathcal S)</span>: <span id="eq:mc_marginal"><span class="math display">
\mathrm P(\mathbf x_i) = \int\mathrm d\mathbf s\ \mathrm P(\mathbf s)\ \mathrm P(\mathbf x_i|\mathbf s) \approx \frac{\sum\limits_{j=1}^{N_s} \mathrm P(\mathbf x_i | \mathbf s_j)}{N_s} \,.
\qquad(6)</span></span> While for a low-dimensional signal space it is feasible to instead compute the marginalization integral using direct evaluation <span class="citation" data-cites="2019:Cepeda-Humerez">[<a href="#ref-2019:Cepeda-Humerez" role="doc-biblioref">3</a>]</span> we choose to use MC evaluation to also be able to handle high-dimensional signal spaces. This is crucial since eventually we are interested in computing the mutual information between trajectories where the dimensionality of the distributions increases with trajectory length.</p>
<p>We can summarize the estimation procedure for the marginal entropy using the equation <span id="eq:mc_entropy_notation"><span class="math display">
\mathrm H(\mathcal X) = -\left\langle \ln \left\langle \mathrm P(\mathbf x | \mathbf s) \right\rangle_{\mathrm P(\mathbf s)} \right\rangle_{\mathrm P(\mathbf x)}
\qquad(7)</span></span> where we use the notation <span class="math inline">\langle f(x)\rangle_{g(x)}</span> for the expected value of <span class="math inline">f(x)</span> when <span class="math inline">x</span> is distributed according to the probability density given by <span class="math inline">g(x)</span>. Thus when thinking in mathematical terms we have the shorthand <span class="math inline">\langle f(x)\rangle_{g(x)} \equiv\int \mathrm dx\ g(x) f(x)</span>. We can also easily translate this notation into a Monte-Carlo estimate, i.e. <span class="math inline">\langle f(x)\rangle_{g(x)} = \lim\limits_{N\rightarrow\infty}\frac{\sum_{i=1}^N f(x_i)}{N}</span> where <span class="math inline">x_1, x_2,\ldots</span> are independent samples of the probability distribution given by <span class="math inline">g(x)</span>.</p>
<p>The estimates for the entropies given by eq. <a href="#eq:mc_entropy">5</a> and eq. <a href="#eq:mc_marginal">6</a> together allow us to compute the mutual information of <span class="math inline">\mathcal X</span> and <span class="math inline">\mathcal S</span> <em>in principle</em>. In the following we discuss for which conditions and sample sizes you can expect a good entropy estimate from this method.</p>
<section id="choice-of-covariance-matrices" class="level3" data-number="1.2.1">
<h3 data-number="2.2.1"><span class="header-section-number">2.2.1</span> Choice of Covariance Matrices</h3>
<p>We want to carefully choose the covariance matrices such that we can expect any sampling issues that arise in the Gaussian framework to also be present when dealing with stochastic trajectories. Therefore we chose to model a very simple gene expression model described by the reaction equations <span><span class="math display">
\begin{gathered}
\emptyset \xrightarrow{\kappa} S \xrightarrow{\lambda} \emptyset\\
S \xrightarrow{\rho} S + X\\
X \xrightarrow{\mu}\emptyset
\end{gathered}
\qquad(8)</span></span> where <span class="math inline">X</span> are particles representing the cell response and <span class="math inline">S</span> are particles that will be interpreted as the signal. We describe the signal and response trajectories as a vector of values at discrete sample times, e.g. <span class="math inline">\mathbf s = \left(s(t_1),\ldots,s(t_d)\right)^T</span>. For this model we can analytically compute the correlation functions. For simplicity we assume that the system is in steady state such that the correlation functions do only depend on time differences, i.e. <span class="math inline">C_{\alpha\beta}(t, t^\prime) = C_{\alpha\beta}(t^\prime-t)</span>. The correlation functions then give us the elements of the covariance matrices <span><span class="math display">
C_{\alpha\beta}^{ij} = C_{\alpha\beta}(t_j - t_i) = \langle\alpha(t_i)\beta(t_j)\rangle\,.
\qquad(9)</span></span></p>
<figure>
<img src="matrix_plots.png" id="fig:corr" alt="" /></img><figcaption>Figure 1: Matrix plots of the full correlation matrix <span class="math inline">Z</span> from eq. <a href="#eq:corr_z">3</a> for different values of dimensionality <span class="math inline">d</span> and <span class="math inline">\Delta t</span>. Brighter colors indicate higher matrix element values. We can clearly observe the block structure of <span class="math inline">Z</span> in every matrix plot. For every matrix plot, the element with coordinates <span class="math inline">(i,j)</span> in the top left quadrant shows the correlations <span class="math inline">\langle s(i\Delta t) s(j \Delta t)\rangle</span>. In the top right quadrant we see the correlations <span class="math inline">\langle s(i\Delta t) x(j \Delta t)\rangle</span> and in the lower quadrants we see <span class="math inline">\langle x(i\Delta t) s(j \Delta t)\rangle</span> and <span class="math inline">\langle x(i\Delta t) x(j \Delta t)\rangle</span> on the left and right side respectively. The product <span class="math inline">T = d\Delta t</span> is the duration of the signal and response trajectories. The quantity <span class="math inline">d\Delta t</span> also serves as a rough measure of the sparsity of the correlation matrices (i.e. the fraction of matrix elements lower than some cutoff). Along diagonals from bottom left to top right, the product <span class="math inline">T = d \Delta t</span> is constant. Indeed, we see that along these diagonals the sparsity is roughly constant. Yet, as we move along such a diagonal of equal sparsity <span class="math inline">d\Delta t</span> but increasing dimensionality <span class="math inline">d</span> we see correlation matrices that display the same features in a gradually more refined and smooth way.</figcaption>
</figure>
<p>Using this system we have two parameters left to tune. We can freely choose the number <span class="math inline">d</span> and offsets <span class="math inline">\Delta t</span> of our time samples. The duration of the trajectories <span class="math inline">\mathbf s</span> and <span class="math inline">\mathbf x</span> is given by the product <span class="math inline">T=d\Delta t</span>. In fig. <a href="#fig:corr">1</a> we show matrix plots of the joint covariance matrix <span class="math inline">Z</span> for different values of <span class="math inline">d</span> and <span class="math inline">\Delta t</span>. We can also observe that <span class="math inline">d</span> determines the dimensionality of the problem while the product <span class="math inline">d \Delta t</span> serves as a measure for the sparsity of the correlation matrices. Note that the choice of <span class="math inline">\Delta t</span> affects how well the discretized trajectories approximate physical continuous-time trajectories. However here we are not interested in comparing our results to physical systems (as is done by Tostevin, et. al. <span class="citation" data-cites="2010:Tostevin">[<a href="#ref-2010:Tostevin" role="doc-biblioref">1</a>]</span>) and therefore we can simply regard <span class="math inline">\Delta t</span> as a parameter describing the sparsity of the covariance matrices.</p>
<div id="tbl:k">
<table>
<caption>Table 1: Values of the reaction constants used for all computations.</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\kappa</span></th>
<th style="text-align: center;"><span class="math inline">\lambda</span></th>
<th style="text-align: center;"><span class="math inline">\rho</span></th>
<th style="text-align: center;"><span class="math inline">\mu</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="direct-importance-sampling" class="level3" data-number="1.2.2">
<h3 data-number="2.2.2"><span class="header-section-number">2.2.2</span> Direct Importance Sampling</h3>
<p>We want to use this fully Gaussian model to understand how the sample sizes of the different Monte Carlo steps affect the estimate and whether there exists a bias in the approximation. We calculate the marginal entropy as a Monte Carlo average over the logarithms of the marginal distribution densities of <span class="math inline">N_x</span> sampled responses as shown in eq. <a href="#eq:mc_entropy">5</a>. The evaluation of the marginal density itself requires a Monte Carlo average over <span class="math inline">N_s</span> sampled signals (eq. <a href="#eq:mc_marginal">6</a>). Hence to evaluate the marginal density we need to perform nested averaging as shown in eq. <a href="#eq:mc_entropy_notation">7</a>. We performed this procedure for various values of <span class="math inline">N_s</span> and <span class="math inline">N_x</span> and compared the estimate with reference results using the analytical expression for the entropy of a multivariate Gaussian distribution.</p>
<p>Both, increase of <span class="math inline">N_x</span> and increase of <span class="math inline">N_s</span> should lead to an improved estimate of <span class="math inline">\mathrm H(\mathcal X)</span>. To understand the accuracy of an estimate with a given <span class="math inline">N_s</span> and <span class="math inline">N_x</span> we repeat the estimation procedure multiple times and compute the mean and the standard deviation of the individual estimation results.</p>
<figure>
<img src="relative_error_responses.svg" id="fig:rel_err_responses" alt="" /></img><figcaption>Figure 2: Top: relative error for the marginal entropy as a function of <span class="math inline">1/N_x</span>. Bottom: empirical variance of ensembles of 144 estimates. The solid lines show a linear extrapolation of the data points for <span class="math inline">N_x \rightarrow\infty</span>. All estimates were performed using a constant number of signal samples <span class="math inline">N_s = 400</span> and for <span class="math inline">d = 200</span>. The linear extrapolation in the bottom plot indicates that we do predict the variance of the results to vanish in the limit of infinite sampling. This behavior is generally expected for Monte Carlo estimates. Strikingly however, we find that there is a consistent offset of the average estimate from the correct result, even in the limit <span class="math inline">N_x \rightarrow\infty</span>. We see that the bias scales with the sparsity of the covariance matrices. The relative error is computed using <span class="math inline">\mathrm H_\text{estimate}/\mathrm H_\text{analytical} - 1</span> where <span class="math inline">\mathrm H_\text{estimate}=\sum^{M}_{i=1} \hat{\mathrm H}_i/M</span> is the average over the results of the <span class="math inline">M=144</span> marginal entropy estimates that were performed using eq. <a href="#eq:mc_entropy_notation">7</a> and <span class="math inline">\mathrm H_\text{analytical}</span> is the value resulting from an analytical compuation of the marginal entropy. The empirical variance shown is <span class="math inline">\sum^{M}_{i=1} (\hat{\mathrm H}_i - \mathrm H_\text{estimate})^2/M</span>.</figcaption>
</figure>
<p>In fig. <a href="#fig:rel_err_responses">2</a> we see how the relative error of our estimate varies with the number of simulated responses <span class="math inline">N_x</span>. Here use the same number of signals per response <span class="math inline">N_s</span> for all estimates. While—as expected—the variance of the estimate decreases when we increase <span class="math inline">N_x</span> we find that especially for very sparse covariance matrices we consistently over-estimate the marginal entropy. Indeed, we find that the systematic bias in our results seems to be independent of <span class="math inline">N_x</span>.</p>
<p>We found that the bias is stronger for correlation matrices with higher sparsities <span class="math inline">d\Delta t</span>. Since the sparsity grows with trajectory duration we can expect an increasingly strong over-estimation for longer trajectories. The sparsity can be increased either by decreasing the time-resolution or by increasing the dimensions of the covariance matrix. To understand how these parameters relate to each other we tested how the estimation error changes when we increase the dimensionality of the correlation matrices while the sparsity remains constant.</p>
<p>Fig. <a href="#fig:sparsity">3</a> shows how large the estimation error for the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> is on average for different levels of sparsity. We see that in all cases that increasing the sparsity leads to larger errors in the estimates. Additionally we find that for a given sparsity value, the estimates with high-dimensional covariance matrices are slightly worse. As we keep increasing the number of dimensions <span class="math inline">d</span> at constant sparsity <span class="math inline">d\Delta t</span>, thus decreasing <span class="math inline">\Delta t</span>, the matrices gradually become a more faithful representation of the continuous correlation functions of the system (see fig. <a href="#fig:corr">1</a>). Extrapolating the lines in fig. <a href="#fig:sparsity">3</a> we project that for very large covariance matrices, the sparsity is the only determining factor of the estimation bias.</p>
<figure>
<img src="sparsity.svg" id="fig:sparsity" alt="" /></img><figcaption>Figure 3: Absolute error of marginal entropy estimates for different values of the sparsity <span class="math inline">d\Delta t</span> of the correlation matrices. We see that for high dimensionality the lines of constant sparsity become increasingly flat. This indicates that for high-dimensional systems the sparsity of the covariance matrix is a good measure for the difficulty of correct estimation. We therefore claim that the bias of the entropy estimate for the Gaussian system primarily depends on the sparsity of the covariance matrix. Note that for lower numbers of dimensions the covariance matrices of along the diagonals of equal sparsity look more blocky (see fig. <a href="#fig:corr">1</a>). That may be an indicator why the estimation error is not constant for a given sparsity at lower dimensions.</figcaption>
</figure>
<figure>
<img src="error_grid.svg" id="fig:error_regression" alt="" /></img><figcaption>Figure 4: Relative error <span class="math inline">\mathrm H_\text{estimate}/\mathrm H_\text{analytical} - 1</span> as a function of <span class="math inline">1/N_s</span>. We can see that the relative error in the marginal entropy estimate increases with the sparsity <span class="math inline">d\Delta t</span> (i.e. with trajectory duration). The linear extrapolating lines emphasize that there is a noticable but very slight decrease in error as <span class="math inline">N_s\to\infty</span>. This seems puzzling since for infinite sampling we should expect the error to vanish. Apparently for high-sparsity covariance matrices we need extraordinarly many signal samples to achieve unbiased estimates.</figcaption>
</figure>
<p>As a next step we investigated how changes in the sampling for the marginal density <span class="math inline">\mathrm P(\mathbf x_i)</span> affect the estimation bias. Thus in fig. <a href="#fig:error_regression">4</a> we show how the increase of simulated signals per response <span class="math inline">N_s</span> improves the estimate of the marginal entropy. Here we again see that for high number of dimensions we over-estimate the marginal entropy. An increase of <span class="math inline">N_s</span> does lead to slightly less over-estimation but the linear extrapolation indicates that even if we choose enormously high values for <span class="math inline">N_s</span> we can not expect to reduce the bias substantially.</p>
<p>For a given number of samples, the fraction of the trajectory space probed by the Monte Carlo scheme is lower for longer durations. Therefore, for a given number of Monte Carlo samples we expect the estimate to become worse for longer trajectories, i.e. when the sparsity of the covariance matrix is high. This is confirmed by our results. Furthermore and more surprisingly we find that we consistently over-estimate the marginal entropy and while increasing <span class="math inline">N_s</span> <em>does</em> reduce the bias slightly it appears to require an astronomically high sampling in signal trajectory space to reach arbitrary low errors. An increase in <span class="math inline">N_x</span> however reduces the variance of the results but does not influence the bias at all.</p>
<p>Thus we are lead to believe that the main difficulty in estimating the marginal entropy is the Monte-Carlo marginalization of the probability density function. To estimate <span class="math inline">\mathrm P(\mathbf x)</span> we sample signals from the marginal distribution <span class="math inline">\mathrm P(\mathbf s)</span> and average over the likelihoods <span class="math inline">\mathrm P(\mathbf x | \mathbf s)</span>. However as the space of signals becomes increasingly vast for longer trajectories, it becomes more and more unlikely to sample a signal <span class="math inline">\mathbf s</span> where <span class="math inline">\mathbf x</span> has a non-vanishing likelihood of occurring. Hence the duration of the trajectories strongly influences the bias of the marginal entropy computation and we are well advised to keep the trajectories as short as possible. To capture the essential system dynamics however, the trajectories must be at least as long as the longest timescale <span class="math inline">\tau</span> in the system. If we are interested in the marginal entropy for timescales longer than the longest timescale in the system we can then use the fact that trajectory pieces of duration <span class="math inline"> \tau</span> become independent of each other and we can add the individual entropies of these pieces to get the full entropy for such a long trajectory. For example, if we were interested in the marginal entropy of trajectories of duration <span class="math inline">T=\ell\tau</span> where <span class="math inline">\ell\in\mathbb N^+</span> we could approximate it by estimating the entropy <span class="math inline">\hat{H}_\tau</span> of trajectories of duration <span class="math inline">\tau</span> and then take <span class="math inline">\ell \hat{H}_\tau</span> as an approximation for <span class="math inline">\hat{H}_{\ell\tau}</span>. While performing the estimate <span class="math inline">\hat{H}_\tau</span> is computationally much cheaper than directly estimating <span class="math inline">\hat{H}_{\ell\tau}</span> and therefore for a given amount of CPU-time we get a lower systematic bias of the estimate <span class="math inline">\hat{H}_\tau</span>, the bias of <span class="math inline">\ell \hat{H}_\tau</span> of course still scales linearly with <span class="math inline">\ell</span>. Therefore it is still in our best interest to reduce the systematic bias of the marginal entropy as much as possible.</p>
</section>
<section id="umbrella-sampling" class="level3" data-number="1.2.3">
<h3 data-number="2.2.3"><span class="header-section-number">2.2.3</span> Umbrella Sampling</h3>
<p>To get a better estimate of <span class="math inline">\mathrm P(\mathbf x)</span> we decided to use <em>umbrella sampling</em>, i.e. to bias our sampling strategy towards signals that we expect to have a high likelihood for the given response. Since Monte-Carlo estimates depend on the distribution of the chosen samples we must correct our estimate by re-weighing the samples accordingly.</p>
<p>More specifically, given a sampling distribution <span class="math inline">w(\mathbf s)</span> (which is normalized like a probability density function) we can write <span><span class="math display">
\mathrm P(\mathbf x) = \int \mathrm d\mathbf s\ w(\mathbf s)\frac{\mathrm P(\mathbf s)\mathrm P(\mathbf x | \mathbf s)}{w(\mathbf s)} = \left\langle \frac{\mathrm P(\mathbf s)\mathrm P(\mathbf x | \mathbf s)}{w(\mathbf s)} \right\rangle_{w(\mathbf s)}
\qquad(10)</span></span> which shows us how to compute <span class="math inline">\mathrm P(\mathbf x_i)</span> from signal trajectories <span class="math inline">\mathbf s_1^w, \ldots, \mathbf s_{N_s}^w</span> which are distributed according to the sampling distribution given by <span class="math inline">w</span>: <span><span class="math display">
\mathrm P(\mathbf x_i) \approx \frac1{N_s} \sum\limits_{j=1}^{N_s} \frac{\mathrm P(\mathbf s_j^w)\mathrm P(\mathbf x_i | \mathbf s_j^w)}{w(\mathbf s_j^w)} \equiv P_{\mathbf x_i, N_s}^w \,.
\qquad(11)</span></span></p>
<p>The choice of the sampling distribution <span class="math inline">w</span> has a direct impact on the variance of an ensemble of estimates <span class="math inline">P_{\mathbf x_i, N_s}^w</span>. Indeed, for any given <span class="math inline">\mathbf x_i</span> there is an optimal choice for the sampling distribution <span class="math inline">w_\text{opt}</span> such that the variance of the estimates vanishes. This optimal choice is given by <span class="math inline">w_\text{opt}(\mathbf s) = \mathrm P(\mathbf s | \mathbf x_i)</span> which is easily confirmed by the calculation <span id="eq:opt_sampling"><span class="math display">
P_{\mathbf x_i, N_s}^{w_\text{opt}} = \frac1{N_s}\sum\limits_{j=1}^{N_s} \frac{\mathrm P(\mathbf s_j^w)\mathrm P(\mathbf x_i | \mathbf s_j^w)}{\mathrm P(\mathbf s_j^w | \mathbf x_i)} = \frac1{N_s}\sum\limits_{j=1}^{N_s} \mathrm P(\mathbf x_i)
\qquad(12)</span></span> where in the last step we applied Bayes’ rule. Since the expression above is completely independent of the chosen signal samples the result is deterministic and thus has zero variance. We also see from eq. <a href="#eq:opt_sampling">12</a> that in practice we can’t directly use <span class="math inline">w_\text{opt}(\mathbf s) = \mathrm P(\mathbf s | \mathbf x_i)</span> as our sampling distribution since the evaluation of <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i) = \frac{\mathrm P(\mathbf x_i|\mathbf s) \mathrm P(\mathbf s)}{\mathrm P(\mathbf x_i)}</span> itself depends on <span class="math inline">\mathrm P(\mathbf x_i)</span> which is precisely the quantity we are interested in estimating.</p>
<figure>
<img src="sampling2.svg" id="fig:rel_err_opt" alt="" /></img><figcaption>Figure 5: Relative error as a function of the dimensionality <span class="math inline">d</span>. The solid lines show the results using non-optimized sampling while the dashed lines show the results when using a sampling distribution close to the optimal distribution <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span>. We see that with optimized sampling there is no consistent over-estimation anymore. All estimated were done using <span class="math inline">d = 200</span> dimensional covariance matrices.</figcaption>
</figure>
<p>Instead, we can try to obtain a sampling distribution that is as close as possible to <span class="math inline">w_\text{opt}(\mathbf s)</span>. A known approach involves using random samples from <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i)</span> to pick the most optimal sampling distribution from a family of candidate distributions <span class="citation" data-cites="2011:Chan">[<a href="#ref-2011:Chan" role="doc-biblioref">4</a>]</span>. Generating so-called <em>posterior samples</em> from <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i) \sim \mathrm P(\mathbf x_i|\mathbf s) \mathrm P(\mathbf s)</span> is generally possible without knowledge of the normalization factor <span class="math inline">\mathrm P(\mathbf x_i)</span> e.g. by using Metropolis-Sampling <span class="citation" data-cites="1991:Müller 1994:Tierney">[<a href="#ref-1991:Müller" role="doc-biblioref">5</a>,<a href="#ref-1994:Tierney" role="doc-biblioref">6</a>]</span>. To test within the Gaussian framework whether such an approach to importance sampling could work in principle, we generate 400 posterior samples by directly sampling from the analytically known posterior distribution <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i)</span>. We compute the empircial mean <span class="math inline">\bar{\mathbf s}</span> and the empirical covariance <span class="math inline">\bar C_{\mathbf s|\mathbf x_i}</span> of these samples as parameter estimates for a multivariate Gaussian <span class="math inline">\mathcal N(\bar{\mathbf s}, \bar C_{\mathbf s|\mathbf x_i})</span> and use the latter as an optimized sampling distribution.</p>
<p>In fig. <a href="#fig:rel_err_opt">5</a> we show that using optimized sampling we can strongly reduce the systematic bias in marginal entropy estimation. As expected, importance sampling is especially useful when the sparsity is very high, i.e. the trajectories are long. It is clear that for longer trajectories we expect <span class="math inline">\mathrm P(\mathbf s | \mathbf x_i)</span> to be a much more narrow sampling distribution than <span class="math inline">\mathrm P(\mathbf s)</span> whenever the <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> are not completely independent. Consequently, it becomes more and more unlikely to obtain a sample <span class="math inline">s^\prime</span> from <span class="math inline">\mathrm P(\mathbf s)</span> such that <span class="math inline">\mathrm P(s^\prime | \mathbf x_i)  \epsilon</span> for any <span class="math inline">\epsilon  0</span> and therefore more difficult to accurately estimate <span class="math inline">\mathrm P(\mathbf x_i)</span> using an unbiased sampling distribution.</p>

</section>
</section>
<section id="estimating-the-conditional-entropy" class="level2" data-number="1.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> Estimating the Conditional Entropy</h2>
<p>We can also estimate the <em>conditional entropy</em> and thus the mutual information within the Gaussian Framework. We express the conditional entropy using the notation introduced above <span><span class="math display">
\mathrm H(\mathcal X|\mathcal S) = -\int \mathrm d\mathbf s\mathrm d\mathbf x\ \mathrm P(\mathbf s)\mathrm P(\mathbf x | \mathbf s) \ln\mathrm P(\mathbf x|\mathbf s) = -\left\langle\langle\ln\mathrm P(\mathbf x | \mathbf s)\rangle_{\mathrm P(\mathbf x | \mathbf s)} \right\rangle_{\mathrm P(\mathbf s)}
\qquad(13)</span></span> to show that we require nested Monte Carlo integrations to evaluate the integral. We first generate signal samples <span class="math inline">\mathbf s_1, \ldots, \mathbf s_{N_s}</span> from the density <span class="math inline">\mathrm P(\mathbf s)</span>. Let <span class="math inline">\mathbf x_i^1,\ldots,\mathbf x_i^{N_x}</span> be response samples generated from <span class="math inline">\mathrm P(\mathbf x | \mathbf s_i)</span>. The Monte Carlo estimate for the conditional entropy then reads <span id="eq:conditional_entropy"><span class="math display">
\mathrm H(\mathcal X|\mathcal S) \approx - \frac1{N_s N_x} \sum\limits_{i=1}^{N_s} \sum\limits_{j=1}^{N_x} \ln\mathrm P(\mathbf x_i^j | \mathbf s_i)\,.
\qquad(14)</span></span></p>
<figure>
<img src="conditional.svg" id="fig:conditional" alt="" /></img><figcaption>Figure 6: Comparison of the relative error of conditional entropy estimates versus marginal error estimates. The relative errors are shown on a logarithmic scale as a function of the sparsity. We can see that the relative error for the estimate of the conditional entropy is a few orders of magnitude smaller than the estimates of the marginal entropy. All estimates were performed with <span class="math inline">N_x=25600</span> and <span class="math inline">N_s=1000</span>.</figcaption>
</figure>
<p>For both, marginal entropy and conditional entropy we have to evaluate the likelihood <span class="math inline">\mathrm P(\mathbf x| \mathbf s)</span> a total of <span class="math inline">N_s N_x</span> times. To compare the accuracy of we performed estimates of the marginal entropy with and without optimized sampling together with estimates of the conditional entropy for <span class="math inline">N_s = 1000</span> and <span class="math inline">N_x = 25600</span>. In fig. <a href="#fig:conditional">6</a> we show the relative error of both, marginal and conditional entropy estimates as a function of the sparsity. We find that the estimate of the conditional entropy is very accurate regardless of sampling size. Even with optimized sampling the marginal entropy estimate is roughly two orders of magnitude worse than a comparable conditional entropy estimate.</p>
</section>
<section id="discussion" class="level2" data-number="1.4">
<h2 data-number="2.4"><span class="header-section-number">2.4</span> Discussion</h2>
<p>Since both the estimate of the marginal entropy and of the conditional entropy require the computation of two nested Monte-Carlo averages one could expect the results of both estimates to be of similar accuracy. Yet we find that computing the marginal entropy is much more challenging than computing the conditional entropy. While analyzing the estimation procedure for the marginal entropy we found the main source of error to arise from the computation of the marginal probability density <span class="math inline">\mathrm P(\mathbf x)</span>. While the computation of this density suffers from high Monte-Carlo variance when we are not carefully optimizing our trajectory sampling procedure, the real issue arises in the next step when we have to <em>compute the logarithm of the marginal probability density</em> to estimate the marginal entropy <span class="math inline">\mathrm H(\mathcal X) \approx \sum^{N_x}_{i=1}-\ln\mathrm P(\mathbf x_i) / N_x</span> from our sampled response trajectories (see also eq. <a href="#eq:mc_entropy_notation">7</a>). For us, computing <span class="math inline">\ln\mathrm P(\mathbf x_i)</span> means computing the logarithm of an average. Taking the logarithm—which is concave function—of a Monte-Carlo average leads to a consistent bias. We see the existence of this bias in our results since we consistently over-estimate the marginal entropy. Indeed, the reason why it is much easier to get a good estimate of the conditional entropy is that in the latter case we have to average the logarithm of a quantity (see eq. <a href="#eq:conditional_entropy">14</a>) rather than taking the logarithm of an average, as we need for the marginal entropy.</p>
<p>We can thus conclude that the main difficulty of obtaining a good estimate for the mutual information between trajectories lies in the efficient and accurate computation of the marginal entropy. A viable approach for this seems to be to use importance sampling in the signal space in the computation of the marginal probability density. Our results indicate that such an approach could also work for trajectories generated using a fully stochastic model of a biochemical network. Another direction to pursue might be to use the replica trick, based on the mathematical identity that <span class="math inline">\ln Z = \lim_{n\to 0} (Z^n-1) / n</span>. This may allow us to eliminate the systematic bias by circumventing the need to take the logarithm of an estimate.</p>
</section>
<section id="references" class="level2 unnumbered" data-number="">
<h2 class="unnumbered" data-number="1">References</h2>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-2010:Tostevin">
<p>[1] F. Tostevin, P.R. ten Wolde, Mutual information in time-varying biochemical systems, Physical Review E. 81 (2010) 061917. <a href="https://doi.org/10.1103/physreve.81.061917">https://doi.org/10.1103/physreve.81.061917</a>.</p>
</div>
<div id="ref-1948:Shannon">
<p>[2] C.E. Shannon, A Mathematical Theory of Communication, Bell System Technical Journal. 27 (1948) 379–423. <a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x">https://doi.org/10.1002/j.1538-7305.1948.tb01338.x</a>.</p>
</div>
<div id="ref-2019:Cepeda-Humerez">
<p>[3] S.A. Cepeda-Humerez, J. Ruess, G. Tkačik, Estimating information in time-varying signals., PLoS Computational Biology. 15 (2019) e1007290. <a href="https://doi.org/10.1371/journal.pcbi.1007290">https://doi.org/10.1371/journal.pcbi.1007290</a>.</p>
</div>
<div id="ref-2011:Chan">
<p>[4] J.C.C. Chan, D.P. Kroese, Improved cross-entropy method for estimation, Statistics and Computing. 22 (2011) 1031–1040. <a href="https://doi.org/10.1007/s11222-011-9275-7">https://doi.org/10.1007/s11222-011-9275-7</a>.</p>
</div>
<div id="ref-1991:Müller">
<p>[5] P. Müller, A Generic Approach to Posterior Integration and Gibbs Sampling, Purdue University, 1991.</p>
</div>
<div id="ref-1994:Tierney">
<p>[6] L. Tierney, Markov Chains for Exploring Posterior Distributions, The Annals of Statistics. 22 (1994) 1701–1728. <a href="https://doi.org/10.1214/aos/1176325750">https://doi.org/10.1214/aos/1176325750</a>.</p>
</div>
</div>
</section>
</section>
<section id="information-theory-for-trajectories" class="level1" data-number="1">
<h1 data-number="3"><span class="header-section-number">3</span> Information theory for trajectories</h1>
<p>A trajectory <span class="math inline">X</span> with <span class="math inline">N</span> steps is defined by a set of pairs <span class="math inline">X=\{(t_i, \mathbf{x}_i)\; |\; i=0\ldots N-1 \}</span> where <span class="math inline">\mathbf{x}_i</span> defines the trajectory value at time <span class="math inline">t_i</span>. We can also have random variables over trajectories and therefore probability distributions over the space of all trajectories.</p>
<p>As a next step we can make sense of the entropy of a trajectory. Let <span class="math inline">\mathcal{X}_N</span> be a random variable over trajectories of length <span class="math inline">N</span>. We call</p>
<p><span id="eq:entropy_integral"><span class="math display">
\mathrm H(\mathcal{X}_N) = - \int\limits_{X\in \sigma(\mathcal{X}_N)} dX\; \mathrm{P}(\mathcal{X}_N = X)\; \ln \mathrm{P} (\mathcal{X}_N = X)
\qquad(1)</span></span></p>
<p>the entropy of <span class="math inline">\mathcal{X}_N</span> where <span class="math inline">\mathrm{P}(\mathcal{X}_N = X)</span> is the probability density function of a trajectory <span class="math inline">X=\{(t_i, \mathbf{x}_i)\; |\; i=0\ldots N-1 \}</span>. We can also define the conditional entropy for trajectories</p>
<p><span><span class="math display">
\mathrm H(\mathcal{X}_N | \mathcal{S}_M) = -\int\limits_{S\in \sigma(\mathcal{S}_N)} dS\; \mathrm{P} (\mathcal{S}_N = S) \int\limits_{X\in \sigma(\mathcal{X}_N)} dX\; \mathrm{P}(\mathcal{X}_N = X | \mathcal{S}_N = S)\; \ln \mathrm{P} (\mathcal{X}_N = X | \mathcal{S}_N = S) \,.
\qquad(2)</span></span></p>
<p>With these two quantities we can express the <em>mutual information</em> between trajectories</p>
<p><span><span class="math display">
\mathrm{I}(\mathcal{X}_N; \mathcal{S}_M) = \mathrm H(\mathcal{X}_N) - \mathrm H(\mathcal{X}_N | \mathcal{S}_M) \,.
\qquad(3)</span></span></p>
<p>The mutual information between two random variables quantifies by how much our certainty of the value of one variable increases if we know the other one.</p>
<p>To shorten the notation we write <span class="math inline">\mathrm{P} (\mathcal{X}_N = X)</span> as <span class="math inline">\mathrm P_{\mathcal{X}_N}(X)</span> and if the random variable is clear from the context we even drop the index and only write <span class="math inline">\mathrm P(X)</span>. With the short notation we can rewrite the mutual information</p>
<p><span><span class="math display">
\mathrm{I}(\mathcal{X}_N; \mathcal{S}_M) = \int\limits_{S\in \sigma(\mathcal{S}_N)} dS \int\limits_{X\in \sigma(\mathcal{X}_N)} dX\; \mathrm{P}( X , S)\; \ln \frac{\mathrm{P} ( X |  S)}{\mathrm P(X)} \,.
\qquad(4)</span></span></p>
<p>To evaluate <span class="math inline">\mathrm P(X)</span> we have to expand it as follows</p>
<p><span><span class="math display">
\mathrm P(X) = \int\limits_{S\in \sigma(\mathcal{S}_N)} dS\; \mathrm P(X, S) = \int\limits_{S\in \sigma(\mathcal{S}_N)} dS\; \mathrm P(X|S) \ \mathrm P (S) \equiv \left\langle P(X | S) \right\rangle_{\mathcal{S}_N} \,.
\qquad(5)</span></span></p>
<p>These relations let us state the mutual information as nested averages over the likelihood <span class="math inline">P(X|S)</span>:</p>
<p><span><span class="math display">
\mathrm{I}(\mathcal{X}; \mathcal{S}) = \left\langle \ln \frac{\mathrm{P} ( X |  S)}{\mathrm P(X)} \right\rangle_{\mathcal{X},\mathcal{S}} = \left\langle \ln \frac{\mathrm{P} ( X |  S)}{\left\langle\mathrm P(X | S) \right\rangle_\mathcal{S}} \right\rangle_{\mathcal{X},\mathcal{S}} \,.
\qquad(6)</span></span></p>
<p>These averages are defined as integrals over the very high-dimensional space of trajectories and thus very hard to evaluate analytically or numerically in the general case. Our goal is use <em>Monte-Carlo sampling</em> in the trajectory space to evaluate the above averages. To do this we have to sample trajectories from their probably distribution and we need to evaluate the likelihood for a response given a signal.</p>
<section id="monte-carlo-simulation" class="level2" data-number="1.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Monte-Carlo simulation</h2>
<p>While so-called Monte-Carlo methods comprise a wide variety of approaches to stochastically evaluate integrals or sums the common idea is easily stated. We have a state space <span class="math inline">U</span> and a probability distribution <span class="math inline">p_U</span> over that state space. The problem is to evaluate</p>
<p><span><span class="math display">
\langle f(u) \rangle \equiv \int\limits_{u \in U} \mathrm du\; f(u) p_U(u)
\qquad(7)</span></span></p>
<p>where <span class="math inline">f: U\rightarrow\mathbb R</span> is some smooth function. If <span class="math inline">U</span> is high-dimensional it is very time-consuming to estimate it by direct numerical integration.</p>
</section>
<section id="estimating-the-likelihood" class="level2" data-number="1.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Estimating the likelihood</h2>
<p>The Probability density of a markovian trajectory can be expressed as</p>
<p><span><span class="math display">
\mathrm P(X) = \mathrm P(x_0,t_0;x_1,t_1;\ldots;x_{N-1},t_{N-1}) = \mathrm P(x_0,t_0 ) \prod\limits^{N-1}_{n=1} \mathrm P(x_n,t_n|x_{n-1},t_{n-1}) \,.
\qquad(8)</span></span></p>
<p>Therefore the problem of calculating the likelihood for a particular trajectory amounts to solving two independent problems:</p>
<ol type="1">
<li>estimating the probability density of the starting point <span class="math inline">\mathrm P (x_0, t_0)</span> of a response</li>
<li>calculating the transition probabilities <span class="math inline">\mathrm P(x_n,t_n|x_{n-1},t_{n-1})</span></li>
</ol>
<p>For a given chemical reaction network we can write down the chemical master equation. The chemical master equation contains all the information needed to compute the individual terms <span class="math inline">\mathrm P(x_n,t_n|x_{n-1},t_{n-1})</span> for the entire system.</p>
<p>To calculate the mutual information between <span class="math inline">\mathcal{S}</span> and <span class="math inline">\mathcal X</span> we have to consider the entire reaction network containing the components both in <span class="math inline">S</span> and in <span class="math inline">X</span>. The precise reaction dynamics of the response part of the chemical network crucially depend on the observed signal trajectory. Therefore the chemical master equation for the whole reaction network allows us to compute the likelihood of a response trajectory for a particular signal trajectory:</p>
<p><span><span class="math display">
\mathrm P(\mathcal X = X|\mathcal S = S) = \mathrm P(x_0,t_0;x_1,t_1;\ldots;x_{N-1},t_{N-1} | S) = \mathrm P(x_0,t_0 | S) \prod\limits^{N-1}_{n=1} \mathrm P(x_n,t_n|x_{n-1},t_{n-1}, S) \,.
\qquad(9)</span></span></p>
<p>For increasingly long trajectories this quantity will in many physically relevant cases either grow or decay exponentially (<em>TODO: explain why</em>). Thus sufficiently long trajectories, the numerical values of the likelihood will not be directly representable by conventional floating-point numbers.</p>
<p>This problem can be avoided if we compute the <em>log-likelihood</em> <span class="math inline">\ell(X|S) \equiv \ln\mathrm P(X|S)</span> instead. We can easily rephrase the equation for the likelihood:</p>
<p><span><span class="math display">
\ell(X|S) = \ln\left[ \mathrm P(x_0,t_0 | S) \prod\limits^{N-1}_{n=1} \mathrm P(x_n,t_n|x_{n-1},t_{n-1}, S) \right] = \ln \mathrm P(x_0,t_0 | S) +\sum\limits^{N-1}_{n=1} \ln \mathrm P(x_n,t_n|x_{n-1},t_{n-1}, S)\,.
\qquad(10)</span></span></p>
<section id="the-probability-density-for-the-starting-point-of-a-trajectory" class="level3" data-number="1.2.1">
<h3 data-number="3.2.1"><span class="header-section-number">3.2.1</span> The probability density for the starting point of a trajectory</h3>
<p>We first look at the term <span class="math inline">P_0 = \mathrm P(x_0,t_0 | S)</span>. Since <span class="math inline">S</span> is a trajectory in time we can directly conclude from causality that</p>
<p><span><span class="math display">
\mathrm P(x_0, t_0 | S) = \mathrm P(x_0, t_0 | S_{t \leq t_0})
\qquad(11)</span></span></p>
<p>where <span class="math inline">S_{t \leq t_0}</span> is the temporal piece of the signal up to <span class="math inline">t_0</span>. We further suppose that the signal itself is markovian and therefore has no memory of its past. With this simplification we get</p>
<p><span><span class="math display">
\mathrm P(x_0, t_0 | S) = \mathrm P(x_0, t_0 | S_{t = t_0}) = \frac{\mathrm P((x_0, t_0), (s_0, t_0))}{\mathrm P(s_0, t_0)} \,.
\qquad(12)</span></span></p>
<p>We estimate <span class="math inline">P_0</span> using gaussian kernel density estimation to approximate both, the joint distribution of <span class="math inline">X_0, S_0</span> and the marginal distribution of <span class="math inline">S_0</span>.</p>
<p>Knowing the probabilities of the initial condition of both response and signal we can directly estimate the mutual information of <span class="math inline">\mathcal{X}_{t=t_0}</span> and <span class="math inline">\mathcal{S}_{t=t_0}</span>:</p>
<p><span><span class="math display">
\mathrm I(\mathcal{X}_{t=t_0}, \mathcal{S}_{t=t_0}) = \int ds_0\int dx_0\; \mathrm{P}(x_0, s_0)\; \ln \frac{\mathrm{P} (x_0, s_0)}{\mathrm{P} (x_0) \mathrm{P} (s_0)}
\qquad(13)</span></span></p>
</section>
<section id="the-transition-probabilities" class="level3" data-number="1.2.2">
<h3 data-number="3.2.2"><span class="header-section-number">3.2.2</span> The transition probabilities</h3>
<p><strong>TODO:</strong> describe how the transition rates follow from the master equation (probably follow the style of Cepeda-Humerez, et. al.)</p>
</section>
<section id="estimating-the-marginal-probability-of-response-trajectories" class="level3" data-number="1.2.3">
<h3 data-number="3.2.3"><span class="header-section-number">3.2.3</span> Estimating the marginal probability of response trajectories</h3>
<p>To calculate the mutual information between trajectories we need to have a good estimate for <span class="math inline">\ln\left\langle \mathrm P(X | S) \right\rangle_\mathcal{S}</span>. We calculate this average by sampling of trajectories <span class="math inline">(S^{(i)})_{i=1\ldots N_S}</span> from the probability distribution of <span class="math inline">\mathcal{S}</span>:</p>
<p><span><span class="math display">
\ln\left\langle\mathrm P(X | S) \right\rangle_\mathcal{S} \approx \ln \frac{\sum^{N_S}_{i=1} \mathrm P(X|S^{(i)})}{N_S} = \ln \sum^{N_S}_{i=1} \mathrm P(X|S^{(i)}) - \ln N_S
\qquad(14)</span></span></p>
<p>Thus we find that it is enough to be able to compute the likelihood between trajectories to estimate the marginal distribution of trajectories.</p>
<p>In practice (due to limited precision of floating-point arithmetic) it is only possible to evaluate the log-likelihood <span class="math inline">\ell(X|S) \equiv \ln\mathrm P(X|S)</span>. This means that the calculation of the averaged likelihood involves the quantity</p>
<p><span><span class="math display">
\ln \sum^{N_S}_{i=1} \mathrm P(X|S^{(i)}) = \ln \sum\limits^{N_S}_{i=1} \exp \ell(X|S^{(i)}) \equiv \mathrm{LSE}\left( \ell(X|S^{(1)}),\ldots, \ell(X|S^{(N_S)})\right)
\qquad(15)</span></span></p>
<p>where <span class="math inline">\mathrm{LSE} : \mathbb{R}^n \rightarrow \mathbb{R}</span> is called log-sum-exp . An interesting property of <span class="math inline">\mathrm{LSE}</span> is that it’s a smooth approximation to the <span class="math inline">\max</span> function. This means that for finite sample sizes the monte-carlo estimate of the averaged likelihood will always be too small!</p>
<p>We approximate the mutual information between trajectories as</p>
<p><span><span class="math display">
\mathrm{I}(\mathcal{X}; \mathcal{S}) = \left\langle \ln \frac{\mathrm{P} ( X |  S)}{\left\langle\mathrm P(X | S) \right\rangle_\mathcal{S}} \right\rangle_{\mathcal{X},\mathcal{S}} = \left\langle \ell ( X |  S) - \mathrm{LSE}\left( \ell(X|S^{(1)}),\ldots, \ell(X|S^{(N_S)})\right) + \ln N_S\right\rangle_{\mathcal{X},\mathcal{S}}
\qquad(16)</span></span></p>
<p>which means that for finite amount of signal samples we will <em>systematically over-estimate</em> the mutual information. <strong>TODO: Is that really true? What about <span class="math inline">\ln N_S</span>?</strong> Even worse: the longer the trajectories the bigger the error becomes since the dimensionality of the space of possible signals is growing.</p>
<p>Another way to phrase this insight is that to get a good approximation for the logarithmic average likelihood, our set of signals that we use for monte-carlo sampling should contain many signals that produce a high likelihood. <strong>Therefore it probably is necessary to come up with a scheme to specifically sample signal trajectories for which the likelihood of a particular trajectory is high</strong>. On the other hand the results do not seem to get significantly better when averaging over more trajectories.</p>
</section>
</section>
<section id="chemical-master-equation" class="level2" data-number="1.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Chemical Master Equation</h2>
<p>As a model for the biochemical processing that takes place inside a cell we suppose that all interactions can be described by a chemical networks composed of different molecular species and reactions between them. Such networks can be described by a <em>chemical master equation</em> which makes it possible to compute all the probabilities associated with the time-evolution of such a system.</p>
<p>For illustrative purposes, let’s consider a highly simplified model of gene expression consisting of two components and four reactions</p>
<p><span><span class="math display"> \begin{gathered}
\emptyset \xrightarrow{\kappa} S \xrightarrow{\lambda} \emptyset\\
S \xrightarrow{\rho} S + X\\
X \xrightarrow{\mu}\emptyset
\end{gathered} \qquad(17)</span></span></p>
<p>The constants <span class="math inline">\kappa, \lambda, \rho, \mu</span> determine the rates at which the individual reactions occur. For example, assuming a well stirred system in thermal equilibrium, it can be shown that the probabilities for the individual reactions happening at least once in the time interval <span class="math inline">[t, t+\mathrm\delta t]</span> are</p>
<p><span id="eq:transition_probabilities"><span class="math display">
\begin{aligned}
p^{(\kappa)}_{[t, t+\mathrm\delta t]} = \kappa\delta t + \mathcal{O}(\delta t^2)\\
p^{(\lambda)}_{[t, t+\mathrm\delta t]}(s) = s\lambda\delta t + \mathcal{O}(\delta t^2)\\
p^{(\rho)}_{[t, t+\mathrm\delta t]}(s) = s\rho\delta t + \mathcal{O}(\delta t^2)\\
p^{(\mu)}_{[t, t+\mathrm\delta t]}(x) = x\mu\delta t + \mathcal{O}(\delta t^2)
\end{aligned}
\qquad(18)</span></span></p>
<p>where <span class="math inline">s</span> and <span class="math inline">x</span> denote the particle numbers of the respective species at time <span class="math inline">t</span>. Consequently, the probability for <em>any</em> of the reactions to occur at least once in the time interval <span class="math inline">[t, t+\mathrm\delta t]</span> is</p>
<p><span id="eq:exit_probability"><span class="math display">p_{[t, t+\mathrm\delta t]}(s, x) = (\kappa + s\lambda + s\rho + x\mu)\ \mathrm \delta t + \mathcal{O}(\delta t^2)\qquad(19)</span></span></p>
<p>Using these expressions we can write down the so-called <em>chemical master equation</em> for this network. Let <span class="math inline">\mathrm P_{s,x}(t)</span> be the probability that the system is in state <span class="math inline">(s, x)</span> at time <span class="math inline">t</span>. Assuming that at most one reaction happens in the small time interval <span class="math inline">[t, t+\delta t]</span> we can use the transition probabilities from eqns. 18, 19 to write</p>
<p><span><span class="math display">
\begin{aligned}
\mathrm P_{s,x}(t + \delta t) = \phantom{+}p^{(\kappa)}_{[t, t+\mathrm\delta t]}\ \mathrm P_{s-1,x}(t)\\ +
p^{(\lambda)}_{[t, t+\mathrm\delta t]}(s + 1)\ \mathrm P_{s+1,x}(t)\\ +
p^{(\rho)}_{[t, t+\mathrm\delta t]}(s)\ \mathrm P_{s,x-1}(t)\\ +
p^{(\mu)}_{[t, t+\mathrm\delta t]}(x + 1)\ \mathrm P_{s, x + 1}(t)\\ + 
\left[1 - p_{[t, t+\mathrm\delta t]}(s, x)\right]\ \mathrm P_{s,x}(t)
\end{aligned}
\qquad(20)</span></span></p>
<p>and by taking the limit <span class="math inline">\delta t\rightarrow 0</span> we arrive at the chemical master equation</p>
<p><span id="eq:chemical_master_equation"><span class="math display">
\begin{aligned}
\frac{\partial \mathrm P_{s,x}(t)}{\partial t} = \lim\limits_{\delta t\rightarrow 0} \frac{\mathrm P_{s,x}(t + \delta t) -  \mathrm P_{s,x}(t)}{\delta t}\\
= \kappa\ \mathrm P_{s-1,x}(t) +
(s+1)\lambda\ \mathrm P_{s+1,x}(t) +
s\rho\ \mathrm P_{s,x-1}(t) +
(x+1)\mu\ \mathrm P_{s, x + 1}(t)\\ \phantom{=} - 
(\kappa + s\lambda + s\rho + x\mu)\ \mathrm P_{s,x}(t)
\end{aligned}
\qquad(21)</span></span></p>
<p>In an analogous way a chemical master equation can be derived for any biochemical network <span class="citation" data-cites="2009:Gardiner">[1]</span> and thus forms the basis for our further computations. Eq. 21 describes a special kind of <em>stochastic process</em>, a so-called <em>jump process</em>.</p>
<p>In our example we might interpret <span class="math inline">S</span> as some signal whose quantity varies stochastically. For every signal molecule there is a constant probability to be sensed by the cell which triggers the creation of an <span class="math inline">X</span>. Additionally, <span class="math inline">X</span> molecules decays by themselves over time. We call the trajectory of <span class="math inline">S</span> the “signal” and the trajectory of <span class="math inline">X</span> the “response”. This nomenclature will we used throughout the thesis.</p>
</section>
<section id="jump-processes" class="level2" data-number="1.4">
<h2 data-number="3.4"><span class="header-section-number">3.4</span> Jump Processes</h2>
<p>Since particle counts can’t ever become negative, eq. 21 describes a Markov process in continuous time with the state space <span class="math inline">\{(s, x) | s\in\mathbb{N}_0, x\in\mathbb{N}_0\}</span>. In general, every continuous-time Markov process with a discrete state space obeys a master equation. Such processes are also commonly called <em>jump processes</em> since they generate discontinuous sample paths <span class="citation" data-cites="2017:Weber">[2]</span>.</p>
<p>A jump process <span class="math inline">\mathcal{X}</span> with state space <span class="math inline">\mathcal{U}</span> and an initial state <span class="math inline">\mathbf{x}_0\in\mathcal{U}</span> at time <span class="math inline">t_0</span> generates trajectories that can be described by a sequence of pairs <span class="math inline">(\mathbf{x}_i, t_i)_{i=1,2,\ldots}</span> where at every <em>transition time</em> <span class="math inline">t_i</span> there occurs a jump in state space <span class="math inline">\mathbf{x}_{i-1}\rightarrow \mathbf{x}_{i}</span>. The trajectories generated by a jump process are infinitely long and we denote the set of all possible trajectories by <span class="math inline">\mathcal K(\mathcal X)</span>. For a given duration <span class="math inline">\tau0</span> we denote the set of all unique trajectory segments of duration <span class="math inline">\tau</span> by <span class="math inline">\mathcal K_\tau[\mathcal X]</span>. The master equation allows to express the probability distribution in trajectory space…</p>
</section>
<section id="simulating-a-biochemical-network-driven-by-an-external-signal" class="level2" data-number="1.5">
<h2 data-number="3.5"><span class="header-section-number">3.5</span> Simulating a Biochemical Network Driven by an External Signal</h2>
<p>When we want to compute information transmission in a biological context it is often</p>

</section>
<section id="references" class="level2 unnumbered" data-number="">
<h2 class="unnumbered" data-number="2">References</h2>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-2009:Gardiner">
<p>[1] C. Gardiner, Stochastic Methods, 4th ed., Springer-Verlag, Berlin Heidelberg, 2009.</p>
</div>
<div id="ref-2017:Weber">
<p>[2] M.F. Weber, E. Frey, Master equations and the theory of stochastic path integrals, Reports on Progress in Physics. 80 (2017) 046601. <a href="https://doi.org/10.1088/1361-6633/aa5ae2">https://doi.org/10.1088/1361-6633/aa5ae2</a>.</p>
</div>
</div>
</section>
</section>
<section id="estimation-strategies-inspired-by-statistical-physics" class="level1" data-number="1">
<h1 data-number="4"><span class="header-section-number">4</span> Estimation Strategies Inspired by Statistical Physics</h1>
<section id="borrowing-terminology-from-statistical-physics" class="level2" data-number="1.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Borrowing Terminology from Statistical Physics</h2>
<p>In the context of Bayesian Inference the terms of Bayes’ formula <span id="eq:bayes_thm"><span class="math display">
\mathrm P(\mathbf s | \mathbf x) = \frac{\mathrm P(\mathbf x|\mathbf s)\ \mathrm P(\mathbf s)}{\mathrm P(\mathbf x)}
\qquad(1)</span></span> are typically considered as <span class="math inline">\mathrm P(\mathbf s)</span> being the <em>prior</em> probability of…</p>
<p>In the framework employed by statistical physics, Bayes’ theorem corresponds to the canonical ensemble distribution of <span class="math inline">\mathbf s</span> (for <span class="math inline">\beta=1</span>) <span><span class="math display">
\mathrm P(\mathbf s | \mathbf x) = \frac{1}{Z(\mathbf x)}\exp\left[-E(\mathbf s, \mathbf x)\right]
\qquad(2)</span></span> where the <em>partition function</em> is defined by <span class="math inline">Z(\mathbf x) = \int \mathrm d\mathbf s\ \exp\left[-E(\mathbf s, \mathbf x)\right]</span> and <span class="math inline">E(\mathbf s, \mathbf x)</span> denotes the total energy of the system at state <span class="math inline">\mathbf s</span>. In this context <span class="math inline">\mathbf x</span> is considered a parameter vector for the specific model used to compute the energy. In classical problems of statistical physics (such as e.g. the <em>Ising model</em>) the state space spans the single particle states <span class="math inline">\mathbf{s} = (\sigma_1,\ldots,\sigma_n)\in\Omega^n</span> for all particles and the energy is given by the <em>Hamiltonian</em> <span class="math inline">\mathcal H(\sigma_1,\ldots,\sigma_n;\mathbf x)</span> where <span class="math inline">\mathbf x</span> could contain parameters describing e.g. the interaction strength between neighbouring spins. In our case however we define our energy function by comparison with eq. <a href="#eq:bayes_thm">1</a> as <span><span class="math display">E(\mathbf s, \mathbf x) = -\ln\mathrm P(\mathbf x|\mathbf s)-\ln\mathrm P(\mathbf s)\,.\qquad(3)</span></span> From this point of view the marginal density <span class="math inline">\mathrm P(\mathbf x) = Z(\mathbf x)</span> <em>is</em> the partition function of the canonical ensemble. In statistical physics the partition function is of central importance since its partial derivatives include all thermodynamic properties of a physical system. The free energy of the canonical ensemble is defined by <span class="math inline">F(\mathbf x) = -\ln Z(\mathbf x)</span> (for <span class="math inline">\beta=1</span>) such that using this terminology we can write the marginal entropy <span class="math inline">\mathrm H(\mathcal X)</span> as an average over the <em>“free energies of response trajectories”</em> <span><span class="math display">
\mathrm H(\mathcal X) = \int\mathrm d\mathbf x\ \mathrm P(\mathbf x)\ F(\mathbf x) = \left\langle F(\mathbf x) \right\rangle_{\mathrm P(\mathbf x)}\,.
\qquad(4)</span></span></p>
<p>Since the computation of the partition function is central to the solution of many statistical problems there has been done considerable work on efficient estimation of the partition function, the free energy and other related quantities such as the <em>density of states</em>.</p>
</section>
<section id="thermodynamic-integration" class="level2" data-number="1.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Thermodynamic Integration</h2>
<p>One well-established technique to estimate free energy (differences) is by thermodynamic integration (TI) <span class="citation" data-cites="1998:Gelman">[<a href="#ref-1998:Gelman" role="doc-biblioref">1</a>]</span>. It allows the accurate computation of the ratio between the normalization constants of two different probability distributions using a continuous path in <em>distribution space</em> that connects both. Since this strategy uses random samples taken from many different distributions along this path it is especially robust when the two distributions have very little overlap. For the computation of the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> we can (for a given <span class="math inline">\mathbf x</span>) define a suitable path in distribution space between <span class="math inline">\mathrm P(\mathbf s)</span> and <span class="math inline">\mathrm P(\mathbf s, \mathbf x)</span>. The normalization constants of these distributions are <span class="math inline">z_0 = 1</span> and <span class="math inline">z_1 = \mathrm P(\mathbf x)</span>, respectively such that the ratio <span class="math inline">r=z_1/z_0</span> of these normalization constants directly corresponds to the marginal density. Using TI we estimate this ratio using approximately independent samples from a <em>Markov chain Monte Carlo</em> (MCMC) simulation.</p>
<p>In the following sections we will give a quick summary of TI followed by an explanation of the Markov chain Monte Carlo simulation and a discussion of the resulting accuracy of the estimates.</p>
<section id="summary-of-ti" class="level3" data-number="1.2.1">
<h3 data-number="4.2.1"><span class="header-section-number">4.2.1</span> Summary of TI</h3>
<p>Let <span class="math inline">q_0</span> and <span class="math inline">q_1</span> be the unnormalized distribution functions and <span class="math inline">z_0, z_1</span> the corrsponding normalization constants such that <span class="math inline">z_i=\int\mathrm d\mathbf s\ q_i(\mathbf s)</span>. Next we construct a path between <span class="math inline">q_0</span> and <span class="math inline">q_1</span>, parametrized by <span class="math inline">\theta\in[0,1]</span> such that <span class="math inline">q_\theta</span> smoothly connects the end points. We similarly define <span class="math inline">z(\theta)</span> as the normalization constant of <span class="math inline">q_\theta</span>. A smooth path that can be constructed for any pair of distributions <span class="math inline">(q_0, q_1)</span> is the <em>geometric path</em> given by <span class="math inline">q_\theta=q^{1-\theta}_0\ q^\theta_1</span>. Note however that variance of the estimate depends on the chosen path and that the geometric path is not the optimal path in general.</p>
<p>For the estimation of free energy differences we are interested in the ratio <span class="math inline">r=z(1)/z(0)</span>. To find an estimate we differentiate the logarithm of <span class="math inline">z(\theta)</span> with respect to <span class="math inline">\theta</span> to arrive at <span><span class="math display">
\frac{\mathrm d\ln z(\theta)}{\mathrm d\theta} = \frac{1}{z(\theta)} \frac{\partial}{\partial\theta}  \int\mathrm d\mathbf s\ q_\theta(\mathbf s) = \int\mathrm d\mathbf s\ \frac{q_\theta(\mathbf s)}{z(\theta)} \frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s) = \left\langle \frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s) \right\rangle_{p_\theta(\mathbf s)}
\qquad(5)</span></span> where <span class="math inline">p_\theta(\mathbf s) = q_\theta(\mathbf s)/z(\theta)</span> is the normalized probability distribution corresponding to <span class="math inline">q_\theta</span>. By analogy to the potential in statistical physics we define <span><span class="math display">
U(\mathbf s, \theta) = -\frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s)\,.
\qquad(6)</span></span> Now we can express the log-ratio <span class="math inline">\lambda=\ln r</span> by the integral <span id="eq:path_sampling_int"><span class="math display">
\lambda = \ln z(1) - \ln z(0) = -\int\limits^1_0 \mathrm d\theta\ \left\langle 
U(\mathbf s, \theta)
\right\rangle_{p_\theta(\mathbf s)}
\qquad(7)</span></span> which forms the basis of all thermodynamic integration estimates. One advantage of the TI estimators is that we directly estimate the log-ratio <span class="math inline">\lambda</span>, i.e. the free energy difference as opposed to the ratio of partition functions. Indeed, to eventually compute the marginal entropy <span class="math inline">\mathrm H(\mathcal X) = -\langle\ln P(\mathbf x)\rangle</span> we require the logarithm of the marginal density thus no further error is introduced by taking the logarithm of an estimated quantity.</p>
<p>Using the previous identities, one possible way to estimate <span class="math inline">\lambda</span> is to regard <span class="math inline">\theta</span> as a random variable with a density <span class="math inline">p(\theta)</span>, allowing us to compute the integral in eq. <a href="#eq:path_sampling_int">7</a> using the Monte Carlo estimator <span id="eq:lambda_mc"><span class="math display">
\hat{\lambda}_\text{MC} = -\frac{1}{n} \sum\limits^n_{i=1}\frac{U(\mathbf s_i, \theta_i)}{p(\theta_i)}
\qquad(8)</span></span> with draws <span class="math inline">(\mathbf s_1, \theta_1),\ldots,(\mathbf s_n, \theta_n)</span> from the joint probability density <span class="math inline">p(\mathbf s, \theta) = p_\theta(\mathbf s)\ p(\theta)</span>. Alternatively, we can perform numerical integration using the trapezoidal rule by evaluating the potential over values <span class="math inline">\theta_1\cdots\theta_{n-1}</span> between <span class="math inline">\theta_0=0</span> and <span class="math inline">\theta_n=1</span> <span id="eq:lambda_ni"><span class="math display">
\hat{\lambda}_\text{NI} = -\sum\limits^n_{i=1}\frac{
  \langle U(\mathbf s, \theta_{i-1}) \rangle_{p_{\theta_{i-1}}(\mathbf s) }
  + \langle U(\mathbf s, \theta_{i}) \rangle_{p_{\theta_{i}}(\mathbf s) }
  }{2} (\theta_i - \theta_{i-1})
\qquad(9)</span></span> where each average over the potential is performed using a Monte Carlo simulation.</p>
<p>To use these estimators for the computation of the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> at a given <span class="math inline">\mathbf x</span> we need to construct a path between the densities <span class="math inline">q_0(\mathbf s) = \mathrm P(\mathbf s)</span> and <span class="math inline">q_1(\mathbf s) = \mathrm P(\mathbf s)\mathrm P(\mathbf x|\mathbf s)</span>. For simplicity and convenience we choose the geometric path <span class="math inline">q_\theta(\mathbf s) = \mathrm P(\mathbf s)\ [\mathrm P(\mathbf x|\mathbf s)]^\theta</span>. Taking the logarithm of this density we get <span class="math inline">\ln q_\theta(\mathbf s) = \ln P(\mathbf s) + \theta \ln \mathrm P(\mathbf x|\mathbf s)</span> which prompts us to define the “energy” of a signal trajecory with respect to <span class="math inline">\theta</span> as <span><span class="math display">
E(\mathbf s, \theta) = -\ln q_\theta(\mathbf s) = -\ln P(\mathbf s) - \theta \ln \mathrm P(\mathbf x|\mathbf s)\,.
\qquad(10)</span></span> For <span class="math inline">\theta = 1</span> this definition of the energy matches our previous definition by analogy with the canonical ensemble whereas for <span class="math inline">\theta = 0</span> this definition of the energy is equivalent to the energy of a signal trajectory for a system where <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span> are completely independent and thus <span class="math inline">\mathrm P(\mathbf s|\mathbf x) = \mathrm P(\mathbf s)</span>. Thus, this nomenclature also motivates the name “potential” for the quantity <span><span class="math display">
U(\mathbf s, \theta) = - \frac{\partial}{\partial\theta} \ln q_\theta(\mathbf s) = \frac{\partial}{\partial\theta} E_\theta(\mathbf s) = -\ln \mathrm P(\mathbf x|\mathbf s)
\qquad(11)</span></span> i.e. <span class="math inline">\theta</span> acts as a <em>“knob”</em> that allows us to gradually turn the potential on or off. The potential term itself characterizes the amount of dependence between the random variables <span class="math inline">\mathcal S</span> and <span class="math inline">\mathcal X</span>. Note that all energetic quantities depend on the specific response <span class="math inline">\mathbf x</span> (except at <span class="math inline">\theta=0</span>) even if this dependence is suppressed in the notation.</p>
<p>To use the TI estimators introduced in eqns. <a href="#eq:lambda_mc">8</a>, <a href="#eq:lambda_ni">9</a> we need to generate samples from arbitrary distributions along our chosen geometric path. Since we can compute the unnormalized densities of these distributions, we can use the Metropolis-Hastings algorithm as a very general method to sample from arbitrary distributions <span class="citation" data-cites="1970:Hastings">[<a href="#ref-1970:Hastings" role="doc-biblioref">2</a>]</span>.</p>
</section>
<section id="markov-chain-monte-carlo" class="level3" data-number="1.2.2">
<h3 data-number="4.2.2"><span class="header-section-number">4.2.2</span> Markov Chain Monte Carlo</h3>
<p>To generate approximately independent samples from a distribution given by the unnormalized density <span class="math inline">q_\theta</span> we start from an (in principle arbitrary) initial signal <span class="math inline">\mathbf s</span>. Next, a new signal <span class="math inline">\mathbf s^\prime</span> is proposed from the proposal distribution <span class="math inline">\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)</span> which is typically chosen to yield a <span class="math inline">\mathbf s^\prime</span> close to <span class="math inline">\mathbf s</span>. Then with some probability <span class="math inline">A(\mathbf s^\prime, \mathbf s)</span> we <em>accept</em> the new configuration and our first generated sample is <span class="math inline">\mathbf s_1 = \mathbf s^\prime</span>. Otherwise we <em>reject</em> the new configuration and our first sample is equal to the initial signal <span class="math inline">\mathbf s_1 = \mathbf s</span>. For the next iteration of the algorithm we then set our new initial signal to be <span class="math inline">\mathbf s \leftarrow \mathbf s_1</span> such that when we repeat this procedure many times we generate a sequence of signals <span class="math inline">\mathbf s_1, \mathbf s_2, \ldots</span> where each sample is a random value only directly dependent on the immediately preceding sample. Thus we have defined a Markov process that generates a <em>chain</em> of signals with the transition probability given by <span class="math inline">\mathrm P(\mathbf s \rightarrow \mathbf s^\prime) = T(\mathbf s \rightarrow \mathbf s^\prime)\,A(\mathbf s^\prime, \mathbf s)</span>. We want to choose the acceptance probability <span class="math inline">A(\mathbf s^\prime, \mathbf s)</span> such that the stationary distribution of this Markov process is precisely <span class="math inline">q_\theta</span>. It can be shown that the <em>Metropolis choice</em> <span><span class="math display">
A(\mathbf s, \mathbf s^\prime) = \min\left( 1, \frac{q_\theta(\mathbf s^\prime)}{q_\theta(\mathbf s)} \frac{\mathrm T(\mathbf s^\prime \rightarrow \mathbf s)}{\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)} \right)
\qquad(12)</span></span> leads to the correct stationary distribution given that the system is ergodic.</p>
<p>TODO: While this algorithm has some disadvantages (dependence of samples, yada yada) it often is the only sampling strategy that works at all in very high-dimensional spaces or complex distributions (is also well parallelizable)…</p>
<figure>
<img src="figures/monte_carlo_sims.svg" id="fig:monte_carlo_sims" alt="" /></img><figcaption>Figure 1: Visualization.</figcaption>
</figure>
<figure>
<img src="figures/mcmc_covariance_comparison.svg" id="fig:mcmc_covariance" alt="" /></img><figcaption>Figure 2: Comparison of the covariance matrices obtained a) by computing the empirical covariance of 1000 approximately uncorrelated samples taken from the MCMC procedure (for <span class="math inline">\theta = 1</span>) and b) by analytically computing the covariance matrix of the normal distribution <span class="math inline">\mathrm P(\mathbf s|\mathbf x)</span>. The proposal distribution is a multivariate normal distribution with covariance <span class="math inline">\Sigma=\sigma^{-2} \mathbb I</span>, with a value of <span class="math inline">\sigma=0.01</span>.</figcaption>
</figure>
<p>For the Gaussian system we choose the proposal distribution <span class="math inline">\mathrm T(\mathbf s \rightarrow \mathbf s^\prime)</span> to be a multivariate normal distribution centered around <span class="math inline">\mathbf s</span> and with uniform covariance <span class="math inline">\Sigma=\sigma^{-2} \mathbb I</span>. In fig. <a href="#fig:mcmc_covariance">2</a> we show that using the Metropolis-Hastings algorithm we can generate samples with an appropriate distribution that matches the analytical expectation. In fig. <a href="#fig:thermodynamic_int_results">3</a> we show the averaged potentials for 216 MCMC runs for different values of <span class="math inline">\theta</span>. From these potentials we can the compute the marginal density using the estimator from eq. <a href="#eq:lambda_mc">8</a>. The results are very promising since the estimated value differs by merely 0.012 % from the analytically correct value of <span class="math inline">\mathrm P(\mathbf x)</span>.</p>
<figure>
<img src="figures/mcmc_theromdynamic_integration.svg" id="fig:thermodynamic_int_results" alt="" /></img><figcaption>Figure 3: Samples of the averaged potential for different values of <span class="math inline">\theta</span>. There are 216 samples for values of <span class="math inline">\theta</span> chosen uniformly distributed in the interval <span class="math inline">[0, 1]</span>. Every point is an individual MCMC simulation with 1000 approximately independent draws. The bars on the right show a histogram of the log-likelihoods. The TI estimate is the integral from <span class="math inline">\theta=0</span> to <span class="math inline">1</span> of the curve that the individual samples approximate. Using the estimate from eq. <a href="#eq:lambda_mc">8</a>, the estimated value differs by merely 0.012 % from the analytically correct value of <span class="math inline">\mathrm P(\mathbf x)</span>. This shows that given enough samples, TI is able to provide very accurate results for the marginal density.</figcaption>
</figure>
</section>
</section>
<section id="estimating-the-density-of-states" class="level2" data-number="1.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Estimating the Density of States</h2>

<p>In the context of statistical physics we often look at configurations of a system that can be described by a parameter vector <span class="math inline">\mathbf{n}\in\Omega</span> where <span class="math inline">\Omega</span> is the state space of the system. We can typically assign a probability (density) to each configuration. For example, let’s consider the canonical ensemble for a given inverse temperature <span class="math inline">\beta</span> and Hamiltonian <span class="math inline">\mathcal H</span> <span id="eq:canonical_probability"><span class="math display">
\mathrm{P}(\mathbf{n}) = \frac{1}{Z(\beta)} e^{-\beta \mathcal H(\mathbf{n})}
\qquad(13)</span></span> with the <em>partition function</em> <span class="math inline">Z(\beta)=\int \mathrm{d}\mathbf{n}\ e^{-\beta H(\mathbf{n})}</span>. The Hamiltonian assigns an energy to every state, i.e. for every state <span class="math inline">\mathbf{n}</span> we have an associated energy <span class="math inline">\mathcal H(\mathbf{n})</span>. To learn more about the distribution of energies in our system we can now define the <em>density of states</em> <span class="math inline">g(E)</span> at a given energy <span class="math inline">E</span> as the probability density of a random<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> state <span class="math inline">\hat{\mathbf{n}}</span> to have energy <span class="math inline">\mathcal H(\hat{\mathbf{n}}) = E</span>. More precisely, let <span class="math inline">\mathcal{N}</span> be a random variable uniformly distributed in the state space, then <span><span class="math display">
g(E) = \mathrm{P}\left(\mathcal H(\mathcal N) = E\right)\,.
\qquad(14)</span></span></p>
<p>The density of states (<em>DOS</em>) thus describes the contribution of individual energy levels to the ensemble average of quantities that merely depend on the energy of a state. That is, we can compute the ensemble average <span class="math inline">\langle f(\mathcal H(\mathbf{n}))\rangle</span> of any function <span class="math inline">f</span> that depends only on the energy of a given state as <span id="eq:def_dos"><span class="math display">
\langle f(\mathcal H(\mathbf{n}))\rangle = \frac{\int_\Omega\mathrm d\mathbf n\ f(\mathcal H(\mathbf n)) e^{-\beta \mathcal H(\mathbf{n})}}{\int_\Omega\mathrm d\mathbf n\ e^{-\beta \mathcal H(\mathbf{n})}} = 
\frac{
\int\mathrm dE\ g(E) f(E) e^{-\beta E}
 }{
   \int\mathrm dE\ g(E) e^{-\beta E}
 }
\qquad(15)</span></span> where <span class="math inline">\int_\Omega\mathrm d\mathbf{n}</span> denotes an integral over phase space. Eq. <a href="#eq:def_dos">15</a> motivates the common way of specifying the DOS using the Dirac delta function <span id="eq:dirac_dos"><span class="math display">
g(E) = \int\limits_\Omega \mathrm d\mathbf n\ \delta(\mathcal H(\mathbf n) - E)
\qquad(16)</span></span> which matches the intuition of plotting an energy histogram for randomly chosen states. I.e. for discrete energies <span class="math inline">E_1\cdotsE_n</span> (the histogram bins) and random states <span class="math inline">\mathbf n_1,\ldots,\mathbf n_N</span> we can approximate the DOS as <span id="eq:dos_histogram"><span class="math display">
g_\text{discrete}(E_i) = \frac1N \sum\limits^N_{j=1} \delta_{\mathcal H(\mathbf n_j), E_i}
\qquad(17)</span></span> where <span class="math inline">\delta_{\epsilon, E_i}</span> is <span class="math inline">1</span> if the energy <span class="math inline">\epsilon</span> falls inside the <span class="math inline">i</span>-th histogram bin and <span class="math inline">0</span> otherwise. As the number of random states and the number of histogram bins grow towards infinity, <span class="math inline">g_\text{discrete}</span> converges to eq. <a href="#eq:dirac_dos">16</a>.</p>
<p>For us, the DOS is of relevance because can be used to compute the partition function <span id="eq:partition_fn_from_dos"><span class="math display">
Z(\beta) = \int\limits_\Omega \mathrm{d}\mathbf{n}\ e^{-\beta H(\mathbf{n})} = \int \mathrm dE\ g(E) e^{-\beta E}
\qquad(18)</span></span> and thus the free energy. In the following we will discuss the Wang and Landau algorithm to estimate the DOS and evaluate its usefulness for the computation of the marginal density of a trajectory.</p>

</section>
<section id="wang-and-landau-algorithm" class="level2" data-number="1.4">
<h2 data-number="4.4"><span class="header-section-number">4.4</span> Wang and Landau Algorithm</h2>
<p>Since the state spaces <span class="math inline">\Omega</span> are usually very large, one typically resorts to Monte-Carlo methods to estimate the density of states. There one generates a sequence of states <span class="math inline">\mathbf{n}_i</span> that are approximately independent and distributed according to <span class="math inline">\mathrm{P}(\mathcal{N})</span>, e.g. by using the Metropolis-Hastings algorithm. For every sampled state <span class="math inline">\mathbf{n}_i</span> we can compute the Energy <span class="math inline">\mathcal H(\mathbf{n}_i)</span> and then approximate the density of states by a histogram of the energy values as in eq. <a href="#eq:dos_histogram">17</a>. To get an accurate estimate of the density of states for energy values <span class="math inline">E</span> where <span class="math inline">g(E)</span> is very small we need a lot of iterations since we will on average pick very few samples with low probability.</p>
<p>The approach of Wang and Landau <span class="citation" data-cites="2001:Wangg8b">[<a href="#ref-2001:Wangg8b" role="doc-biblioref">3</a>]</span> is instead to not generate samples that are distributed according to the equilibrium distribution <span class="math inline">\mathrm{P}(\mathbf{n})</span> but to adaptively vary the sampling distribution throughout the simulation. This is done such that for every energy value <span class="math inline">E</span> approximately the same number of samples are acquired such that the DOS can be accurately estimated even in regions of low density <span class="math inline">g(E)</span>.</p>
<p>The main idea is to perform a random walk in energy space such that on average all energy levels in a predefined interval are visited equally often. If we switch from energy space to state space this implies that the probability density for this random walk to visit a state <span class="math inline">\mathbf n</span> is proportional to the reciprocal density of states <span class="math inline">1/g[\mathcal H(\mathbf n)]</span>. Of course we can’t sample directly using the reciprocal DOS since it is unknown. Instead, at each step of the algorithm we slightly alter our sampling distribution until the histogram of energy values becomes <em>flat</em>. Once the histogram is flat we conclude that the adaptively altered sampling distribution represents precisely the reciprocal DOS.</p>
<p>To perform Wang-Landau sampling we have to define energy bins <span class="math inline">E_1,\ldots,E_n</span> that represent the range of energies that we want to compute the DOS for. We start by setting <span class="math inline">g(E_i)=1</span> for all <span class="math inline">i=1,\ldots,n</span>. Then—similarly to Metropolis-Hastings sampling—we iteratively propose and selectively accept new configurations such that the transition probability from energy level <span class="math inline">E_i\rightarrow E_j</span> is <span><span class="math display">
p(E_i\rightarrow E_j) = \min\left( 1, \frac{g(E_i)}{g(E_j)} \right)\,.
\qquad(19)</span></span> After each proposal we update a histogram of visited energies <span class="math inline">H(E_j)\leftarrow H(E_j) + 1</span> and modify the density of states at <span class="math inline">E_j</span> by a constant factor <span class="math inline">g(E_j)\leftarrow f\ g(E_j)</span>. This updating of the sampling distribution during the simulation is precisely what makes the random walk non-Markovian and promises fast convergence towards the correct DOS. We start the procedure with the factor <span class="math inline">f=\exp(1)=e</span>. Once the histogram <span class="math inline">H(E)</span> is sufficiently flat (we use 95% flatness) we update <span class="math inline">f\leftarrow \sqrt{f}</span> and reset the histogram to continue sampling. We continue the simulation, iteratively reducing <span class="math inline">f</span> until it reaches a small predefined threshold value which allows us to adjust the tradeoff between accuracy and simulation speed.</p>
<p>One important consideration is the choice of energy bins. Since we are interested in the computation of the partition function using eq. <a href="#eq:partition_fn_from_dos">18</a>, the relevant energies are those where the product <span class="math inline">g(E)e^{-\beta E}</span> is not vanishingly small. Additionally we have to take into account that the estimate for the DOS is not normalized. To be able to correctly normalize the DOS we have to ensure that the range of energy bins includes all energies where the DOS is non-vanishing.</p>
<section id="applying-wang-landau-to-the-computation-of-the-marginal-density" class="level3" data-number="1.4.1">
<h3 data-number="4.4.1"><span class="header-section-number">4.4.1</span> Applying Wang-Landau to the Computation of the Marginal Density</h3>
<p>When working with statistical models such as the Ising model there is often a clear concept of the <em>state space</em> <span class="math inline">\Omega</span> and an associated volume of regions in state space such that integrals of the form <span class="math inline">\int_\Omega\mathrm d\mathbf n\ f(\mathbf n)</span> are well-defined for any <span class="math inline">f: \Omega\rightarrow\mathbb{R}</span>. However in the case where the individual states <span class="math inline">\mathbf n</span> represent stochastic trajectories it is not obvious what the meaning of such an integral should be. Therefore we use a modified DOS defined for a given response trajectory <span class="math inline">\mathbf x</span> by <span id="eq:modified_dos"><span class="math display">
\rho(U) = \int\mathrm d\mathbf s\ \mathrm P(\mathbf s)\,\delta(U(\mathbf s, \mathbf x) - U)
\qquad(20)</span></span> with <span class="math inline">U(\mathbf s, \mathbf x) = -\ln\mathrm P(\mathbf x|\mathbf s)</span>. In other words we are assigning a measure <span class="math inline">\mu</span> to our state space which is defined by the inherent probability density of the signals, such that <span class="math inline">\int\mu(\mathrm d\mathbf s) \equiv \int\mathrm d\mathbf s\ \mathrm P(\mathbf s)</span>. Thus we can express the marginal density of <span class="math inline">\mathbf x</span> analogously to eq. <a href="#eq:partition_fn_from_dos">18</a> by <span id="eq:modified_int"><span class="math display">
\mathrm P(\mathbf x) = \int\mathrm dU\ \rho(U)\,e^{-U}\,.
\qquad(21)</span></span></p>
<p>We have to slightly adapt the Wang-Landau procedure described above so that it produces an estimate of the modified DOS. To account for the density <span class="math inline">\mathrm P(\mathbf s)</span> in eq. <a href="#eq:modified_dos">20</a> we need ensure we propose configurations, asymptotically distributed according to <span class="math inline">\mathrm P(\mathbf s)</span>, which we then—in a second step—accept or reject using the inverse DOS. However we can combine both of these steps into a single one by combining a Metropolis acceptance step with the usual Wang-Landau procedure. Our algorithm therefore consists of the follwing steps:</p>
<ol type="1">
<li>Set all entries of the modified DOS to 1, <span class="math inline">\rho(U_i)=1, i=1,\ldots,n</span>.</li>
<li>Set all entries of the histogram to 0, <span class="math inline">H(U_i)=0, i=1,\ldots,n</span>.</li>
<li>Loop until <span class="math inline">f\epsilon</span>.
<ol type="1">
<li>Propose a new configuration <span class="math inline">\mathbf s^\prime\sim T(\mathbf s\rightarrow \mathbf s^\prime)</span>.</li>
<li>Let <span class="math inline">U_i</span> be the potential of state <span class="math inline">\mathbf s</span> and <span class="math inline">U_j</span> the potential of state <span class="math inline">\mathbf s^\prime</span>.</li>
<li>Accept the new configuration with probability <span id="eq:modified_acceptance_probability"><span class="math display">A(\mathbf s^\prime, \mathbf s) = \min\left[1, \frac{\mathrm P(\mathbf s^\prime)}{\mathrm P(\mathbf s)} \frac{\rho(U_i)}{\rho(U_j)} \frac{T(\mathbf s^\prime\rightarrow \mathbf s)}{T(\mathbf s\rightarrow \mathbf s^\prime)} \right]\,.
 \qquad(22)</span></span></li>
<li>Let <span class="math inline">U^\star</span> be either <span class="math inline">U_j</span> if <span class="math inline">\mathbf s^\prime</span> was accepted or <span class="math inline">U_i</span> otherwise.</li>
<li>Update the histogram <span class="math inline">H(U^\star)\leftarrow H(U^\star)+1</span> and the DOS <span class="math inline">\rho(U^\star)\leftarrow f\,\rho(U^\star)</span>.</li>
<li>If the histogram <span class="math inline">H</span> is flat, set <span class="math inline">f\leftarrow\sqrt f</span> and reset <span class="math inline">H(U_i)=0, i=1,\ldots,n</span>.</li>
</ol></li>
</ol>
<p>The proposal distribution <span class="math inline">T</span> can in principle be arbitrary. The definition of the acceptance probability in eq. <a href="#eq:modified_acceptance_probability">22</a> illustrates that—once the simulation is converged—<span class="math inline">\rho</span> describes how we have to modify the state space density <span class="math inline">\mathrm P(\mathbf s)</span> such that we sample uniformly over all potentials.</p>
<figure>
<img src="figures/normalized_densities.svg" id="fig:normalized_densities" alt="" /></img><figcaption>Figure 4: Exemplifying the benefit of the Wang-Landau algorithm for the multivariate normal system at different dimensionalities: The blue lines show the modified density of states from eq. <a href="#eq:modified_dos">20</a>, computed using a conventional MC simulation. The orange line represents the Boltzmann factor <span class="math inline">e^{-U}</span> and the green line shows the integrand of eq. <a href="#eq:modified_int">21</a> which is the product of the other two quantities. For visualization purposes, all functions where rescaled such that their integrals over the displayed interval equal 1. We see that especially at higher dimensionality there is very little overlap between the green and the blue line which leads to high inaccuracy in the computation of the marginal density. For all simulations we chose the covariance matrix using <span class="math inline">\Delta t = 64</span>.</figcaption>
</figure>
<p>Fig. <a href="#fig:normalized_densities">4</a> makes it clear why we expect Wang-Landau sampling to lead to a better estimate of the marginal density than the brute-force Monte-Carlo computation, especially in high-dimensional state spaces. For <span class="math inline">d=50</span> and <span class="math inline">d=200</span> most of the weight of the integral is in regions where <span class="math inline">\rho(E)\approx 0</span>. In these low density regions we usually get a very inaccurate estimation of the (modified) DOS by normal MC simulations since we only very occasionally sample a relevant state. The Wang-Landau algorithm ensures that for every energy there is a consistent sampling density and we get a good estimate of the DOS even in low-density regimes.</p>
<p>From fig. <a href="#fig:normalized_densities">4</a> we can also estimate for which range of potentials we must compute the DOS. Since the Boltzmann weight <span class="math inline">e^{-U}</span> strongly favours low-potential configurations it is important to compute the DOS for very low potentials even if it nearly vanishes there (i.e. in regions where the blue line vanishes but the green line has relevant weight).</p>

</section>
<section id="connection-to-standard-monte-carlo-sampling" class="level3" data-number="1.4.2">
<h3 data-number="4.4.2"><span class="header-section-number">4.4.2</span> Connection to Standard Monte-Carlo Sampling</h3>
<p>When we perform a standard Monte-Carlo estimate of <span class="math inline">\mathrm{P}(\mathbf{x})</span> we generate independent samples <span class="math inline">\mathbf{s}_1,\ldots,\mathbf{s}_M</span>, all identically distributed according to <span class="math inline">\mathrm P(\mathcal{S})</span> and then compute <span><span class="math display">
\hat{\mathrm{P}}(\mathbf{x}) = \frac{1}{M} \sum\limits^M_{i=1} \mathrm{P}(\mathbf x|\mathbf s_i) \,.
\qquad(23)</span></span> This estimate is essentially the same as performing the integral from eq. <a href="#eq:modified_int">21</a> where the density of states <span class="math inline">\rho(U)</span> is just approximated as the histogram of the potentials <span class="math inline">U(\mathbf{s}_1),\ldots,U(\mathbf{s}_M)</span>. Specifically in the limit of the width of histogram bins approaching 0, the approximate density of states becomes <span class="math inline">\hat{\rho}(U)=1/M\ \sum^M_{i=1} \delta(U-U(\mathbf{s}_i))</span> and therefore <span><span class="math display">
\int\mathrm{d}U\ \hat{\rho}(U) e^{-U} = \frac{1}{M}\int\mathrm dU \left[\sum^M_{i=1} \delta(U-U(\mathbf{s}_i)) e^{-U}\right] = \frac{1}{M} \sum\limits^M_{i=1} e^{-U(\mathbf{s}_i)} = \hat{\mathrm{P}}(\mathbf{x})\,.
\qquad(24)</span></span></p>
<p>For the purpose of comparing estimates we can therefore associate the standard MC approach with computing the empirical histogram of potential values when sampling signals according to their marginal distribution. In the next section we will compare this empirical histogram to the DOS as computed using the Wang-Landau algorithm.</p>
</section>
<section id="results-for-wang-landau" class="level3" data-number="1.4.3">
<h3 data-number="4.4.3"><span class="header-section-number">4.4.3</span> Results for Wang Landau</h3>
<figure>
<img src="figures/wl_dos.svg" id="fig:wl_dos" alt="" /></img><figcaption>Figure 5: Plots of estimates of the modified DOS from eq. <a href="#eq:modified_dos">20</a> compared on both linear and log scales. The blue line shows the Wang Landau estimate while the orange line is a histogram estimate using unbiased sampling according to <span class="math inline">\mathrm P(\mathbf s)</span>. We see that especially in the low-potential regime the Wang Landau estimate is much more accurate.</figcaption>
</figure>
<p>In fig. <a href="#fig:wl_dos">5</a> we display the estimated DOS using the Wang Landau algorithm compared with a histogram estimate of the DOS using unbiased sampling. We see that in the highly relevant regime of low potential the Wang Landau procedure allows us to get an accurate estimate of the DOS even though its density is as low as <span class="math inline">e^{-30}</span>. Using eq. <a href="#eq:modified_int">21</a> we compute the marginal density to be <span class="math inline">-688.52</span> whereas the “correct” value computed analytically is <span class="math inline">-683.02</span>. We thus find a relative error of <span class="math inline">0.8\%</span> in this estimate.</p>
<p>While we can achieve a good estimate for the marginal density <span class="math inline">\mathrm P(\mathbf x)</span> using the estimated DOS from the Wang-Landau algorithm there remain some practical difficulties. For maximum efficiency and accuracy the different parameters affecting the procedure such as the required histogram flatness, the updating scheme of the <span class="math inline">f</span> parameter, and the choice of potential bins have to be tuned for a given problem. After some tuning of these parameters for the Gaussian system for a fixed set of covariance matrices we still find the estimation to be at least one order of magnitude slower in CPU time compared to thermodynamic integration. Therefore, at least for the Gaussian system thermodynamic integration seems to be better suited to compute the marginal density.</p>
<p>With that said, we do expect the Wang Landau procedure to perform especially well in cases were there are many local minima of the potential. Here using TI we might get <em>“stuck”</em> in a specific minimum and thus not sample all relevant states. Therefore we suggest that while TI should be the method of choice for the computation of the marginal density for high dimensional systems, in specific cases it may make sense to try other approaches that are well-established in statistical physics, such as Wang Landau.</p>


</section>
</section>
<section id="references" class="level2 unnumbered" data-number="">
<h2 class="unnumbered" data-number="3">References</h2>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-1998:Gelman">
<p>[1] A. Gelman, X.-L. Meng, Simulating normalizing constants: from importance sampling to bridge sampling to path sampling, Statistical Science. 13 (1998) 163–185. <a href="https://doi.org/10.1214/ss/1028905934">https://doi.org/10.1214/ss/1028905934</a>.</p>
</div>
<div id="ref-1970:Hastings">
<p>[2] W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications, Biometrika. 57 (1970) 97–109. <a href="https://doi.org/10.1093/biomet/57.1.97">https://doi.org/10.1093/biomet/57.1.97</a>.</p>
</div>
<div id="ref-2001:Wangg8b">
<p>[3] F. Wang, D.P. Landau, Determining the density of states for classical statistical models: A random walk algorithm to produce a flat histogram, Physical Review E. 64 (2001) 056101. <a href="https://doi.org/10.1103/physreve.64.056101">https://doi.org/10.1103/physreve.64.056101</a>.</p>
</div>
</div>
</section>
</section>
<section class="footnotes" role="doc-endnotes">
<hr /></hr>
<ol>
<li id="fn1" role="doc-endnote"><p>By random state we refer to a state randomly chosen from the state space and <em>not</em> a state sampled according to the density given in eq. <a href="#eq:canonical_probability">13</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        
        

        

        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        

    </body>
</html>