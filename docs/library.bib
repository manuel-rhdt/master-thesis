@article{1995.Kass, 
author = {Kass, Robert E and Raftery, Adrian E}, 
title = {{Bayes Factors}}, 
issn = {0162-1459}, 
doi = {10.1080/01621459.1995.10476572}, 
abstract = {{In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points:}}, 
pages = {773--795}, 
number = {430}, 
volume = {90}, 
journal = {Journal of the American Statistical Association}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Journal%20of%20the%20American%20Statistical%20Association-1995-Kass-Raftery.pdf}, 
year = {1995}
}
@article{1962.Parzen, 
author = {Parzen, Emanuel}, 
title = {{On Estimation of a Probability Density Function and Mode}}, 
issn = {0003-4851}, 
doi = {10.1214/aoms/1177704472}, 
pages = {1065--1076}, 
number = {3}, 
volume = {33}, 
journal = {The Annals of Mathematical Statistics}, 
year = {1962}
}
@article{1956.Rosenblatt, 
author = {Rosenblatt, Murray}, 
title = {{Remarks on Some Nonparametric Estimates of a Density Function}}, 
issn = {0003-4851}, 
doi = {10.1214/aoms/1177728190}, 
abstract = {{This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymptotic mean square error of a particular class of estimates is evaluated.}}, 
pages = {832--837}, 
number = {3}, 
volume = {27}, 
journal = {The Annals of Mathematical Statistics}, 
year = {1956}
}
@article{2001.Neal, 
author = {Neal, Radford M}, 
title = {{Annealed importance sampling}}, 
issn = {0960-3174}, 
doi = {10.1023/a:1008923215028}, 
abstract = {{Simulated annealing—moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions—has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.}}, 
pages = {125--139}, 
number = {2}, 
volume = {11}, 
journal = {Statistics and Computing}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Statistics%20and%20Computing-2001-Neal-Neal.pdf}, 
year = {2001}
}
@article{1987.Tanner, 
author = {Tanner, Martin A and Wong, Wing Hung}, 
title = {{The Calculation of Posterior Distributions by Data Augmentation}}, 
issn = {0162-1459}, 
doi = {10.1080/01621459.1987.10478458}, 
pages = {528--540}, 
number = {398}, 
volume = {82}, 
journal = {Journal of the American Statistical Association}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Journal%20of%20the%20American%20Statistical%20Association-1987-Tanner-Wong.pdf}, 
year = {1987}
}
@article{1976.Bennett, 
author = {Bennett, Charles H}, 
title = {{Efficient estimation of free energy differences from Monte Carlo data}}, 
issn = {0021-9991}, 
doi = {10.1016/0021-9991(76)90078-4}, 
abstract = {{Near-optimal strategies are developed for estimating the free energy difference between two canonical ensembles, given a Metropolis-type Monte Carlo program for sampling each one. The estimation strategy depends on the extent of overlap between the two ensembles, on the smoothness of the density-of-states as a function of the difference potential, and on the relative Monte Carlo sampling costs, per statistically independent data point. The best estimate of the free energy difference is usually obtained by dividing the available computer time approximately equally between the two ensembles; its efficiency (variance x computer time)-1 is never less, and may be several orders of magnitude greater, than that obtained by sampling only one ensemble, as is done in perturbation theory.}}, 
pages = {245--268}, 
number = {2}, 
volume = {22}, 
journal = {Journal of Computational Physics}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Journal%20of%20Computational%20Physics-1976-Bennett-Bennett.pdf}, 
year = {1976}
}
@article{2017.Meulen, 
author = {Meulen, Frank van der and Schauer, Moritz}, 
title = {{Bayesian estimation of discretely observed multi-dimensional diffusion processes using guided proposals}}, 
issn = {1935-7524}, 
doi = {10.1214/17-ejs1290}, 
eprint = {1406.4704}, 
abstract = {{Estimation of parameters of a diffusion based on discrete time observations poses a difficult problem due to the lack of a closed form expression for the likelihood. From a Bayesian computational perspective it can be casted as a missing data problem where the diffusion bridges in between discrete-time observations are missing. The computational problem can then be dealt with using a Markov-chain Monte-Carlo method known as data-augmentation. If unknown parameters appear in the diffusion coefficient, direct implementation of data-augmentation results in a Markov chain that is reducible. Furthermore, data-augmentation requires efficient sampling of diffusion bridges, which can be difficult, especially in the multidimensional case. We present a general framework to deal with with these problems that does not rely on discretisation. The construction generalises previous approaches and sheds light on the assumptions necessary to make these approaches work. We define a random-walk type Metropolis-Hastings sampler for updating diffusion bridges. Our methods are illustrated using guided proposals for sampling diffusion bridges. These are Markov processes obtained by adding a guiding term to the drift of the diffusion. We give general guidelines on the construction of these proposals and introduce a time change and scaling of the guided proposal that reduces discretisation error. Numerical examples demonstrate the performance of our methods.}}, 
pages = {2358--2396}, 
number = {1}, 
volume = {11}, 
journal = {Electronic Journal of Statistics}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Electronic%20Journal%20of%20Statistics-2017-Meulen-Schauer.pdf}, 
year = {2017}
}
@article{2016.Meulen, 
author = {Meulen, Frank van der and Schauer, Moritz}, 
title = {{Bayesian estimation of incompletely observed diffusions}}, 
issn = {1744-2508}, 
doi = {10.1080/17442508.2017.1381097}, 
eprint = {1606.04082}, 
abstract = {{We present a general framework for Bayesian estimation of incompletely observed multivariate diffusion processes. Observations are assumed to be discrete in time, noisy and incomplete. We assume the drift and diffusion coefficient depend on an unknown parameter. A data-augmentation algorithm for drawing from the posterior distribution is presented which is based on simulating diffusion bridges conditional on a noisy incomplete observation at an intermediate time. The dynamics of such filtered bridges are derived and it is shown how these can be simulated using a generalised version of the guided proposals introduced in Schauer et al. (2016).}}, 
pages = {641--662}, 
number = {5}, 
volume = {90}, 
journal = {arXiv}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/arXiv-2016-Meulen-Schauer.pdf}, 
year = {2016}
}
@article{2017.Mider, 
author = {Mider, Marcin and Schauer, Moritz and Meulen, Frank van der}, 
title = {{Continuous-discrete smoothing of diffusions}}, 
eprint = {1712.03807}, 
abstract = {{Suppose X is a multivariate diffusion process that is observed discretely in time. At each observation time, a linear transformation of the state of the process is observed with noise. The smoothing problem consists of recovering the path of the process, consistent with the observations. We derive a novel Markov Chain Monte Carlo algorithm to sample from the exact smoothing distribution. The resulting algorithm is called the Backward Filtering Forward Guiding (BFFG) algorithm. We extend the algorithm to include parameter estimation. The proposed method relies on guided proposals introduced in Schauer et al. (2017). We illustrate its efficiency in a number of challenging problems.}}, 
journal = {arXiv}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/arXiv-2017-Mider-Meulen.pdf}, 
year = {2017}
}
@book{1992.Kloeden, 
author = {Kloeden, Peter E and Platen, Eckhard}, 
title = {{Numerical Solution of Stochastic Differential Equations}}, 
isbn = {9783642081071}, 
year = {1992}
}
@article{2008.Boulware, 
author = {Boulware, Michael J and Marchant, Jonathan S}, 
title = {{Timing in Cellular Ca2+ Signaling}}, 
issn = {0960-9822}, 
doi = {10.1016/j.cub.2008.07.018}, 
pmid = {18786382}, 
pmcid = {PMC3236564}, 
abstract = {{Calcium (Ca2+) signals are generated across a broad time range. Kinetic considerations impact how information is processed to encode and decode Ca2+ signals, the choreography of responses that ensure specific and efficient signaling and the overall temporal amplification such that ephemeral Ca2+ signals have lasting physiological value. The reciprocal importance of timing for Ca2+ signaling, and Ca2+ signaling for timing is exemplified by the altered kinetic profiles of Ca2+ signals in certain diseases and the likely role of basal Ca2+ fluctuations in the perception of time itself.}}, 
pages = {R769--R776}, 
number = {17}, 
volume = {18}, 
journal = {Current Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Current%20Biology-2008-Boulware-Marchant.pdf}, 
year = {2008}
}
@article{2020.Leifer, 
author = {Leifer, Ian and Morone, Flaviano and Reis, Saulo D. S. and Andrade, José S. and Sigman, Mariano and Makse, Hernán A.}, 
title = {{Circuits with broken fibration symmetries perform core logic computations in biological networks}}, 
issn = {1553-7358}, 
doi = {10.1371/journal.pcbi.1007776}, 
url = {http://dx.doi.org/10.1371/journal.pcbi.1007776}, 
pages = {e1007776}, 
number = {6}, 
volume = {16}, 
journal = {PLOS Computational Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/PLOS%20Computational%20Biology-2020-Leifer-Makse.pdf}, 
year = {2020}
}
@article{1997.Bunkin, 
author = {Bunkin, F V and Kadomtsev, Boris B and Klimontovich, Yu L and Koroteev, Nikolai I and Landa, Polina S and Maslov, V P and Romanovskii, Yurii M}, 
title = {{In memory of Ruslan Leont'evich Stratonovich}}, 
issn = {1063-7869}, 
doi = {10.1070/pu1997v040n07abeh000259}, 
pages = {751--752}, 
number = {7}, 
volume = {40}, 
journal = {Physics-Uspekhi}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Physics-Uspekhi-1997-Bunkin-Romanovskii.pdf}, 
year = {1997}
}
@article{2010.Kunita, 
author = {Kunita, Hiroshi}, 
title = {{Itô’s stochastic calculus: Its surprising power for applications}}, 
issn = {0304-4149}, 
doi = {10.1016/j.spa.2010.01.013}, 
abstract = {{We trace Itô’s early work in the 1940s, concerning stochastic integrals, stochastic differential equations (SDEs) and Itô’s formula. Then we study its developments in the 1960s, combining it with martingale theory. Finally, we review a surprising application of Itô’s formula in mathematical finance in the 1970s. Throughout the paper, we treat Itô’s jump SDEs driven by Brownian motions and Poisson random measures, as well as the well-known continuous SDEs driven by Brownian motions.}}, 
pages = {622--652}, 
number = {5}, 
volume = {120}, 
journal = {Stochastic Processes and their Applications}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Stochastic%20Processes%20and%20their%20Applications-2010-Kunita-Kunita.pdf}, 
year = {2010}
}
@article{1908.Langevin, 
author = {Langevin, Paul}, 
title = {{Sur la théorie du mouvement brownien}}, 
pages = {530--533}, 
number = {146}, 
journal = {C. R. Acad. Sci.}, 
year = {1908}
}
@book{2006.Cover, 
author = {Cover, Thomas M. and Thomas, Joy A.}, 
title = {{Elements of Information Theory}}, 
isbn = {978-0-471-24195-9}, 
publisher = {John Wiley \& Sons}, 
edition = {2}, 
year = {2006}
}
@article{2009.Tkačik, 
author = {Tkačik, Gašper and Walczak, Aleksandra M and Bialek, William}, 
title = {{Optimizing information flow in small genetic networks}}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.80.031920}, 
pmid = {19905159}, 
eprint = {0903.4491}, 
abstract = {{In order to survive, reproduce, and (in multicellular organisms) differentiate, cells must control the concentrations of the myriad different proteins that are encoded in the genome. The precision of this control is limited by the inevitable randomness of individual molecular events. Here we explore how cells can maximize their control power in the presence of these physical limits; formally, we solve the theoretical problem of maximizing the information transferred from inputs to outputs when the number of available molecules is held fixed. We start with the simplest version of the problem, in which a single transcription factor protein controls the readout of one or more genes by binding to DNA. We further simplify by assuming that this regulatory network operates in steady state, that the noise is small relative to the available dynamic range, and that the target genes do not interact. Even in this simple limit, we find a surprisingly rich set of optimal solutions. Importantly, for each locally optimal regulatory network, all parameters are determined once the physical constraints on the number of available molecules are specified. Although we are solving an oversimplified version of the problem facing real cells, we see parallels between the structure of these optimal solutions and the behavior of actual genetic regulatory networks. Subsequent papers will discuss more complete versions of the problem.}}, 
pages = {031920}, 
number = {3}, 
volume = {80}, 
journal = {Physical Review E}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Physical%20Review%20E-2009-Tkačik-Bialek.pdf}, 
year = {2009}
}
@article{2011.Hallatschek, 
author = {Hallatschek, Oskar}, 
title = {{Noise Driven Evolutionary Waves}}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1002005}, 
pmid = {21423714}, 
pmcid = {PMC3053316}, 
abstract = {{Adaptation in spatially extended populations entails the propagation of evolutionary novelties across habitat ranges. Driven by natural selection, beneficial mutations sweep through the population in a “wave of advance”. The standard model for these traveling waves, due to R. Fisher and A. Kolmogorov, plays an important role in many scientific areas besides evolution, such as ecology, epidemiology, chemical kinetics, and recently even in particle physics. Here, we extend the Fisher–Kolmogorov model to account for mutations that confer an increase in the density of the population, for instance as a result of an improved metabolic efficiency. We show that these mutations invade by the action of random genetic drift, even if the mutations are slightly deleterious. The ensuing class of noise-driven waves are characterized by a wave speed that decreases with increasing population sizes, contrary to conventional Fisher–Kolmogorov waves. When a trade-off exists between density and growth rate, an evolutionary optimal population density can be predicted. Our simulations and analytical results show that genetic drift in conjunction with spatial structure promotes the economical use of limited resources. The simplicity of our model, which lacks any complex interactions between individuals, suggests that noise-induced pattern formation may arise in many complex biological systems including evolution.}}, 
pages = {e1002005}, 
number = {3}, 
volume = {7}, 
journal = {PLoS Computational Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/PLoS%20Computational%20Biology-2011-Hallatschek-Hallatschek.pdf}, 
year = {2011}
}
@article{1990.Parsons, 
author = {Parsons, P A}, 
title = {{Fluctuating Asymmetry: An Epigenetic Measure of Stress}}, 
issn = {1464-7931}, 
doi = {10.1111/j.1469-185x.1990.tb01186.x}, 
pmid = {2190634}, 
abstract = {{(1) Fluctuating asymmetry (FA) is a useful trait for monitoring stress in the laboratory and in natural environments.
(2) Both genomic and environmental changes can increase FA which represents a deterioration in developmental homeostasis apparent in adult morphology. Genetic perturbations include intense directional selection and certain specific genes. Environmental perturbations include temperature extremes in particular, protein deprivation, audiogenic stress, and exposure to pollutants.
(3) There is a negative association between FA and heterozygosity in a range of taxa especially fish, a result consistent with FA being a measure of fitness.
(4) Scattered reports on non-experimental populations are consistent with experiments under controlled laboratory conditions. FA tends to increase as habitats become ecologically marginal; this includes exposure to environmental toxicants.
(5) In our own species, FA of an increasing range of traits has been related to both environmental and genomic stress.
(6) Domestication increases FA of the strength of homologous long bones of vertebrate species due to a relaxation of natural selection.
(7) FA levels are paralleled by the incidence of skeletal abnormalities in stressful environments.
(8) Increased FA is a reflection of poorer developmental homeostasis at the molecular, chromosomal and epigenetic levels.}}, 
pages = {131--145}, 
number = {2}, 
volume = {65}, 
journal = {Biological Reviews}, 
year = {1990}
}
@article{2008.Faisal, 
author = {Faisal, A Aldo and Selen, Luc P J and Wolpert, Daniel M}, 
title = {{Noise in the nervous system}}, 
issn = {1471-003X}, 
doi = {10.1038/nrn2258}, 
pmid = {18319728}, 
pmcid = {PMC2631351}, 
abstract = {{Noise--random disturbances of signals--poses a fundamental problem for information processing and affects all aspects of nervous-system function. However, the nature, amount and impact of noise in the nervous system have only recently been addressed in a quantitative manner. Experimental and computational methods have shown that multiple noise sources contribute to cellular and behavioural trial-to-trial variability. We review the sources of noise in the nervous system, from the molecular to the behavioural level, and show how noise contributes to trial-to-trial variability. We highlight how noise affects neuronal networks and the principles the nervous system applies to counter detrimental effects of noise, and briefly discuss noise's potential benefits.}}, 
pages = {292--303}, 
number = {4}, 
volume = {9}, 
journal = {Nature Reviews Neuroscience}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Nature%20Reviews%20Neuroscience-2008-Faisal-Wolpert.pdf}, 
year = {2008}
}
@article{1995.Mainen, 
author = {Mainen, Z and Sejnowski, T}, 
title = {{Reliability of spike timing in neocortical neurons}}, 
issn = {0036-8075}, 
doi = {10.1126/science.7770778}, 
pmid = {7770778}, 
pages = {1503--1506}, 
number = {5216}, 
volume = {268}, 
journal = {Science}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Science-1995-Mainen-Sejnowski.pdf}, 
year = {1995}
}
@article{2018.Timme, 
author = {Timme, Nicholas M and Lapish, Christopher}, 
title = {{A Tutorial for Information Theory in Neuroscience}}, 
issn = {2373-2822}, 
doi = {10.1523/eneuro.0052-18.2018}, 
pmid = {30211307}, 
abstract = {{Understanding how neural systems integrate, encode, and compute information is central to understanding brain function. Frequently, data from neuroscience experiments are multivariate, the interactions between the variables are nonlinear, and the landscape of hypothesized or possible interactions between variables is extremely broad. Information theory is well suited to address these types of data, as it possesses multivariate analysis tools, it can be applied to many different types of data, it can capture nonlinear interactions, and it does not require assumptions about the structure of the underlying data (i.e., it is model independent). In this article, we walk through the mathematics of information theory along with common logistical problems associated with data type, data binning, data quantity requirements, bias, and significance testing. Next, we analyze models inspired by canonical neuroscience experiments to improve understanding and demonstrate the strengths of information theory analyses. To facilitate the use of information theory analyses, and an understanding of how these analyses are implemented, we also provide a free MATLAB software package that can be applied to a wide range of data from neuroscience experiments, as well as from other fields of study.}}, 
pages = {ENEURO.0052--18.2018}, 
number = {3}, 
volume = {5}, 
journal = {eneuro}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/eneuro-2018-Timme-Lapish.pdf}, 
year = {2018}
}
@article{2002.Elowitz, 
author = {Elowitz, Michael B. and Levine, Arnold J. and Siggia, Eric D. and Swain, Peter S.}, 
title = {{Stochastic Gene Expression in a Single Cell}}, 
issn = {0036-8075}, 
doi = {10.1126/science.1070919}, 
pmid = {12183631}, 
abstract = {{Clonal populations of cells exhibit substantial phenotypic variation. Such heterogeneity can be essential for many biological processes and is conjectured to arise from stochasticity, or noise, in gene expression. We constructed strains of Escherichia coli that enable detection of noise and discrimination between the two mechanisms by which it is generated. Both stochasticity inherent in the biochemical process of gene expression (intrinsic noise) and fluctuations in other cellular components (extrinsic noise) contribute substantially to overall variation. Transcription rate, regulatory dynamics, and genetic factors control the amplitude of noise. These results establish a quantitative foundation for modeling noise in genetic networks and reveal how low intracellular copy numbers of molecules can fundamentally limit the precision of gene regulation.}}, 
pages = {1183--1186}, 
number = {5584}, 
volume = {297}, 
journal = {Science}, 
year = {2002}
}
@article{2009.Simpson, 
author = {Simpson, Michael L and Cox, Chris D and Allen, Michael S and McCollum, James M and Dar, Roy D and Karig, David K and Cooke, John F}, 
title = {{Noise in biological circuits}}, 
issn = {1939-5116}, 
doi = {10.1002/wnan.22}, 
pmid = {20049792}, 
abstract = {{Noise biology focuses on the sources, processing, and biological consequences of the inherent stochastic fluctuations in molecular transitions or interactions that control cellular behavior. These fluctuations are especially pronounced in small systems where the magnitudes of the fluctuations approach or exceed the mean value of the molecular population. Noise biology is an essential component of nanomedicine where the communication of information is across a boundary that separates small synthetic and biological systems that are bound by their size to reside in environments of large fluctuations. Here we review the fundamentals of the computational, analytical, and experimental approaches to noise biology. We review results that show that the competition between the benefits of low noise and those of low population has resulted in the evolution of genetic system architectures that produce an uneven distribution of stochasticity across the molecular components of cells and, in some cases, use noise to drive biological function. We review the exact and approximate approaches to gene circuit noise analysis and simulation, and review many of the key experimental results obtained using flow cytometry and time‐lapse fluorescent microscopy. In addition, we consider the probative value of noise with a discussion of using measured noise properties to elucidate the structure and function of the underlying gene circuit. We conclude with a discussion of the frontiers of and significant future challenges for noise biology. Copyright © 2009 John Wiley \& Sons, Inc. This article is categorized under: Nanotechnology Approaches to Biology > Cells at the Nanoscale}}, 
pages = {214--225}, 
number = {2}, 
volume = {1}, 
journal = {Wiley Interdisciplinary Reviews: Nanomedicine and Nanobiotechnology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Wiley%20Interdisciplinary%20Reviews-%20Nanomedicine%20and%20Nanobiotechnology-2009-Simpson-Cooke.pdf}, 
year = {2009}
}
@article{2010.Nemenman, 
author = {Nemenman, Ilya}, 
title = {{Information theory and adaptation}}, 
eprint = {1011.5466}, 
abstract = {{In this Chapter, we ask questions (1) What is the right way to measure the quality of information processing in a biological system? and (2) What can real-life organisms do in order to improve their performance in information-processing tasks? We then review the body of work that investigates these questions experimentally, computationally, and theoretically in biological domains as diverse as cell biology, population biology, and computational neuroscience}}, 
journal = {arXiv}, 
year = {2010}
}
@article{2014.Levchenko, 
author = {Levchenko, Andre and Nemenman, Ilya}, 
title = {{Cellular noise and information transmission}}, 
issn = {0958-1669}, 
doi = {10.1016/j.copbio.2014.05.002}, 
pmid = {24922112}, 
abstract = {{The technological revolution in biological research, and in particular the use of molecular fluorescent labels, has allowed investigation of heterogeneity of cellular responses to stimuli on the single cell level. Computational, theoretical, and synthetic biology advances have allowed predicting and manipulating this heterogeneity with an exquisite precision previously reserved only for physical sciences. Functionally, this cell-to-cell variability can compromise cellular responses to environmental signals, and it can also enlarge the repertoire of possible cellular responses and hence increase the adaptive nature of cellular behaviors. And yet quantification of the functional importance of this response heterogeneity remained elusive. Recently the mathematical language of information theory has been proposed to address this problem. This opinion reviews the recent advances and discusses the broader implications of using information-theoretic tools to characterize heterogeneity of cellular behaviors.}}, 
pages = {156--164}, 
volume = {28}, 
journal = {Current Opinion in Biotechnology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Current%20Opinion%20in%20Biotechnology-2014-Levchenko-Nemenman.pdf}, 
year = {2014}
}
@article{2001.Gillespie, 
author = {Gillespie, Daniel T}, 
title = {{Approximate accelerated stochastic simulation of chemically reacting systems}}, 
issn = {0021-9606}, 
doi = {10.1063/1.1378322}, 
pages = {1716--1733}, 
number = {4}, 
volume = {115}, 
journal = {The Journal of Chemical Physics}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/The%20Journal%20of%20Chemical%20Physics-2001-Gillespie-Gillespie.pdf}, 
year = {2001}
}
@article{1976.Gillespie, 
author = {Gillespie, Daniel T}, 
title = {{A general method for numerically simulating the stochastic time evolution of coupled chemical reactions}}, 
issn = {0021-9991}, 
doi = {10.1016/0021-9991(76)90041-3}, 
abstract = {{An exact method is presented for numerically calculating, within the framework of the stochastic formulation of chemical kinetics, the time evolution of any spatially homogeneous mixture of molecular species which interreact through a specified set of coupled chemical reaction channels. The method is a compact, computer-oriented, Monte Carlo simulation procedure. It should be particularly useful for modeling the transient behavior of well-mixed gas-phase systems in which many molecular species participate in many highly coupled chemical reactions. For “ordinary” chemical systems in which fluctuations and correlations play no significant role, the method stands as an alternative to the traditional procedure of numerically solving the deterministic reaction rate equations. For nonlinear systems near chemical instabilities, where fluctuations and correlations may invalidate the deterministic equations, the method constitutes an efficient way of numerically examining the predictions of the stochastic master equation. Although fully equivalent to the spatially homogeneous master equation, the numerical simulation algorithm presented here is more directly based on a newly defined entity called “the reaction probability density function.” The purpose of this article is to describe the mechanics of the simulation algorithm, and to establish in a rigorous, a priori manner its physical and mathematical validity; numerical applications to specific chemical systems will be presented in subsequent publications.}}, 
pages = {403--434}, 
number = {4}, 
volume = {22}, 
journal = {Journal of Computational Physics}, 
year = {1976}
}
@article{2020.Richards, 
author = {Richards, David M and Walker, Jamie J and Tabak, Joel}, 
title = {{Ion channel noise shapes the electrical activity of endocrine cells}}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1007769}, 
pmid = {32251433}, 
abstract = {{Endocrine cells in the pituitary gland typically display either spiking or bursting electrical activity, which is related to the level of hormone secretion. Recent work, which combines mathematical modelling with dynamic clamp experiments, suggests the difference is due to the presence or absence of a few large-conductance potassium channels. Since endocrine cells only contain a handful of these channels, it is likely that stochastic effects play an important role in the pattern of electrical activity. Here, for the first time, we explicitly determine the effect of such noise by studying a mathematical model that includes the realistic noisy opening and closing of ion channels. This allows us to investigate how noise affects the electrical activity, examine the origin of spiking and bursting, and determine which channel types are responsible for the greatest noise. Further, for the first time, we address the role of cell size in endocrine cell electrical activity, finding that larger cells typically display more bursting, while the smallest cells almost always only exhibit spiking behaviour.}}, 
pages = {e1007769}, 
number = {4}, 
volume = {16}, 
journal = {PLOS Computational Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/PLOS%20Computational%20Biology-2020-Richards-Tabak.pdf}, 
year = {2020}
}
@article{2020.Einav, 
author = {Einav, Tal and Bloom, Jesse D}, 
title = {{When two are better than one: Modeling the mechanisms of antibody mixtures}}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1007830}, 
pmid = {32365091}, 
abstract = {{It is difficult to predict how antibodies will behave when mixed together, even after each has been independently characterized. Here, we present a statistical mechanical model for the activity of antibody mixtures that accounts for whether pairs of antibodies bind to distinct or overlapping epitopes. This model requires measuring n individual antibodies and their n ( n - 1 ) 2 pairwise interactions to predict the 2n potential combinations. We apply this model to epidermal growth factor receptor (EGFR) antibodies and find that the activity of antibody mixtures can be predicted without positing synergy at the molecular level. In addition, we demonstrate how the model can be used in reverse, where straightforward experiments measuring the activity of antibody mixtures can be used to infer the molecular interactions between antibodies. Lastly, we generalize this model to analyze engineered multidomain antibodies, where components of different antibodies are tethered together to form novel amalgams, and characterize how well it predicts recently designed influenza antibodies.}}, 
pages = {e1007830}, 
number = {5}, 
volume = {16}, 
journal = {PLOS Computational Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/PLOS%20Computational%20Biology-2020-Einav-Bloom.pdf}, 
year = {2020}
}
@article{2020.Harootonian, 
author = {Harootonian, Sevan K and Wilson, Robert C and Hejtmánek, Lukáš and Ziskin, Eli M and Ekstrom, Arne D}, 
title = {{Path integration in large-scale space and with novel geometries: Comparing vector addition and encoding-error models}}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1007489}, 
pmid = {32379824}, 
abstract = {{Path integration is thought to rely on vestibular and proprioceptive cues yet most studies in humans involve primarily visual input, providing limited insight into their respective contributions. We developed a paradigm involving walking in an omnidirectional treadmill in which participants were guided on two sides of a triangle and then found their back way to origin. In Experiment 1, we tested a range of different triangle types while keeping the distance of the unguided side constant to determine the influence of spatial geometry. Participants overshot the angle they needed to turn and undershot the distance they needed to walk, with no consistent effect of triangle type. In Experiment 2, we manipulated distance while keeping angle constant to determine how path integration operated over both shorter and longer distances. Participants underestimated the distance they needed to walk to the origin, with error increasing as a function of the walked distance. To attempt to account for our findings, we developed configural-based computational models involving vector addition, the second of which included terms for the influence of past trials on the current one. We compared against a previously developed configural model of human path integration, the Encoding-Error model. We found that the vector addition models captured the tendency of participants to under-encode guided sides of the triangles and an influence of past trials on current trials. Together, our findings expand our understanding of body-based contributions to human path integration, further suggesting the value of vector addition models in understanding these important components of human navigation.}}, 
pages = {e1007489}, 
number = {5}, 
volume = {16}, 
journal = {PLOS Computational Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/PLOS%20Computational%20Biology-2020-Harootonian-Ekstrom.pdf}, 
year = {2020}
}
@article{2014.Tsimring, 
author = {Tsimring, Lev S}, 
title = {{Noise in biology}}, 
issn = {0034-4885}, 
doi = {10.1088/0034-4885/77/2/026601}, 
pmid = {24444693}, 
pmcid = {PMC4033672}, 
abstract = {{Noise permeates biology on all levels, from the most basic molecular, sub-cellular processes to the dynamics of tissues, organs, organisms and populations. The functional roles of noise in biological processes can vary greatly. Along with standard, entropy-increasing effects of producing random mutations, diversifying phenotypes in isogenic populations, limiting information capacity of signaling relays, it occasionally plays more surprising constructive roles by accelerating the pace of evolution, providing selective advantage in dynamic environments, enhancing intracellular transport of biomolecules and increasing information capacity of signaling pathways. This short review covers the recent progress in understanding mechanisms and effects of fluctuations in biological systems of different scales and the basic approaches to their mathematical modeling.}}, 
pages = {026601}, 
number = {2}, 
volume = {77}, 
journal = {Reports on Progress in Physics}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Reports%20on%20Progress%20in%20Physics-2014-Tsimring-Tsimring.pdf}, 
year = {2014}
}
@article{2011.Chan, 
author = {Chan, Joshua C C and Kroese, Dirk P}, 
title = {{Improved cross-entropy method for estimation}}, 
issn = {0960-3174}, 
doi = {10.1007/s11222-011-9275-7}, 
abstract = {{The cross-entropy (CE) method is an adaptive importance sampling procedure that has been successfully applied to a diverse range of complicated simulation problems. However, recent research has shown that in some high-dimensional settings, the likelihood ratio degeneracy problem becomes severe and the importance sampling estimator obtained from the CE algorithm becomes unreliable. We consider a variation of the CE method whose performance does not deteriorate as the dimension of the problem increases. We then illustrate the algorithm via a high-dimensional estimation problem in risk management.}}, 
pages = {1031--1040}, 
number = {5}, 
volume = {22}, 
journal = {Statistics and Computing}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Statistics%20and%20Computing-2011-Chan-Kroese.pdf}, 
year = {2011}
}
@article{1995.Ceperley, 
author = {Ceperley, D M}, 
title = {{Path integrals in the theory of condensed helium}}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.67.279}, 
abstract = {{One of Feynman's early applications of path integrals was to superfluid He4. He showed that the thermodynamic properties of Bose systems are exactly equivalent to those of a peculiar type of interacting classical "ring polymer." Using this mapping, one can generalize Monte Carlo simulation techniques commonly used for classical systems to simulate boson systems. In this review, the author introduces this picture of a boson superfluid and shows how superfluidity and Bose condensation manifest themselves. He shows the excellent agreement between simulations and experimental measurements on liquid and solid helium for such quantities as pair correlations, the superfluid density, the energy, and the momentum distribution. Major aspects of computational techniques developed for a boson superfluid are discussed: the construction of more accurate approximate density matrices to reduce the number of points on the path integral, sampling techniques to move through the space of exchanges and paths quickly, and the construction of estimators for various properties such as the energy, the momentum distribution, the superfluid density, and the exchange frequency in a quantum crystal. Finally the path-integral Monte Carlo method is compared to other quantum Monte Carlo methods.}}, 
pages = {279--355}, 
number = {2}, 
volume = {67}, 
journal = {Reviews of Modern Physics}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Reviews%20of%20Modern%20Physics-1995-Ceperley-Ceperley.pdf}, 
year = {1995}
}
@article{1970.Hastings, 
author = {Hastings, W K}, 
title = {{Monte Carlo sampling methods using Markov chains and their applications}}, 
issn = {0006-3444}, 
doi = {10.1093/biomet/57.1.97}, 
pages = {97--109}, 
number = {1}, 
volume = {57}, 
journal = {Biometrika}, 
year = {1970}
}
@article{2006.Skilling, 
author = {Skilling, John}, 
title = {{Nested sampling for general Bayesian computation}}, 
issn = {1936-0975}, 
doi = {10.1214/06-ba127}, 
abstract = {{Nested sampling estimates directly how the likelihood function relates to prior mass. The evidence (alternatively the marginal likelihood, marginal density of the data, or the prior predictive) is immediately obtained by summation. It is the prime result of the computation, and is accompanied by an estimate of numerical uncertainty. Samples from the posterior distribution are an optional by-product, obtainable for any temperature. The method relies on sampling within a hard constraint on likelihood value, as opposed to the softened likelihood of annealing methods. Progress depends only on the shape of the "nested" contours of likelihood, and not on the likelihood values. This invariance (over monotonic re-labelling) allows the method to deal with a class of phase-change problems which effectively defeat thermal annealing.}}, 
pages = {833--859}, 
number = {4}, 
volume = {1}, 
journal = {Bayesian Analysis}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Bayesian%20Analysis-2006-Skilling-Skilling.pdf}, 
year = {2006}
}
@article{2019.Rotskoff, 
author = {Rotskoff, Grant M and Vanden-Eijnden, Eric}, 
title = {{Dynamical Computation of the Density of States and Bayes Factors Using Nonequilibrium Importance Sampling}}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.122.150602}, 
pmid = {31050526}, 
eprint = {1809.11132}, 
abstract = {{Nonequilibrium sampling is potentially much more versatile than its equilibrium counterpart, but it comes with challenges because the invariant distribution is not typically known when the dynamics breaks detailed balance. Here, we derive a generic importance sampling technique that leverages the statistical power of configurations transported by nonequilibrium trajectories and can be used to compute averages with respect to arbitrary target distributions. As a dissipative reweighting scheme, the method can be viewed in relation to the annealed importance sampling (AIS) method and the related Jarzynski equality. Unlike AIS, our approach gives an unbiased estimator, with a provably lower variance than directly estimating the average of an observable. We also establish a direct relation between a dynamical quantity, the dissipation, and the volume of phase space, from which we can compute quantities such as the density of states and Bayes factors. We illustrate the properties of estimators relying on this sampling technique in the context of density of state calculations, showing that it scales favorable with dimensionality—in particular, we show that it can be used to compute the phase diagram of the mean-field Ising model from a single nonequilibrium trajectory. We also demonstrate the robustness and efficiency of the approach with an application to a Bayesian model comparison problem of the type encountered in astrophysics and machine learning.}}, 
pages = {150602}, 
number = {15}, 
volume = {122}, 
journal = {Physical Review Letters}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Physical%20Review%20Letters-2019-Rotskoff-Vanden-Eijnden.pdf}, 
year = {2019}
}
@article{1995.Chib, 
author = {Chib, Siddhartha}, 
title = {{Marginal Likelihood from the Gibbs Output}}, 
issn = {0162-1459}, 
doi = {10.1080/01621459.1995.10476635}, 
abstract = {{In the context of Bayes estimation via Gibbs sampling, with or without data augmentation, a simple approach is developed for computing the marginal density of the sample data (marginal likelihood) given parameter draws from the posterior distribution. Consequently, Bayes factors for model comparisons can be routinely computed as a by-product of the simulation. Hitherto, this calculation has proved extremely challenging. Our approach exploits the fact that the marginal density can be expressed as the prior times the likelihood function over the posterior density. This simple identity holds for any parameter value. An estimate of the posterior density is shown to be available if all complete conditional densities used in the Gibbs sampler have closed-form expressions. To improve accuracy, the posterior density is estimated at a high density point, and the numerical standard error of resulting estimate is derived. The ideas are applied to probit regression and finite mixture models.}}, 
pages = {1313--1321}, 
number = {432}, 
volume = {90}, 
journal = {Journal of the American Statistical Association}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Journal%20of%20the%20American%20Statistical%20Association-1995-Chib-Chib.pdf}, 
year = {1995}
}
@book{2009.Gardiner, 
author = {Gardiner, Crispin}, 
title = {{Stochastic Methods}}, 
isbn = {978-3-540-70712-7}, 
series = {Springer Series in Synergetics}, 
number = {13}, 
publisher = {Springer-Verlag}, 
address = {Berlin Heidelberg}, 
edition = {4}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Springer%20Series%20in%20Synergetics-2009-Gardiner-Gardiner.pdf}, 
year = {2009}
}
@article{2001.Han, 
author = {Han, Cong and Carlin, Bradley P}, 
title = {{Markov Chain Monte Carlo Methods for Computing Bayes Factors: A Comparative Review}}, 
issn = {0162-1459}, 
doi = {10.1198/016214501753208780}, 
pages = {1122--1132}, 
number = {455}, 
volume = {96}, 
journal = {Journal of the American Statistical Association}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Journal%20of%20the%20American%20Statistical%20Association-2001-Han-Carlin.pdf}, 
year = {2001}
}
@article{1997.Rubinstein, 
author = {Rubinstein, Reuven Y}, 
title = {{Optimization of computer simulation models with rare events}}, 
issn = {0377-2217}, 
doi = {10.1016/s0377-2217(96)00385-2}, 
abstract = {{Discrete event simulation systems (DESS) are widely used in many diverse areas such as computer-communication networks, flexible manufacturing systems, project evaluation and review techniques (PERT), and flow networks. Because of their complexity, such systems are typically analyzed via Monte Carlo simulation methods. This paper deals with optimization of complex computer simulation models involving rare events. A classic example is to find an optimal (s, S) policy in a multi-item, multicommodity inventory system, when quality standards require the backlog probability to be extremely small. Our approach is based on change of the probability measure techniques, also called likelihood ratio (LR) and importance sampling (IS) methods. Unfortunately, for arbitrary probability measures the LR estimators and the resulting optimal solution often tend to be unstable and may have large variances. Therefore, the choice of the corresponding importance sampling distribution and in particular its parameters in an optimal way is an important task. We consider the case where the IS distribution comes from the same parametric family as the original (true) one and use the stochastic counterpart method to handle simulation based optimization models. More specifically, we use a two-stage procedure: at the first stage we identify (estimate) the optimal parameter vector at the IS distribution, while at the second stage we estimate the optimal solution of the underlying constrained optimization problem. Particular emphasis will be placed on estimation of rare events and on integration of the associated performance function into stochastic optimization programs. Supporting numerical results are provided as well.}}, 
pages = {89--112}, 
number = {1}, 
volume = {99}, 
journal = {European Journal of Operational Research}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/European%20Journal%20of%20Operational%20Research-1997-Rubinstein-Rubinstein.pdf}, 
year = {1997}
}
@article{2007.Harland, 
author = {Harland, Ben and Sun, Sean X}, 
title = {{Path ensembles and path sampling in nonequilibrium stochastic systems}}, 
issn = {0021-9606}, 
doi = {10.1063/1.2775439}, 
pmid = {17867733}, 
abstract = {{Markovian models based on the stochastic master equation are often encountered in single molecule dynamics, reaction networks, and nonequilibrium problems in chemistry, physics, and biology. An efficient and convenient method to simulate these systems is the kinetic Monte Carlo algorithm which generates continuous-time stochastic trajectories. We discuss an alternative simulation method based on sampling of stochastic paths. Utilizing known probabilities of stochastic paths, it is possible to apply Metropolis Monte Carlo in path space to generate a desired ensemble of stochastic paths. The method is a generalization of the path sampling idea to stochastic dynamics, and is especially suited for the analysis of rare paths which are not often produced in the standard kinetic Monte Carlo procedure. Two generic examples are presented to illustrate the methodology.}}, 
pages = {104103}, 
number = {10}, 
volume = {127}, 
journal = {The Journal of Chemical Physics}, 
keywords = {Stochastic Paths}, 
year = {2007}
}
@article{2020.Busto-Moner, 
author = {Busto-Moner, Luis and Morival, Julien and Ren, Honglei and Fahim, Arjang and Reitz, Zachary and Downing, Timothy L and Read, Elizabeth L}, 
title = {{Stochastic modeling reveals kinetic heterogeneity in post-replication DNA methylation}}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1007195}, 
pmid = {32275652}, 
abstract = {{DNA methylation is a heritable epigenetic modification that plays an essential role in mammalian development. Genomic methylation patterns are dynamically maintained, with DNA methyltransferases mediating inheritance of methyl marks onto nascent DNA over cycles of replication. A recently developed experimental technique employing immunoprecipitation of bromodeoxyuridine labeled nascent DNA followed by bisulfite sequencing (Repli-BS) measures post-replication temporal evolution of cytosine methylation, thus enabling genome-wide monitoring of methylation maintenance. In this work, we combine statistical analysis and stochastic mathematical modeling to analyze Repli-BS data from human embryonic stem cells. We estimate site-specific kinetic rate constants for the restoration of methyl marks on >10 million uniquely mapped cytosines within the CpG (cytosine-phosphate-guanine) dinucleotide context across the genome using Maximum Likelihood Estimation. We find that post-replication remethylation rate constants span approximately two orders of magnitude, with half-lives of per-site recovery of steady-state methylation levels ranging from shorter than ten minutes to five hours and longer. Furthermore, we find that kinetic constants of maintenance methylation are correlated among neighboring CpG sites. Stochastic mathematical modeling provides insight to the biological mechanisms underlying the inference results, suggesting that enzyme processivity and/or collaboration can produce the observed kinetic correlations. Our combined statistical/mathematical modeling approach expands the utility of genomic datasets and disentangles heterogeneity in methylation patterns arising from replication-associated temporal dynamics versus stable cell-to-cell differences.}}, 
pages = {e1007195}, 
number = {4}, 
volume = {16}, 
journal = {PLOS Computational Biology}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/PLOS%20Computational%20Biology-2020-Busto-Moner-Read.pdf}, 
year = {2020}
}
@article{2020.Buijsman, 
author = {Buijsman, P and Bolhuis, P G}, 
title = {{Transition path sampling for non-equilibrium dynamics without predefined reaction coordinates}}, 
issn = {0021-9606}, 
doi = {10.1063/1.5130760}, 
pmid = {32007082}, 
abstract = {{We develop two novel transition path sampling (TPS) algorithms for harvesting ensembles of rare event trajectories using non-equilibrium dynamics. These methods have the advantage that no predefined reaction coordinate is needed. Instead, an instantaneous reaction coordinate is based on the current path. Constituting a Monte Carlo random walk in trajectory space, the algorithms can be viewed as bridging between the original TPS methodology and the Rosenbluth based forward flux sampling methodology. We illustrate the new methods on toy models undergoing equilibrium and non-equilibrium dynamics, including an active Brownian particle system. For the latter, we find that transitions between steady states occur via states that are locally ordered but globally disordered.}}, 
pages = {044108}, 
number = {4}, 
volume = {152}, 
journal = {The Journal of Chemical Physics}, 
keywords = {Recommended by PRtW}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/The%20Journal%20of%20Chemical%20Physics-2020-Buijsman-Bolhuis.pdf}, 
year = {2020}
}
@article{2011.Ciancarini, 
author = {Ciancarini, Paolo and Iorio, Angelo Di and Furini, Luca and Vitali, Fabio}, 
title = {{High-quality pagination for publishing: HIGH-QUALITY PAGINATION FOR PUBLISHING}}, 
issn = {0038-0644}, 
doi = {10.1002/spe.1096}, 
abstract = {{The problem of line breaking consists of finding the best way to split paragraphs into lines. It has been cleverly addressed by the total-fit algorithm exposed by Knuth and Plass in a well-known paper. Similarly, page-breaking algorithms break the content flow of a document into page units. Formatting languages—such as the World Wide Web Consortium standard Extensible Stylesheet Language Formatting Objects (XSL-FO)—allow users to set which content should be kept in the same page and how many isolated lines are acceptable at the beginning/end of each page. The strategies most formatters adopt to meet these requirements, however, are not satisfactory for many publishing contexts as they very often generate unpleasant empty areas. In that case, typographers are required to manually craft the results in order to completely fill pages. This paper presents a page-breaking algorithm that extends the original Knuth and Plass line-breaking approach and produces high-quality documents without unwanted empty areas. The basic idea consists of delaying the definitive choice of breaks in the line-breaking process in order to provide a larger set of alternatives to the actual pagination step. The algorithm also allows users to decide the set of properties to be adjusted for pagination and their variation ranges. An application of the algorithm to XSL-FO is also presented, with an extension of the language that allows users to drive the pagination process. The tool, named FOP+, is a customized version of the open-source Apache Formatting Objects Processor formatter. Copyright © 2011 John Wiley \& Sons, Ltd.}}, 
pages = {733--751}, 
number = {6}, 
volume = {42}, 
journal = {Software: Practice and Experience}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Software-%20Practice%20and%20Experience-2011-Ciancarini-Vitali.pdf}, 
year = {2011}
}
@article{2016.Mittelbach, 
author = {Mittelbach, Frank}, 
title = {{A General Framework for Globally Optimized Pagination}}, 
doi = {10.1145/2960811.2960820}, 
abstract = {{Pagination problems deal with questions around transforming a source text stream into a formatted document by dividing it up into individual columns and pages, including adding auxiliary elements that have some relationship to the source stream data but may allow a certain amount of variation in placement (such as figures or footnotes). Traditionally the pagination problem has been approached by separating it into one of micro-typography (e.g., breaking text into paragraphs, also known as h\&j) and one of macro-typography (e.g., taking a galley of already formatted paragraphs and breaking them into columns and pages) without much interaction between the two. While early solutions for both problem spaces used simple greedy algorithms, Knuth and Plass introduced in the '80s a global-fit algorithm for line breaking that optimizes the breaks across the whole paragraph [1]. This algorithm was implemented in TeX'82 [2] and has since kept its crown as the best available solution for this space. However, for macro-typography there has been no (successful) attempt to provide globally optimized page layout: all systems to date (including TeX) use greedy algorithms for pagination. Various problems in this area have been researched (e.g., [3,4,5,6]) and the literature documents some prototype development. But none of these prototypes have been made widely available to the research community or ever made it into a generally usable and publicly available system. This paper presents a framework for a global-fit algorithm for page breaking based on the ideas of Knuth/Plass. It is implemented in such a way that it is directly usable without additional executables with any modern TeX installation. It therefore can serve as a test bed for future experiments and extensions in this space. At the same time a cleaned-up version of the current prototype has the potential to become a production tool for the huge number of TeX users world-wide. The paper also discusses two already implemented extensions that increase the flexibility of the pagination process: the ability to automatically consider existing flexibility in paragraph length (by considering paragraph variations with different numbers of lines [7]) and the concept of running the columns on a double spread a line long or short. It concludes with a discussion of the overall approach, its inherent limitations and directions for future research. [1] D. E. Knuth and M. F. Plass. Breaking Paragraphs into Lines. Software-Practice and Experience, 11(11):1119-1184, Nov. 1981. [2] D. E. Knuth. TeX: The Program, volume B of Computers and Typesetting. Addison-Wesley, Reading, MA, USA, 1986. [3] A. Brüggemann-Klein, R. Klein, and S. Wohlfeil. Computer science in perspective. Chapter On the Pagination of Complex Documents, pages 49-68. Springer-Verlag New York, Inc., New York, NY, USA, 2003. [4] C. Jacobs, W. Li, and D. H. Salesin. Adaptive document layout via manifold content. In Second International Workshop on Web Document Analysis (wda2003), Liverpool, UK, 2003, 2003. [5] A. Holkner. Global multiple objective line breaking. Master's thesis, School of Computer Science and Information Technology, RMIT University, Melbourne, Victoria, Australia, 2006. [6] P. Ciancarini, A. Di Iorio, L. Furini, and F. Vitali. High-quality pagination for publishing. Software-Practice and Experience, 42(6):733-751, June 2012. [7] T. Hassan and A. Hunter. Knuth-Plass revisited: Flexible line-breaking for automatic document layout. In Proceedings of the 2015 ACM Symposium on Document Engineering, DocEng '15, pages 17-20, New York, NY, USA, 2015.}}, 
pages = {11--20}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/2960811.2960820.pdf}, 
year = {2016}
}
@article{1981.Knuth, 
author = {Knuth, Donald E and Plass, Michael F}, 
title = {{Breaking paragraphs into lines}}, 
issn = {0038-0644}, 
doi = {10.1002/spe.4380111102}, 
abstract = {{This paper discusses a new approach to the problem of dividing the text of a paragraph into lines of approximately equal length. Instead of simply making decisions one line at a time, the method considers the paragraph as a whole, so that the final appearance of a given line might be influenced by the text on succeeding lines. A system based on three simple primitive concepts called ‘boxes’, ‘glue’, and ‘penalties’ provides the ability to deal satisfactorily with a wide variety of typesetting problems in a unified framework, using a single algorithm that determines optimum breakpoints. The algorithm avoids backtracking by a judicious use of the techniques of dynamic programming. Extensive computational experience confirms that the approach is both efficient and effective in producing high-quality output. The paper concludes with a brief history of line-breaking methods, and an appendix presents a simplified algorithm that requires comparatively few resources.}}, 
pages = {1119--1184}, 
number = {11}, 
volume = {11}, 
journal = {Software: Practice and Experience}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Software-%20Practice%20and%20Experience-1981-Knuth-Plass.pdf}, 
year = {1981}
}
@article{2010.Roh, 
author = {Roh, Min K and Gillespie, Dan T and Petzold, Linda R}, 
title = {{State-dependent biasing method for importance sampling in the weighted stochastic simulation algorithm}}, 
issn = {0021-9606}, 
doi = {10.1063/1.3493460}, 
pmid = {21054005}, 
pmcid = {PMC3188645}, 
abstract = {{The weighted stochastic simulation algorithm (wSSA) was developed by Kuwahara and Mura [J. Chem. Phys. 129, 165101 (2008)] to efficiently estimate the probabilities of rare events in discrete stochastic systems. The wSSA uses importance sampling to enhance the statistical accuracy in the estimation of the probability of the rare event. The original algorithm biases the reaction selection step with a fixed importance sampling parameter. In this paper, we introduce a novel method where the biasing parameter is state-dependent. The new method features improved accuracy, efficiency, and robustness.}}, 
pages = {174106}, 
number = {17}, 
volume = {133}, 
journal = {The Journal of Chemical Physics}, 
keywords = {Importance Sampling}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/The%20Journal%20of%20Chemical%20Physics-2010-Roh-Petzold.pdf}, 
year = {2010}
}
@article{2018.Warne, 
author = {Warne, David J and Baker, Ruth E and Simpson, Matthew J}, 
title = {{Multilevel rejection sampling for approximate Bayesian computation}}, 
issn = {0167-9473}, 
doi = {10.1016/j.csda.2018.02.009}, 
eprint = {1702.03126}, 
abstract = {{ Likelihood-free methods, such as approximate Bayesian computation, are powerful tools for practical inference problems with intractable likelihood functions. Markov chain Monte Carlo and sequential Monte Carlo variants of approximate Bayesian computation can be effective techniques for sampling posterior distributions in an approximate Bayesian computation setting. However, without careful consideration of convergence criteria and selection of proposal kernels, such methods can lead to very biased inference or computationally inefficient sampling. In contrast, rejection sampling for approximate Bayesian computation, despite being computationally intensive, results in independent, identically distributed samples from the approximated posterior. An alternative method is proposed for the acceleration of likelihood-free Bayesian inference that applies multilevel Monte Carlo variance reduction techniques directly to rejection sampling. The resulting method retains the accuracy advantages of rejection sampling while significantly improving the computational efficiency.}}, 
pages = {71--86}, 
volume = {124}, 
journal = {Computational Statistics \& Data Analysis}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/Computational%20Statistics%20&%20Data%20Analysis-2018-Warne-Simpson.pdf}, 
year = {2018}
}
@article{2016.Warne, 
author = {Warne, David J and Baker, Ruth E and Simpson, Matthew J}, 
title = {{Accelerating computational Bayesian inference for stochastic biochemical reaction network models using multilevel Monte Carlo sampling}}, 
doi = {10.1101/064170}, 
abstract = {{Abstract Investigating the behavior of stochastic models of biochemical reactionnetworks generally relies upon numerical stochastic simulation methods to generate many realizations of the model. For many practical applications, such numerical simulation can be computationally expensive. The statistical inference of reaction rate parameters based on observed data is, however, a significantly greater computational challenge; often relying upon likelihood-free methods such as approximate Bayesian computation, that requirethe generation of millions of individual stochastic realizations. In this study, we investigate a new approach to computational inference, based on multilevel Monte Carlo sampling: we approximate the posterior cumulative distribution function through a combination of model samples taken over a range of acceptance thresholds. We demonstrate this approach using a variety of discrete-state, continuous-time Markov models of biochemical reactionnetworks. Results show that a computational gain over standard rejection schemes of up to an order of magnitude is achievable without significant loss in estimator accuracy. Author Summary We develop a new method to infer the reaction rate parameters for stochastic models of biochemical reaction networks. Standard computational approaches, based on numerical simulations, are often used to estimate parameters. These computational approaches, however, are extremely expensive, potentially requiring millions of simulations. To alleviate this issue, we apply a different method of sampling allowing us to find an optimal trade-off between performance and accuracy. Our approach is approximately one order of magnitude faster than standard methods, without significant loss in accuracy.}}, 
pages = {064170}, 
journal = {bioRxiv}, 
local-url = {file://localhost/Users/mr/Documents/Papers%20Library/bioRxiv-2016-Warne-Simpson.pdf}, 
year = {2016}
}