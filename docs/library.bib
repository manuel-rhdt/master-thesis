% Encoding: UTF-8

@Article{Nemenman2004,
  author       = {Nemenman, Ilya and Bialek, William and Van Steveninck, Rob De Ruyter},
  date         = {2004},
  journaltitle = {Physical Review E},
  title        = {Entropy and information in neural spike trains: Progress on the sampling problem},
  doi          = {10.1103/PhysRevE.69.056111},
  number       = {5},
  pages        = {056111},
  volume       = {69},
  file         = {:Nemenman2004 - Entropy and Information in Neural Spike Trains_ Progress on the Sampling Problem.pdf:PDF},
  groups       = {Entropy Estimation},
  journal      = {Physical Review E},
  keywords     = {read},
  month        = may,
  publisher    = {APS},
  readstatus   = {read},
  year         = {2004},
}

@Article{Paninski2003,
  author       = {Liam Paninski},
  date         = {2003-06},
  journaltitle = {Neural Computation},
  title        = {Estimation of Entropy and Mutual Information},
  doi          = {10.1162/089976603321780272},
  issn         = {0899-7667},
  number       = {6},
  pages        = {1191–1253},
  volume       = {15},
  file         = {:Paninski2003 - Estimation of Entropy and Mutual Information.pdf:PDF},
  groups       = {Entropy Estimation},
  publisher    = {MIT Press - Journals},
}

@Article{Beirlant1997,
  author       = {Beirlant, Jan and Dudewicz, Edward J and Györfi, László and Van der Meulen, Edward C},
  date         = {1997},
  journaltitle = {International Journal of Mathematical and Statistical Sciences},
  title        = {Nonparametric entropy estimation: An overview},
  number       = {1},
  pages        = {17–39},
  volume       = {6},
  file         = {:Beirlant1997 - Nonparametric Entropy Estimation_ an Overview.pdf:PDF},
  groups       = {Entropy Estimation},
  publisher    = {THESAURUS PUBLISHING},
}

@Article{Warren2012,
  author       = {Patrick B. Warren and Rosalind J. Allen},
  date         = {2012-03},
  journaltitle = {The Journal of Chemical Physics},
  title        = {Steady-state parameter sensitivity in stochastic modeling via trajectory reweighting},
  doi          = {10.1063/1.3690092},
  number       = {10},
  pages        = {104106},
  volume       = {136},
  file         = {:Warren2012 - Steady State Parameter Sensitivity in Stochastic Modeling Via Trajectory Reweighting.pdf:PDF},
  publisher    = {AIP Publishing},
}

@Article{Samad2005,
  author       = {Hana El Samad and Mustafa Khammash and Linda Petzold and Dan Gillespie},
  date         = {2005},
  journaltitle = {International Journal of Robust and Nonlinear Control},
  title        = {Stochastic modelling of gene regulatory networks},
  doi          = {10.1002/rnc.1018},
  number       = {15},
  pages        = {691–711},
  volume       = {15},
  file         = {:Samad2005 - Stochastic Modelling of Gene Regulatory Networks.pdf:PDF},
  publisher    = {Wiley},
}

@Article{Ziv,
  author    = {Etay Ziv and Ilya Nemenman and Chris H. Wiggins},
  title     = {Optimal Signal Processing in Small Stochastic Biochemical Networks},
  doi       = {10.1371/journal.pone.0001077},
  editor    = {Gustavo Stolovitzky},
  issn      = {1932-6203},
  number    = {10},
  pages     = {e1077},
  volume    = {2},
  file      = {:Ziv - Optimal Signal Processing in Small Stochastic Biochemical Networks.PDF:PDF},
  journal   = {PLoS ONE},
  month     = oct,
  publisher = {Public Library of Science (PLoS)},
}

@Article{Tostevin2010,
  author     = {Filipe Tostevin and Pieter Rein ten Wolde},
  title      = {Mutual information in time-varying biochemical systems},
  doi        = {10.1103/physreve.81.061917},
  number     = {6},
  volume     = {81},
  file       = {:Tostevin2010 - Mutual Information in Time Varying Biochemical Systems.PDF:PDF},
  journal    = {Physical Review E},
  keywords   = {read},
  month      = jun,
  publisher  = {American Physical Society (APS)},
  readstatus = {read},
  year       = {2010},
}

@Article{CepedaHumerez2019,
  author     = {Sarah Anhala Cepeda-Humerez and Jakob Ruess and Gašper Tkačik},
  title      = {Estimating information in time-varying signals},
  doi        = {10.1371/journal.pcbi.1007290},
  editor     = {Alexandre V. Morozov},
  number     = {9},
  pages      = {e1007290},
  volume     = {15},
  file       = {:CepedaHumerez2019 - Estimating Information in Time Varying Signals.PDF:PDF},
  journal    = {PLOS Computational Biology},
  keywords   = {read},
  month      = sep,
  publisher  = {Public Library of Science (PLoS)},
  readstatus = {read},
  year       = {2019},
}

@Article{Crooks,
  author    = {Gavin E. Crooks and David Chandler},
  title     = {Efficient transition path sampling for nonequilibrium stochastic dynamics},
  doi       = {10.1103/physreve.64.026109},
  issn      = {1063-651X},
  number    = {2},
  volume    = {64},
  journal   = {Physical Review E},
  month     = jul,
  publisher = {American Physical Society (APS)},
  year      = {2001},
}

@Article{Meijers2019,
  author        = {Matthijs Meijers and Sosuke Ito and Pieter Rein ten Wolde},
  title         = {The behaviour of information flow near criticality},
  date          = {2019-06-03},
  eprint        = {1906.00787},
  eprintclass   = {cond-mat.stat-mech},
  eprinttype    = {arXiv},
  url           = {https://arxiv.org/abs/1906.00787},
  abstract      = {Recent experiments have indicated that many biological systems self-organise near their critical point, which hints at a common design principle. While it has been suggested that information transmission is optimized near the critical point, it remains unclear how information transmission depends on the dynamics of the input signal, the distance over which the information needs to be transmitted, and the distance to the critical point. Here we employ stochastic simulations of a driven 2D Ising system and study the instantaneous mutual information and the information transmission rate between a driven input spin and an output spin. The instantaneous mutual information varies non-monotonically with the temperature, but increases monotonically with the correlation time of the input signal. In contrast, the information transmission rate exhibits a maximum as a function of the input correlation time. Moreover, there exists an optimal temperature that maximizes this maximum information transmission rate. It arises from a tradeoff between the necessity to respond fast to changes in the input so that more information per unit amount of time can be transmitted, and the need to respond to reliably. The optimal temperature lies above the critical point, but moves towards it as the distance between the input and output spin is increased.},
  archiveprefix = {arXiv},
  file          = {:http\:/arxiv.org/pdf/1906.00787v1:PDF},
  keywords      = {cond-mat.stat-mech, cond-mat.soft, physics.bio-ph, q-bio.OT},
  primaryclass  = {cond-mat.stat-mech},
}

@Article{Blanchard2019,
  author      = {Pierre Blanchard and Desmond J. Higham and Nicholas J. Higham},
  date        = {2019-09-08},
  title       = {Accurate Computation of the Log-Sum-Exp and Softmax Functions},
  eprint      = {1909.03469v1},
  eprintclass = {math.NA},
  eprinttype  = {arXiv},
  abstract    = {Evaluating the log-sum-exp function or the softmax function is a key step in many modern data science algorithms, notably in inference and classification. Because of the exponentials that these functions contain, the evaluation is prone to overflow and underflow, especially in low precision arithmetic. Software implementations commonly use alternative formulas that avoid overflow and reduce the chance of harmful underflow, employing a shift or another rewriting. Although mathematically equivalent, these variants behave differently in floating-point arithmetic. We give rounding error analyses of different evaluation algorithms and interpret the error bounds using condition numbers for the functions. We conclude, based on the analysis and numerical experiments, that the shifted formulas are of similar accuracy to the unshifted ones and that the shifted softmax formula is typically more accurate than a division-free variant.},
  file        = {:http\://arxiv.org/pdf/1909.03469v1:PDF},
  keywords    = {math.NA, cs.NA, 97N20, G.1.3; I.2.8; G.3; G.4},
}

@Article{Chan2012,
  author       = {Joshua C. C. Chan and Eric Eisenstat},
  date         = {2012-05-01},
  journaltitle = {SSRN Electronic Journal},
  title        = {Marginal Likelihood Estimation with the Cross-Entropy Method},
  doi          = {10.2139/ssrn.2055042},
  issn         = {1556-5068},
  file         = {:Chan - Marginal Likelihood Estimation with the Cross Entropy Method.PDF:PDF},
  groups       = {Importance Sampling},
  publisher    = {Elsevier BV},
  year         = {2012},
}

@Article{Perrakis2014,
  author = {Konstantinos Perrakis and Ioannis Ntzoufras and Efthymios G. Tsionas},
  title  = {On the use of marginal posteriors in marginal likelihood estimation via importance sampling},
  doi    = {10.1016/j.csda.2014.03.004},
  issn   = {0167-9473},
  pages  = {54-69},
  volume = {77},
  file   = {:Perrakis2014 - On the Use of Marginal Posteriors in Marginal Likelihood Estimation Via Importance Sampling.PDF:PDF;:Perrakis2014 - On the use of marginal posteriors in marginal likelihood estimation via importance sampling.PDF:PDF},
  year   = {2014},
}

@TechReport{Gelfand1989,
  author     = {Alan E. Gelfand and Adrian F. Smith},
  date       = {1989-04},
  title      = {Sampling Based Approaches to Calculating Marginal Densities},
  doi        = {10.21236/ada208388},
  file       = {:Gelfand1989 - Sampling Based Approaches to Calculating Marginal Densities.pdf:PDF;:Gelfand1989 - Sampling Based Approaches to Calculating Marginal Densities.pdf:PDF},
  groups     = {Importance Sampling},
  keywords   = {read},
  publisher  = {Defense Technical Information Center},
  readstatus = {read},
}

@Article{Wolpert1995,
  author    = {David H. Wolpert and David R. Wolf},
  title     = {Estimating functions of probability distributions from a finite set of samples},
  doi       = {10.1103/physreve.52.6841},
  number    = {6},
  pages     = {6841--6854},
  volume    = {52},
  file      = {:Wolpert1995 - Estimating Functions of Probability Distributions from a Finite Set of Samples.PDF:PDF},
  journal   = {Physical Review E},
  month     = {dec},
  publisher = {American Physical Society ({APS})},
  year      = {1995},
}

@Article{Duso2019,
  author      = {Lorenzo Duso and Christoph Zechner},
  date        = {2019-04-03},
  title       = {Path mutual information for a class of biochemical reaction networks},
  eprint      = {1904.01988v1},
  eprintclass = {q-bio.MN},
  eprinttype  = {arXiv},
  abstract    = {Living cells encode and transmit information in the temporal dynamics of biochemical components. Gaining a detailed understanding of the input-output relationship in biological systems therefore requires quantitative measures that capture the interdependence between complete time trajectories of biochemical components. Mutual information provides such a measure but its calculation in the context of stochastic reaction networks is associated with mathematical challenges. Here we show how to estimate the mutual information between complete paths of two molecular species that interact with each other through biochemical reactions. We demonstrate our approach using three simple case studies.},
  file        = {:http\://arxiv.org/pdf/1904.01988v1:PDF},
  keywords    = {q-bio.MN, q-bio.QM},
}

@Article{Ouldridge2017,
  author    = {Thomas E. Ouldridge and Christopher C. Govern and Pieter Rein ten Wolde},
  title     = {Thermodynamics of Computational Copying in Biochemical Systems},
  doi       = {10.1103/physrevx.7.021004},
  number    = {2},
  volume    = {7},
  journal   = {Physical Review X},
  month     = {apr},
  publisher = {American Physical Society ({APS})},
  year      = {2017},
}

@Article{Ouldridge2017a,
  author    = {Thomas E. Ouldridge and Pieter Rein ten Wolde},
  title     = {Fundamental Costs in the Production and Destruction of Persistent Polymer Copies},
  doi       = {10.1103/physrevlett.118.158103},
  number    = {15},
  volume    = {118},
  journal   = {Physical Review Letters},
  month     = {apr},
  publisher = {American Physical Society ({APS})},
  year      = {2017},
}

@Article{Shannon1948,
  author    = {C. E. Shannon},
  date      = {1948},
  title     = {A Mathematical Theory of Communication},
  doi       = {10.1002/j.1538-7305.1948.tb01338.x},
  issn      = {0005-8580},
  number    = {3},
  pages     = {379--423},
  volume    = {27},
  file      = {:Shannon1948 - A Mathematical Theory of Communication.pdf:PDF},
  journal   = {Bell System Technical Journal},
  month     = {jul},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  year      = {1948},
}

@Misc{Gelfand1991,
  author = {Alan E. Gelfand and Adrian F. Smith},
  date   = {1991},
  title  = {Gibbs Sampling for Marginal Posterior Expectations},
  doi    = {10.21236/ada243212},
  file   = {:Gelfand1991 - Gibbs Sampling for Marginal Posterior Expectations.pdf:PDF},
  groups = {Importance Sampling},
}

@Misc{Carlin1990,
  author = {Bradley P. Carlin and Alan E. Gelfand and Adrian F. Smith},
  date   = {1990},
  title  = {Hierarchical Bayesian Analysis of Change Point Problems},
  doi    = {10.21236/ada228179},
  file   = {:Carlin1990 - Hierarchical Bayesian Analysis of Change Point Problems.pdf:PDF},
  groups = {Importance Sampling},
}

@TechReport{Mueller1991,
  author      = {Peter Müller},
  date        = {1991-02},
  institution = {Department of Statistics, Purdue University},
  title       = {A Generic Approach to Posterior Integration and Gibbs Sampling},
  file        = {:Mueller1991 - A Generic Approach to Posterior Integration and Gibbs Sampling.pdf:PDF},
  groups      = {Importance Sampling},
}

@Article{Tierney1994,
  author       = {Luke Tierney},
  date         = {1994},
  journaltitle = {The Annals of Statistics},
  title        = {Markov Chains for Exploring Posterior Distributions},
  doi          = {10.1214/aos/1176325750},
  issn         = {0090-5364},
  number       = {4},
  pages        = {1701--1728},
  url          = {http://www.jstor.org/stable/2242477},
  volume       = {22},
  abstract     = {Several Markov chain methods are available for sampling from a posterior distribution. Two important examples are the Gibbs sampler and the Metropolis algorithm. In addition, several strategies are available for constructing hybrid algorithms. This paper outlines some of the basic methods and strategies and discusses some related theoretical and practical issues. On the theoretical side, results from the theory of general state space Markov chains can be used to obtain convergence rates, laws of large numbers and central limit theorems for estimates obtained from Markov chain methods. These theoretical results can be used to guide the construction of more efficient algorithms. For the practical use of Markov chain methods, standard simulation methodology provides several variance reduction techniques and also give guidance on the choice of sample size and allocation.},
  groups       = {Importance Sampling},
  publisher    = {Institute of Mathematical Statistics},
}

@Article{Gelfand1994,
  author       = {A. E. Gelfand and D. K. Dey},
  date         = {1994-09},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
  title        = {Bayesian Model Choice: Asymptotics and Exact Calculations},
  doi          = {10.1111/j.2517-6161.1994.tb01996.x},
  issn         = {0035-9246},
  number       = {3},
  pages        = {501--514},
  volume       = {56},
  file         = {:Gelfand1994 - Bayesian Model Choice_ Asymptotics and Exact Calculations.pdf:PDF},
  groups       = {Importance Sampling},
  publisher    = {Wiley},
}

@Article{Newton1994,
  author       = {Michael A. Newton and Adrian E. Raftery},
  date         = {1994},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Methodological)},
  title        = {Approximate Bayesian Inference with the Weighted Likelihood Bootstrap},
  doi          = {10.1111/j.2517-6161.1994.tb01956.x},
  issn         = {0035-9246},
  number       = {1},
  pages        = {3--26},
  volume       = {56},
  file         = {:Newton1994 - Approximate Bayesian Inference with the Weighted Likelihood Bootstrap.pdf:PDF},
  groups       = {Importance Sampling},
  month        = jan,
  publisher    = {Wiley},
  year         = {1994},
}

@Article{Dijk1987,
  author       = {Herman K. Van Dijk and J. Peter Hop and Adri S. Louter},
  date         = {1987},
  journaltitle = {The Statistician},
  title        = {An Algorithm for the Computation of Posterior Moments and Densities Using Simple Importance Sampling},
  doi          = {10.2307/2348500},
  issn         = {0039-0526},
  number       = {2/3},
  pages        = {83},
  volume       = {36},
  file         = {:Dijk1987 - An Algorithm for the Computation of Posterior Moments and Densities Using Simple Importance Sampling.pdf:PDF},
  groups       = {Importance Sampling},
  publisher    = {JSTOR},
}

@Article{Meng1996,
  author       = {Xiao-Li Meng and Wing Hung Wong},
  date         = {1996},
  journaltitle = {Statistica Sinica},
  title        = {Simulating Ratios of Normalizing Constants Via a Simple Identity: A Theoretical Exploration},
  number       = {4},
  pages        = {831--860},
  url          = {http://www.jstor.org/stable/24306045},
  volume       = {6},
  abstract     = {Let pi(w),i = 1,2, be two densities with common support where each density is known up to a normalizing constant: pi(w) = qi(w)/ci. We have draws from each density (e.g., via Markov chain Monte Carlo), and we want to use these draws to simulate the ratio of the normalizing constants, c1/c2. Such a computational problem is often encountered in likelihood and Bayesian inference, and arises in fields such as physics and genetics. Many methods proposed in statistical and other literature (e.g., computational physics) for dealing with this problem are based on various special cases of the following simple identity: (c₁/c₂) = ((E₂[q₁(w)α (w)])/(E₁[q₂(w)α (w)])) Here Ei denotes the expectation with respect to pi (i = 1,2), and α is an arbitrary function such that the denominator is non-zero. A main purpose of this paper is to provide a theoretical study of the usefulness of this identity, with focus on (asymptotically) optimal and practical choices of α. Using a simple but informative example, we demonstrate that with sensible (not necessarily optimal) choices of α, we can reduce the simulation error by orders of magnitude when compared to the conventional importance sampling method, which corresponds to α = 1/q2. We also introduce several generalizations of this identity for handling more complicated settings (e.g., estimating several ratios simultaneously) and pose several open problems that appear to have practical as well as theoretical value. Furthermore, we discuss related theoretical and empirical work.},
  groups       = {Importance Sampling},
  publisher    = {Institute of Statistical Science, Academia Sinica},
}

@Article{Gelman1998,
  author       = {Andrew Gelman and Xiao-Li Meng},
  date         = {1998-05},
  journaltitle = {Statistical Science},
  title        = {Simulating normalizing constants: from importance sampling to bridge sampling to path sampling},
  doi          = {10.1214/ss/1028905934},
  number       = {2},
  pages        = {163--185},
  volume       = {13},
  groups       = {Importance Sampling},
  publisher    = {Institute of Mathematical Statistics},
}

@Article{Diciccio1997,
  author = {Thomas J. Diciccio and Robert E. Kass and Adrian Raftery and Larry Wasserman},
  title  = {Computing Bayes Factors by Combining Simulation and Asymptotic Approximations},
  doi    = {10.1080/01621459.1997.10474045},
  issn   = {0162-1459},
  pages  = {903-915},
  volume = {92},
  file   = {:Diciccio1997 - Computing Bayes Factors by Combining Simulation and Asymptotic Approximations.PDF:PDF},
  groups = {Importance Sampling},
  year   = {1997},
}

@Comment{jabref-meta: databaseType:biblatex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Importance Sampling\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:Entropy Estimation\;0\;1\;0x8a8a8aff\;\;\;;
}
