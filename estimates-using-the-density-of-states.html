<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js Light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Mutual Information between Trajectories</title>
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.min.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
        <script>document.addEventListener("DOMContentLoaded", function () {
            var mathElements = document.getElementsByClassName("math");
            var regex = /\\qquad\W*\(([0-9]+)\)/;
            for (var i = 0; i < mathElements.length; i++) {
                var texText = mathElements[i].firstChild;
                if (mathElements[i].tagName == "SPAN") {
                    var tex_str = texText.data.replace(regex, "\\tag{$1}");
                    katex.render(tex_str, mathElements[i], {
                    displayMode: mathElements[i].classList.contains('display'),
                    throwOnError: false,
                    fleqn: false
                });
            }}});
        </script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "" : "Light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('Light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="expanded"><a href="index.html" class=""><span class="header-section-number">1</span> Preface
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html" class=""><span class="header-section-number">2</span> Mutual Information for Trajectories in a Gaussian Framework
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#introduction" class=""><span class="header-section-number">2.1</span> Introduction
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#monte-carlo-estimate-for-the-marginal-entropy" class=""><span class="header-section-number">2.2</span> Monte-Carlo Estimate for the Marginal Entropy
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#choice-of-covariance-matrices" class=""><span class="header-section-number">2.2.1</span> Choice of Covariance Matrices
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#direct-importance-sampling" class=""><span class="header-section-number">2.2.2</span> Direct Importance Sampling
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#umbrella-sampling" class=""><span class="header-section-number">2.2.3</span> Umbrella Sampling
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#estimating-the-conditional-entropy" class=""><span class="header-section-number">2.3</span> Estimating the Conditional Entropy
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#discussion" class=""><span class="header-section-number">2.4</span> Discussion
                    </a>
                    </li><li class="expanded"><a href="mutual-information-for-trajectories-in-a-gaussian-framework.html#references" class=""><span class="header-section-number">2.5</span> References
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html" class=""><span class="header-section-number">3</span> Information theory for trajectories
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="information-theory-for-trajectories.html#monte-carlo-simulation" class=""><span class="header-section-number">3.1</span> Monte-Carlo simulation
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#estimating-the-likelihood" class=""><span class="header-section-number">3.2</span> Estimating the likelihood
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="information-theory-for-trajectories.html#the-probability-density-for-the-starting-point-of-a-trajectory" class=""><span class="header-section-number">3.2.1</span> The probability density for the starting point of a trajectory
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#the-transition-probabilities" class=""><span class="header-section-number">3.2.2</span> The transition probabilities
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#estimating-the-marginal-probability-of-response-trajectories" class=""><span class="header-section-number">3.2.3</span> Estimating the marginal probability of response trajectories
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#chemical-master-equation" class=""><span class="header-section-number">3.3</span> Chemical Master Equation
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#jump-processes" class=""><span class="header-section-number">3.4</span> Jump Processes
                    </a>
                    </li><li class="expanded"><a href="information-theory-for-trajectories.html#simulating-a-biochemical-network-driven-by-an-external-signal" class=""><span class="header-section-number">3.5</span> Simulating a Biochemical Network Driven by an External Signal
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="references.html" class="">References
                    </a>
                    </li><li class="expanded"><a href="borrowing-terminology-from-statistical-physics.html" class=""><span class="header-section-number">4</span> Borrowing Terminology from Statistical Physics
                    </a>
                    </li><li class="expanded"><a href="estimates-using-the-density-of-states.html" class="active"><span class="header-section-number">5</span> Estimates Using the Density of States
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="estimates-using-the-density-of-states.html#wang-and-landau-algorithm" class=""><span class="header-section-number">5.1</span> Wang and Landau Algorithm
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="path-sampling.html" class=""><span class="header-section-number">6</span> Path Sampling
                    </a>
                    </li><li class="expanded">
                    <ol class="section">
                        <li class="expanded"><a href="path-sampling.html#summary-of-path-sampling" class=""><span class="header-section-number">6.1</span> Summary of Path Sampling
                    </a>
                    </li><li class="expanded"><a href="path-sampling.html#markov-chain-monte-carlo" class=""><span class="header-section-number">6.2</span> Markov Chain Monte Carlo
                    </a>
                    </li>
                    </ol>
                    </li><li class="expanded"><a href="references.html" class="">References
                    </a>
                    </li><li class="expanded"><a href="chapter_9.html" class="">
                    </a>
                    </li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                    </div>

                    <h1 class="menu-title">Mutual Information between Trajectories</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        <a href="https://github.com/manuel-rhdt/master-thesis" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <section id="estimates-using-the-density-of-states" class="level1" data-number="2">
<h1 data-number="5"><span class="header-section-number">5</span> Estimates Using the Density of States</h1>

<p>In the context of statistical physics we often look at configurations of a system that can be described by a parameter vector <span class="math inline">\mathbf{n}\in\Omega</span> where <span class="math inline">\Omega</span> is the state space of the system. We can typically assign a probability (density) to each configuration. For example, let’s consider the canonical ensemble for a given inverse temperature <span class="math inline">\beta</span> and Hamiltonian <span class="math inline">\mathcal H</span> <span id="eq:canonical_probability"><span class="math display">
\mathrm{P}(\mathbf{n}) = \frac{1}{Z(\beta)} e^{-\beta \mathcal H(\mathbf{n})}
\qquad(5)</span></span> with the <em>partition function</em> <span class="math inline">Z(\beta)=\int \mathrm{d}\mathbf{n}\ e^{-\beta H(\mathbf{n})}</span>. The Hamiltonian assigns an energy to every state, i.e. for every state <span class="math inline">\mathbf{n}</span> we have an associated energy <span class="math inline">\mathcal H(\mathbf{n})</span>. To learn more about the distribution of energies in our system we can now define the <em>density of states</em> <span class="math inline">g(E)</span> at a given energy <span class="math inline">E</span> as the probability density of a random<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> state <span class="math inline">\hat{\mathbf{n}}</span> to have energy <span class="math inline">\mathcal H(\hat{\mathbf{n}}) = E</span>. More precisely, let <span class="math inline">\mathcal{N}</span> be a random variable uniformly distributed in the state space, then <span><span class="math display">
g(E) = \mathrm{P}\left(\mathcal H(\mathcal N) = E\right)\,.
\qquad(6)</span></span></p>
<p>The density of states (<em>DOS</em>) thus describes the contribution of individual energy levels to the ensemble average of quantities that merely depend on the energy of a state. That is, we can compute the ensemble average <span class="math inline">\langle f(\mathcal H(\mathbf{n}))\rangle</span> of any function <span class="math inline">f</span> that depends only on the energy of a given state as <span id="eq:def_dos"><span class="math display">
\langle f(\mathcal H(\mathbf{n}))\rangle = \frac{\int\mathrm d\mathbf n\ f(\mathcal H(\mathbf n)) e^{-\beta \mathcal H(\mathbf{n})}}{\int\mathrm d\mathbf n\ e^{-\beta \mathcal H(\mathbf{n})}} = 
\frac{
\int\mathrm dE\ g(E) f(E) e^{-\beta E}
 }{
   \int\mathrm dE\ g(E) e^{-\beta E}
 } \,.
\qquad(7)</span></span> Eq. <a href="#eq:def_dos">7</a> motivates the common way of specifying the DOS using the Dirac delta function <span id="eq:dirac_dos"><span class="math display">
g(E) = \int \mathrm d\mathbf n\ \delta(\mathcal H(\mathbf n) - E)
\qquad(8)</span></span> which matches the intuition of plotting an energy histogram for randomly chosen states. I.e. for discrete energies <span class="math inline">E_1\cdotsE_n</span> (the histogram bins) and random states <span class="math inline">\mathbf n_1,\ldots,\mathbf n_N</span> we can approximate the DOS as <span id="eq:dos_histogram"><span class="math display">
g_\text{discrete}(E_i) = \frac1N \sum\limits^N_{j=1} \delta_{\mathcal H(\mathbf n_j), E_i}
\qquad(9)</span></span> where <span class="math inline">\delta_{\epsilon, E_i}</span> is <span class="math inline">1</span> if the energy <span class="math inline">\epsilon</span> falls inside the <span class="math inline">i</span>-th histogram bin and <span class="math inline">0</span> otherwise. As the number of random states and the number of histogram bins grow towards infinity, <span class="math inline">g_\text{discrete}</span> converges to eq. <a href="#eq:dirac_dos">8</a>.</p>
<p>For us, the DOS is of relevance because can be used to compute the partition function <span><span class="math display">
Z(\beta) = \int \mathrm{d}\mathbf{n}\ e^{-\beta H(\mathbf{n})} = \int \mathrm dE\ g(E) e^{-\beta E}
\qquad(10)</span></span> and thus the free energy. In the following we will discuss the Wang and Landau algorithm to estimate the DOS and evaluate its usefulness for the computation of the marginal density of a trajectory.</p>

<section id="wang-and-landau-algorithm" class="level2" data-number="2.1">
<h2 data-number="5.1"><span class="header-section-number">5.1</span> Wang and Landau Algorithm</h2>
<p>Since the state spaces <span class="math inline">\Omega</span> are usually very large, one typically resorts to Monte-Carlo methods to estimate the density of states. There one generates a sequence of states <span class="math inline">\mathbf{n}_i</span> that are approximately independent and distributed according to <span class="math inline">\mathrm{P}(\mathcal{N})</span>, e.g. by using the Metropolis-Hastings algorithm. For every sampled state <span class="math inline">\mathbf{n}_i</span> we can compute the Energy <span class="math inline">\mathcal H(\mathbf{n}_i)</span> and then approximate the density of states by a histogram of the energy values as in eq. <a href="#eq:dos_histogram">9</a>. To get an accurate estimate of the density of states for energy values <span class="math inline">E</span> where <span class="math inline">\rho(E)</span> is very small we need a lot of simulation time since we will on average pick very few samples with low probability.</p>
<p>The idea of the Wang and Landau algorithm <span class="citation" data-cites="2001:Wangg8b">[<a href="#ref-2001:Wangg8b" role="doc-biblioref">1</a>]</span> is instead to not generate samples that are distributed according to the equilibrium distribution <span class="math inline">\mathrm{P}(\mathbf{n})</span> but to adaptively vary the sampling distribution throuhgout the simulation. (TODO: I think I understand how the algorithm works but I have not yet found the time to write it down accurately.)</p>
<p>We can use the Wang and Landau algorithm to compute the marginal probability density <span class="math inline">\mathrm{P}(\mathbf{x})</span> for a given response trajectory <span class="math inline">\mathbf{x}</span>. To estimate this we make use of the marginalization <span class="math inline">\mathrm{P}(\mathbf{x}) = \int \mathrm{d}\mathbf{s}\ \mathrm{P}(\mathbf{s})\ \mathrm P(\mathbf{x}|\mathbf{s})</span> over the signals <span class="math inline">\mathbf s</span>. To make the connection to the statistical physics context for the Wang and Landau algorithm notationally clear, we formally introduce the <em>energy</em> of a signal trajectory <span class="math inline">\mathbf s</span> with respect to a given response <span class="math inline">\mathbf x</span> and define it as <span class="math inline">E_\mathbf{x}(\mathbf s) = -\ln\mathrm{P}(\mathbf{x}|\mathbf{s})</span>. Since there is little potential for confusion we will just drop the index <span class="math inline">\mathbf x</span> from now on. Then we can define the density of states by analogy to be <span><span class="math display">
\rho(E) = \mathrm P\left(E(\mathcal S) = E\right)
\qquad(11)</span></span> which allows us to express the marginal probability as <span id="eq:integrated_dos"><span class="math display">
\mathrm{P}(\mathbf{x}) = \int \mathrm{d}\mathbf{s}\ \mathrm{P}(\mathbf{s})\ \mathrm P(\mathbf{x}|\mathbf{s}) = \int \mathrm{d}\mathbf{s}\ \mathrm{P}(\mathbf{s})\ e^{-E(\mathbf s)} = \int\mathrm{d}E\ \rho(E) e^{-E}\,.
\qquad(12)</span></span> Therefore a viable approach to estimate the marginal entropy might be to compute the approximate density of states using the Wang and Landau algorithm and then to directly perform the integral in eq. <a href="#eq:integrated_dos">12</a>.</p>
<p>When we perform a standard Monte-Carlo estimate of <span class="math inline">\mathrm{P}(\mathbf{x})</span> we generate independent samples <span class="math inline">\mathbf{s}_1,\ldots,\mathbf{s}_M</span>, all identically distributed according to <span class="math inline">\mathrm P(\mathcal{S})</span> and then compute <span><span class="math display">
\hat{\mathrm{P}}(\mathbf{x}) = \frac{1}{M} \sum\limits^M_{i=1} \mathrm{P}(\mathbf x|\mathbf s_i) \,.
\qquad(13)</span></span> This estimate is essentially the same as performing the integral from eq. <a href="#eq:integrated_dos">12</a> where the density of states <span class="math inline">\rho(E)</span> is just approximated as the histogram of the energies <span class="math inline">E(\mathbf{s}_1),\ldots,E(\mathbf{s}_M)</span>. Specifically in the limit of the width of histogram bins approaching 0, the approximate density of states becomes <span class="math inline">\hat{\rho}(E)=1/M\ \sum^M_{i=1} \delta(E-E(\mathbf{s}_i))</span> and therefore <span><span class="math display">
\int\mathrm{d}E\ \hat{\rho}(E) e^{-E} = \frac{1}{M}\int\mathrm dE \left[\sum^M_{i=1} \delta(E-E(\mathbf{s}_i)) e^{-E}\right] = \frac{1}{M} \sum\limits^M_{i=1} e^{-E(\mathbf{s}_i)} = \hat{\mathrm{P}}(\mathbf{x})\,.
\qquad(14)</span></span></p>
<figure>
<embed src="figures/density-of-states.pdf" id="fig:density-of-states" /></embed><figcaption>Figure 1: Histograms of the negative log-likelihoods per unit time for various signals and one given response. The y-axis shows probability densities which are akin to the density of states in statistical physics. The data are from Gillespie simulations using a single random trajectory <span class="math inline">\mathbf x</span> of duration <span class="math inline">T</span> and 10000 signal trajectories <span class="math inline">\mathbf{s}_i</span>, each sampled from <span class="math inline">\mathrm{P}(\mathbf s)</span>.</figcaption>
</figure>
<p>In fig. <a href="#fig:density-of-states">1</a> we show several histograms of the density of states (however with finite bin width) for a Gillespie simulation of <span class="math inline">M=10000</span> signals. In these simulations we typically under-estimate the marginal probability density (and therefore over-estimate the marginal entropy). We propose that the bias arises because we do not have good enough sampling in the low-density regions of the density of states. From eq. <a href="#eq:integrated_dos">12</a> we see that due to the factor <span class="math inline">e^{-E}</span> especially trajectories with low energy contribute strongly to the overall estimate. This suggests that we should try to bias our sampling distribution towards trajectories with low energies. One way to do this might be the Wang and Landau algorithm.</p>
</section>
</section>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="borrowing-terminology-from-statistical-physics.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="path-sampling.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a rel="prev" href="borrowing-terminology-from-statistical-physics.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a rel="next" href="path-sampling.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        
        
        

        

        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>